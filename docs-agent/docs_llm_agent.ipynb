{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain core\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# LangChain OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# LangChain Community\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Standard libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Procedure \n",
    "## 1.Pydandic docs llm.txt(https://docs.pydantic.dev/latest/llms.txt)에서 URL과 description을 추출한 후, Supabase 데이터 베이스에 저장\n",
    "\n",
    "## 2. 문서 리스트 조회  \n",
    " (1) URL과 description을 추출출한 것을 가져와 Documet 객체로 변환한다. \n",
    " (2) 임베딩 후 사용자 query와 simiarity check를 통해 URL을 선별한다.\n",
    " (3) 각각의 URL들을 하나의 chunk로 만든다. \n",
    "## 3. 웹 페이지 Fetch\n",
    " (1) 선별된 URL을 fetch를 한 후 각각의 URL에 해당하는 본문을 가져온다. \n",
    "## 4. Context Filter \n",
    "- 마지막으로 각각의 URL 본문들 중에 사용자 query와의 similarity check 를 통해 context filter를 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Procedure\n",
    "\n",
    "## 1. Extract URL and Description from Pydantic Docs\n",
    "- Extract the URL and description from `llms.txt` (https://docs.pydantic.dev/latest/llms.txt).\n",
    "- Save the extracted data to Supabase.\n",
    "\n",
    "## 2. Retrieve Document List\n",
    "1. Load the extracted URLs and descriptions, and convert them into `Document` objects.\n",
    "2. Generate embeddings and select relevant URLs by performing a similarity check with the user query.\n",
    "3. Chunk each selected URL into manageable pieces.\n",
    "\n",
    "## 3. Fetch Web Pages\n",
    "- Fetch the content of each selected URL and retrieve the main body text for each.\n",
    "\n",
    "## 4. Context Filtering\n",
    "- Finally, perform a similarity check between the user query and the content of each URL, filtering the contexts to retain only the most relevant ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/alias/index.md', 'description': 'Alias', 'time': '2025-07-01T19:49:46.868847'}, {'id': 2, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/config/index.md', 'description': 'Configuration', 'time': '2025-07-01T19:49:47.655498'}, {'id': 3, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/conversion_table/index.md', 'description': 'Conversion Table', 'time': '2025-07-01T19:49:47.731734'}, {'id': 4, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/dataclasses/index.md', 'description': 'Dataclasses', 'time': '2025-07-01T19:49:47.819167'}, {'id': 5, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/experimental/index.md', 'description': 'Experimental', 'time': '2025-07-01T19:49:47.920196'}, {'id': 6, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/fields/index.md', 'description': 'Fields', 'time': '2025-07-01T19:49:47.992421'}, {'id': 7, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/forward_annotations/index.md', 'description': 'Forward Annotations', 'time': '2025-07-01T19:49:48.058807'}, {'id': 8, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/json/index.md', 'description': 'JSON', 'time': '2025-07-01T19:49:48.125987'}, {'id': 9, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/json_schema/index.md', 'description': 'JSON Schema', 'time': '2025-07-01T19:49:48.225335'}, {'id': 10, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/models/index.md', 'description': 'Models', 'time': '2025-07-01T19:49:48.290176'}, {'id': 11, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/performance/index.md', 'description': 'Performance', 'time': '2025-07-01T19:49:48.353769'}, {'id': 12, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/pydantic_settings/index.md', 'description': 'Settings Management', 'time': '2025-07-01T19:49:48.414623'}, {'id': 13, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/serialization/index.md', 'description': 'Serialization', 'time': '2025-07-01T19:49:48.488251'}, {'id': 14, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/strict_mode/index.md', 'description': 'Strict Mode', 'time': '2025-07-01T19:49:48.576129'}, {'id': 15, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/type_adapter/index.md', 'description': 'Type Adapter', 'time': '2025-07-01T19:49:48.655649'}, {'id': 16, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/types/index.md', 'description': 'Types', 'time': '2025-07-01T19:49:48.726817'}, {'id': 17, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/unions/index.md', 'description': 'Unions', 'time': '2025-07-01T19:49:48.790849'}, {'id': 18, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/validation_decorator/index.md', 'description': 'Validation Decorator', 'time': '2025-07-01T19:49:48.925773'}, {'id': 19, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/concepts/validators/index.md', 'description': 'Validators', 'time': '2025-07-01T19:49:48.996839'}, {'id': 20, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/aliases/index.md', 'description': 'Aliases', 'time': '2025-07-01T19:49:49.066174'}, {'id': 21, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/annotated_handlers/index.md', 'description': 'Annotated Handlers', 'time': '2025-07-01T19:49:49.130138'}, {'id': 22, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/base_model/index.md', 'description': 'BaseModel', 'time': '2025-07-01T19:49:49.204192'}, {'id': 23, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/config/index.md', 'description': 'Configuration', 'time': '2025-07-01T19:49:49.274695'}, {'id': 24, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md', 'description': 'Pydantic Dataclasses', 'time': '2025-07-01T19:49:49.340694'}, {'id': 25, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/errors/index.md', 'description': 'Errors', 'time': '2025-07-01T19:49:49.418173'}, {'id': 26, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/experimental/index.md', 'description': 'Experimental', 'time': '2025-07-01T19:49:49.485446'}, {'id': 27, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/fields/index.md', 'description': 'Fields', 'time': '2025-07-01T19:49:49.559946'}, {'id': 28, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/functional_serializers/index.md', 'description': 'Functional Serializers', 'time': '2025-07-01T19:49:49.663297'}, {'id': 29, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/functional_validators/index.md', 'description': 'Functional Validators', 'time': '2025-07-01T19:49:49.734852'}, {'id': 30, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/json_schema/index.md', 'description': 'JSON Schema', 'time': '2025-07-01T19:49:49.808435'}, {'id': 31, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/networks/index.md', 'description': 'Network Types', 'time': '2025-07-01T19:49:49.870195'}, {'id': 32, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_core/index.md', 'description': 'pydantic_core', 'time': '2025-07-01T19:49:49.938969'}, {'id': 33, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_core_schema/index.md', 'description': 'pydantic_core.core_schema', 'time': '2025-07-01T19:49:50.013334'}, {'id': 34, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_color/index.md', 'description': 'Color', 'time': '2025-07-01T19:49:50.07987'}, {'id': 35, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_coordinate/index.md', 'description': 'Coordinate', 'time': '2025-07-01T19:49:50.165116'}, {'id': 36, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_country/index.md', 'description': 'Country', 'time': '2025-07-01T19:49:50.249486'}, {'id': 37, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_currency_code/index.md', 'description': 'Currency', 'time': '2025-07-01T19:49:50.311279'}, {'id': 38, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_isbn/index.md', 'description': 'ISBN', 'time': '2025-07-01T19:49:50.380702'}, {'id': 39, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_language_code/index.md', 'description': 'Language', 'time': '2025-07-01T19:49:50.452004'}, {'id': 40, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_mac_address/index.md', 'description': 'Mac Address', 'time': '2025-07-01T19:49:50.521105'}, {'id': 41, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_payment/index.md', 'description': 'Payment', 'time': '2025-07-01T19:49:50.622171'}, {'id': 42, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_pendulum_dt/index.md', 'description': 'Pendulum', 'time': '2025-07-01T19:49:50.69479'}, {'id': 43, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_phone_numbers/index.md', 'description': 'Phone Numbers', 'time': '2025-07-01T19:49:50.776486'}, {'id': 44, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_routing_numbers/index.md', 'description': 'Routing Numbers', 'time': '2025-07-01T19:49:50.873857'}, {'id': 45, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_script_code/index.md', 'description': 'Script Code', 'time': '2025-07-01T19:49:50.945765'}, {'id': 46, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_semantic_version/index.md', 'description': 'Semantic Version', 'time': '2025-07-01T19:49:51.006896'}, {'id': 47, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_timezone_name/index.md', 'description': 'Timezone Name', 'time': '2025-07-01T19:49:51.072657'}, {'id': 48, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_ulid/index.md', 'description': 'ULID', 'time': '2025-07-01T19:49:51.137899'}, {'id': 49, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/pydantic_settings/index.md', 'description': 'Pydantic Settings', 'time': '2025-07-01T19:49:51.201083'}, {'id': 50, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/root_model/index.md', 'description': 'RootModel', 'time': '2025-07-01T19:49:51.276357'}, {'id': 51, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/standard_library_types/index.md', 'description': 'Standard Library Types', 'time': '2025-07-01T19:49:51.355744'}, {'id': 52, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/type_adapter/index.md', 'description': 'TypeAdapter', 'time': '2025-07-01T19:49:51.430648'}, {'id': 53, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/types/index.md', 'description': 'Pydantic Types', 'time': '2025-07-01T19:49:51.515827'}, {'id': 54, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/validate_call/index.md', 'description': 'Validate Call', 'time': '2025-07-01T19:49:51.579219'}, {'id': 55, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/api/version/index.md', 'description': 'Version Information', 'time': '2025-07-01T19:49:51.668098'}, {'id': 56, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/internals/architecture/index.md', 'description': 'Architecture', 'time': '2025-07-01T19:49:51.742148'}, {'id': 57, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/internals/resolving_annotations/index.md', 'description': 'Resolving Annotations', 'time': '2025-07-01T19:49:51.812071'}, {'id': 58, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/errors/errors/index.md', 'description': 'Error Handling', 'time': '2025-07-01T19:49:51.8882'}, {'id': 59, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/errors/usage_errors/index.md', 'description': 'Usage Errors', 'time': '2025-07-01T19:49:51.953184'}, {'id': 60, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/errors/validation_errors/index.md', 'description': 'Validation Errors', 'time': '2025-07-01T19:49:52.027999'}, {'id': 61, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/examples/custom_validators/index.md', 'description': 'Custom Validators', 'time': '2025-07-01T19:49:52.102382'}, {'id': 62, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/examples/files/index.md', 'description': 'Validating File Data', 'time': '2025-07-01T19:49:52.179188'}, {'id': 63, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/examples/orms/index.md', 'description': 'Databases', 'time': '2025-07-01T19:49:52.278554'}, {'id': 64, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/examples/queues/index.md', 'description': 'Queues', 'time': '2025-07-01T19:49:52.350971'}, {'id': 65, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/examples/requests/index.md', 'description': 'Web and API Requests', 'time': '2025-07-01T19:49:52.448753'}, {'id': 66, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/aws_lambda/index.md', 'description': 'AWS Lambda', 'time': '2025-07-01T19:49:52.528225'}, {'id': 67, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/datamodel_code_generator/index.md', 'description': 'datamodel-code-generator', 'time': '2025-07-01T19:49:52.62004'}, {'id': 68, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/devtools/index.md', 'description': 'devtools', 'time': '2025-07-01T19:49:52.724758'}, {'id': 69, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/documentation/index.md', 'description': 'Documentation', 'time': '2025-07-01T19:49:52.820293'}, {'id': 70, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/hypothesis/index.md', 'description': 'Hypothesis', 'time': '2025-07-01T19:49:52.894752'}, {'id': 71, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/linting/index.md', 'description': 'Linting', 'time': '2025-07-01T19:49:52.974199'}, {'id': 72, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/llms/index.md', 'description': 'LLMs', 'time': '2025-07-01T19:49:53.061438'}, {'id': 73, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/logfire/index.md', 'description': 'Pydantic Logfire', 'time': '2025-07-01T19:49:53.136089'}, {'id': 74, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/mypy/index.md', 'description': 'Mypy', 'time': '2025-07-01T19:49:53.227894'}, {'id': 75, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/pycharm/index.md', 'description': 'PyCharm', 'time': '2025-07-01T19:49:53.295295'}, {'id': 76, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/rich/index.md', 'description': 'Rich', 'time': '2025-07-01T19:49:53.356809'}, {'id': 77, 'source_url': 'https://docs.pydantic.dev/latest/llms.txt', 'url': 'https://docs.pydantic.dev/latest/integrations/visual_studio_code/index.md', 'description': 'Visual Studio Code', 'time': '2025-07-01T19:49:53.435591'}]\n"
     ]
    }
   ],
   "source": [
    "# load env variables \n",
    "load_dotenv()\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "\n",
    "# Set supabase client \n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "\n",
    "# load data from supabase database\n",
    "response = supabase.table(\"pydantic_docs_llms\").select(\"*\").execute()\n",
    "data = response.data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/alias/index.md',\n",
       "  'description': 'Alias',\n",
       "  'time': '2025-07-01T19:49:46.868847'},\n",
       " {'id': 2,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/config/index.md',\n",
       "  'description': 'Configuration',\n",
       "  'time': '2025-07-01T19:49:47.655498'},\n",
       " {'id': 3,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/conversion_table/index.md',\n",
       "  'description': 'Conversion Table',\n",
       "  'time': '2025-07-01T19:49:47.731734'},\n",
       " {'id': 4,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/dataclasses/index.md',\n",
       "  'description': 'Dataclasses',\n",
       "  'time': '2025-07-01T19:49:47.819167'},\n",
       " {'id': 5,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/experimental/index.md',\n",
       "  'description': 'Experimental',\n",
       "  'time': '2025-07-01T19:49:47.920196'},\n",
       " {'id': 6,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/fields/index.md',\n",
       "  'description': 'Fields',\n",
       "  'time': '2025-07-01T19:49:47.992421'},\n",
       " {'id': 7,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/forward_annotations/index.md',\n",
       "  'description': 'Forward Annotations',\n",
       "  'time': '2025-07-01T19:49:48.058807'},\n",
       " {'id': 8,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/json/index.md',\n",
       "  'description': 'JSON',\n",
       "  'time': '2025-07-01T19:49:48.125987'},\n",
       " {'id': 9,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/json_schema/index.md',\n",
       "  'description': 'JSON Schema',\n",
       "  'time': '2025-07-01T19:49:48.225335'},\n",
       " {'id': 10,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/models/index.md',\n",
       "  'description': 'Models',\n",
       "  'time': '2025-07-01T19:49:48.290176'},\n",
       " {'id': 11,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/performance/index.md',\n",
       "  'description': 'Performance',\n",
       "  'time': '2025-07-01T19:49:48.353769'},\n",
       " {'id': 12,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/pydantic_settings/index.md',\n",
       "  'description': 'Settings Management',\n",
       "  'time': '2025-07-01T19:49:48.414623'},\n",
       " {'id': 13,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/serialization/index.md',\n",
       "  'description': 'Serialization',\n",
       "  'time': '2025-07-01T19:49:48.488251'},\n",
       " {'id': 14,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/strict_mode/index.md',\n",
       "  'description': 'Strict Mode',\n",
       "  'time': '2025-07-01T19:49:48.576129'},\n",
       " {'id': 15,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/type_adapter/index.md',\n",
       "  'description': 'Type Adapter',\n",
       "  'time': '2025-07-01T19:49:48.655649'},\n",
       " {'id': 16,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/types/index.md',\n",
       "  'description': 'Types',\n",
       "  'time': '2025-07-01T19:49:48.726817'},\n",
       " {'id': 17,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/unions/index.md',\n",
       "  'description': 'Unions',\n",
       "  'time': '2025-07-01T19:49:48.790849'},\n",
       " {'id': 18,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/validation_decorator/index.md',\n",
       "  'description': 'Validation Decorator',\n",
       "  'time': '2025-07-01T19:49:48.925773'},\n",
       " {'id': 19,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/concepts/validators/index.md',\n",
       "  'description': 'Validators',\n",
       "  'time': '2025-07-01T19:49:48.996839'},\n",
       " {'id': 20,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/aliases/index.md',\n",
       "  'description': 'Aliases',\n",
       "  'time': '2025-07-01T19:49:49.066174'},\n",
       " {'id': 21,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/annotated_handlers/index.md',\n",
       "  'description': 'Annotated Handlers',\n",
       "  'time': '2025-07-01T19:49:49.130138'},\n",
       " {'id': 22,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/base_model/index.md',\n",
       "  'description': 'BaseModel',\n",
       "  'time': '2025-07-01T19:49:49.204192'},\n",
       " {'id': 23,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/config/index.md',\n",
       "  'description': 'Configuration',\n",
       "  'time': '2025-07-01T19:49:49.274695'},\n",
       " {'id': 24,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md',\n",
       "  'description': 'Pydantic Dataclasses',\n",
       "  'time': '2025-07-01T19:49:49.340694'},\n",
       " {'id': 25,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/errors/index.md',\n",
       "  'description': 'Errors',\n",
       "  'time': '2025-07-01T19:49:49.418173'},\n",
       " {'id': 26,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/experimental/index.md',\n",
       "  'description': 'Experimental',\n",
       "  'time': '2025-07-01T19:49:49.485446'},\n",
       " {'id': 27,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/fields/index.md',\n",
       "  'description': 'Fields',\n",
       "  'time': '2025-07-01T19:49:49.559946'},\n",
       " {'id': 28,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/functional_serializers/index.md',\n",
       "  'description': 'Functional Serializers',\n",
       "  'time': '2025-07-01T19:49:49.663297'},\n",
       " {'id': 29,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/functional_validators/index.md',\n",
       "  'description': 'Functional Validators',\n",
       "  'time': '2025-07-01T19:49:49.734852'},\n",
       " {'id': 30,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/json_schema/index.md',\n",
       "  'description': 'JSON Schema',\n",
       "  'time': '2025-07-01T19:49:49.808435'},\n",
       " {'id': 31,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/networks/index.md',\n",
       "  'description': 'Network Types',\n",
       "  'time': '2025-07-01T19:49:49.870195'},\n",
       " {'id': 32,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_core/index.md',\n",
       "  'description': 'pydantic_core',\n",
       "  'time': '2025-07-01T19:49:49.938969'},\n",
       " {'id': 33,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_core_schema/index.md',\n",
       "  'description': 'pydantic_core.core_schema',\n",
       "  'time': '2025-07-01T19:49:50.013334'},\n",
       " {'id': 34,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_color/index.md',\n",
       "  'description': 'Color',\n",
       "  'time': '2025-07-01T19:49:50.07987'},\n",
       " {'id': 35,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_coordinate/index.md',\n",
       "  'description': 'Coordinate',\n",
       "  'time': '2025-07-01T19:49:50.165116'},\n",
       " {'id': 36,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_country/index.md',\n",
       "  'description': 'Country',\n",
       "  'time': '2025-07-01T19:49:50.249486'},\n",
       " {'id': 37,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_currency_code/index.md',\n",
       "  'description': 'Currency',\n",
       "  'time': '2025-07-01T19:49:50.311279'},\n",
       " {'id': 38,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_isbn/index.md',\n",
       "  'description': 'ISBN',\n",
       "  'time': '2025-07-01T19:49:50.380702'},\n",
       " {'id': 39,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_language_code/index.md',\n",
       "  'description': 'Language',\n",
       "  'time': '2025-07-01T19:49:50.452004'},\n",
       " {'id': 40,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_mac_address/index.md',\n",
       "  'description': 'Mac Address',\n",
       "  'time': '2025-07-01T19:49:50.521105'},\n",
       " {'id': 41,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_payment/index.md',\n",
       "  'description': 'Payment',\n",
       "  'time': '2025-07-01T19:49:50.622171'},\n",
       " {'id': 42,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_pendulum_dt/index.md',\n",
       "  'description': 'Pendulum',\n",
       "  'time': '2025-07-01T19:49:50.69479'},\n",
       " {'id': 43,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_phone_numbers/index.md',\n",
       "  'description': 'Phone Numbers',\n",
       "  'time': '2025-07-01T19:49:50.776486'},\n",
       " {'id': 44,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_routing_numbers/index.md',\n",
       "  'description': 'Routing Numbers',\n",
       "  'time': '2025-07-01T19:49:50.873857'},\n",
       " {'id': 45,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_script_code/index.md',\n",
       "  'description': 'Script Code',\n",
       "  'time': '2025-07-01T19:49:50.945765'},\n",
       " {'id': 46,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_semantic_version/index.md',\n",
       "  'description': 'Semantic Version',\n",
       "  'time': '2025-07-01T19:49:51.006896'},\n",
       " {'id': 47,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_timezone_name/index.md',\n",
       "  'description': 'Timezone Name',\n",
       "  'time': '2025-07-01T19:49:51.072657'},\n",
       " {'id': 48,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_extra_types_ulid/index.md',\n",
       "  'description': 'ULID',\n",
       "  'time': '2025-07-01T19:49:51.137899'},\n",
       " {'id': 49,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/pydantic_settings/index.md',\n",
       "  'description': 'Pydantic Settings',\n",
       "  'time': '2025-07-01T19:49:51.201083'},\n",
       " {'id': 50,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/root_model/index.md',\n",
       "  'description': 'RootModel',\n",
       "  'time': '2025-07-01T19:49:51.276357'},\n",
       " {'id': 51,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/standard_library_types/index.md',\n",
       "  'description': 'Standard Library Types',\n",
       "  'time': '2025-07-01T19:49:51.355744'},\n",
       " {'id': 52,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/type_adapter/index.md',\n",
       "  'description': 'TypeAdapter',\n",
       "  'time': '2025-07-01T19:49:51.430648'},\n",
       " {'id': 53,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/types/index.md',\n",
       "  'description': 'Pydantic Types',\n",
       "  'time': '2025-07-01T19:49:51.515827'},\n",
       " {'id': 54,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/validate_call/index.md',\n",
       "  'description': 'Validate Call',\n",
       "  'time': '2025-07-01T19:49:51.579219'},\n",
       " {'id': 55,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/version/index.md',\n",
       "  'description': 'Version Information',\n",
       "  'time': '2025-07-01T19:49:51.668098'},\n",
       " {'id': 56,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/internals/architecture/index.md',\n",
       "  'description': 'Architecture',\n",
       "  'time': '2025-07-01T19:49:51.742148'},\n",
       " {'id': 57,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/internals/resolving_annotations/index.md',\n",
       "  'description': 'Resolving Annotations',\n",
       "  'time': '2025-07-01T19:49:51.812071'},\n",
       " {'id': 58,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/errors/errors/index.md',\n",
       "  'description': 'Error Handling',\n",
       "  'time': '2025-07-01T19:49:51.8882'},\n",
       " {'id': 59,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/errors/usage_errors/index.md',\n",
       "  'description': 'Usage Errors',\n",
       "  'time': '2025-07-01T19:49:51.953184'},\n",
       " {'id': 60,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/errors/validation_errors/index.md',\n",
       "  'description': 'Validation Errors',\n",
       "  'time': '2025-07-01T19:49:52.027999'},\n",
       " {'id': 61,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/examples/custom_validators/index.md',\n",
       "  'description': 'Custom Validators',\n",
       "  'time': '2025-07-01T19:49:52.102382'},\n",
       " {'id': 62,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/examples/files/index.md',\n",
       "  'description': 'Validating File Data',\n",
       "  'time': '2025-07-01T19:49:52.179188'},\n",
       " {'id': 63,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/examples/orms/index.md',\n",
       "  'description': 'Databases',\n",
       "  'time': '2025-07-01T19:49:52.278554'},\n",
       " {'id': 64,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/examples/queues/index.md',\n",
       "  'description': 'Queues',\n",
       "  'time': '2025-07-01T19:49:52.350971'},\n",
       " {'id': 65,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/examples/requests/index.md',\n",
       "  'description': 'Web and API Requests',\n",
       "  'time': '2025-07-01T19:49:52.448753'},\n",
       " {'id': 66,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/aws_lambda/index.md',\n",
       "  'description': 'AWS Lambda',\n",
       "  'time': '2025-07-01T19:49:52.528225'},\n",
       " {'id': 67,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/datamodel_code_generator/index.md',\n",
       "  'description': 'datamodel-code-generator',\n",
       "  'time': '2025-07-01T19:49:52.62004'},\n",
       " {'id': 68,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/devtools/index.md',\n",
       "  'description': 'devtools',\n",
       "  'time': '2025-07-01T19:49:52.724758'},\n",
       " {'id': 69,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/documentation/index.md',\n",
       "  'description': 'Documentation',\n",
       "  'time': '2025-07-01T19:49:52.820293'},\n",
       " {'id': 70,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/hypothesis/index.md',\n",
       "  'description': 'Hypothesis',\n",
       "  'time': '2025-07-01T19:49:52.894752'},\n",
       " {'id': 71,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/linting/index.md',\n",
       "  'description': 'Linting',\n",
       "  'time': '2025-07-01T19:49:52.974199'},\n",
       " {'id': 72,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/llms/index.md',\n",
       "  'description': 'LLMs',\n",
       "  'time': '2025-07-01T19:49:53.061438'},\n",
       " {'id': 73,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/logfire/index.md',\n",
       "  'description': 'Pydantic Logfire',\n",
       "  'time': '2025-07-01T19:49:53.136089'},\n",
       " {'id': 74,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/mypy/index.md',\n",
       "  'description': 'Mypy',\n",
       "  'time': '2025-07-01T19:49:53.227894'},\n",
       " {'id': 75,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/pycharm/index.md',\n",
       "  'description': 'PyCharm',\n",
       "  'time': '2025-07-01T19:49:53.295295'},\n",
       " {'id': 76,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/rich/index.md',\n",
       "  'description': 'Rich',\n",
       "  'time': '2025-07-01T19:49:53.356809'},\n",
       " {'id': 77,\n",
       "  'source_url': 'https://docs.pydantic.dev/latest/llms.txt',\n",
       "  'url': 'https://docs.pydantic.dev/latest/integrations/visual_studio_code/index.md',\n",
       "  'description': 'Visual Studio Code',\n",
       "  'time': '2025-07-01T19:49:53.435591'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve Document List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Document objects from data\n",
    "document = []\n",
    "for i in data:\n",
    "    doc = Document(page_content=i[\"url\"], metadata={\"description\": i[\"description\"]})\n",
    "    document.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Alias'}, page_content='https://docs.pydantic.dev/latest/concepts/alias/index.md'),\n",
       " Document(metadata={'description': 'Configuration'}, page_content='https://docs.pydantic.dev/latest/concepts/config/index.md'),\n",
       " Document(metadata={'description': 'Conversion Table'}, page_content='https://docs.pydantic.dev/latest/concepts/conversion_table/index.md'),\n",
       " Document(metadata={'description': 'Dataclasses'}, page_content='https://docs.pydantic.dev/latest/concepts/dataclasses/index.md'),\n",
       " Document(metadata={'description': 'Experimental'}, page_content='https://docs.pydantic.dev/latest/concepts/experimental/index.md'),\n",
       " Document(metadata={'description': 'Fields'}, page_content='https://docs.pydantic.dev/latest/concepts/fields/index.md'),\n",
       " Document(metadata={'description': 'Forward Annotations'}, page_content='https://docs.pydantic.dev/latest/concepts/forward_annotations/index.md'),\n",
       " Document(metadata={'description': 'JSON'}, page_content='https://docs.pydantic.dev/latest/concepts/json/index.md'),\n",
       " Document(metadata={'description': 'JSON Schema'}, page_content='https://docs.pydantic.dev/latest/concepts/json_schema/index.md'),\n",
       " Document(metadata={'description': 'Models'}, page_content='https://docs.pydantic.dev/latest/concepts/models/index.md'),\n",
       " Document(metadata={'description': 'Performance'}, page_content='https://docs.pydantic.dev/latest/concepts/performance/index.md'),\n",
       " Document(metadata={'description': 'Settings Management'}, page_content='https://docs.pydantic.dev/latest/concepts/pydantic_settings/index.md'),\n",
       " Document(metadata={'description': 'Serialization'}, page_content='https://docs.pydantic.dev/latest/concepts/serialization/index.md'),\n",
       " Document(metadata={'description': 'Strict Mode'}, page_content='https://docs.pydantic.dev/latest/concepts/strict_mode/index.md'),\n",
       " Document(metadata={'description': 'Type Adapter'}, page_content='https://docs.pydantic.dev/latest/concepts/type_adapter/index.md'),\n",
       " Document(metadata={'description': 'Types'}, page_content='https://docs.pydantic.dev/latest/concepts/types/index.md'),\n",
       " Document(metadata={'description': 'Unions'}, page_content='https://docs.pydantic.dev/latest/concepts/unions/index.md'),\n",
       " Document(metadata={'description': 'Validation Decorator'}, page_content='https://docs.pydantic.dev/latest/concepts/validation_decorator/index.md'),\n",
       " Document(metadata={'description': 'Validators'}, page_content='https://docs.pydantic.dev/latest/concepts/validators/index.md'),\n",
       " Document(metadata={'description': 'Aliases'}, page_content='https://docs.pydantic.dev/latest/api/aliases/index.md'),\n",
       " Document(metadata={'description': 'Annotated Handlers'}, page_content='https://docs.pydantic.dev/latest/api/annotated_handlers/index.md'),\n",
       " Document(metadata={'description': 'BaseModel'}, page_content='https://docs.pydantic.dev/latest/api/base_model/index.md'),\n",
       " Document(metadata={'description': 'Configuration'}, page_content='https://docs.pydantic.dev/latest/api/config/index.md'),\n",
       " Document(metadata={'description': 'Pydantic Dataclasses'}, page_content='https://docs.pydantic.dev/latest/api/dataclasses/index.md'),\n",
       " Document(metadata={'description': 'Errors'}, page_content='https://docs.pydantic.dev/latest/api/errors/index.md'),\n",
       " Document(metadata={'description': 'Experimental'}, page_content='https://docs.pydantic.dev/latest/api/experimental/index.md'),\n",
       " Document(metadata={'description': 'Fields'}, page_content='https://docs.pydantic.dev/latest/api/fields/index.md'),\n",
       " Document(metadata={'description': 'Functional Serializers'}, page_content='https://docs.pydantic.dev/latest/api/functional_serializers/index.md'),\n",
       " Document(metadata={'description': 'Functional Validators'}, page_content='https://docs.pydantic.dev/latest/api/functional_validators/index.md'),\n",
       " Document(metadata={'description': 'JSON Schema'}, page_content='https://docs.pydantic.dev/latest/api/json_schema/index.md'),\n",
       " Document(metadata={'description': 'Network Types'}, page_content='https://docs.pydantic.dev/latest/api/networks/index.md'),\n",
       " Document(metadata={'description': 'pydantic_core'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_core/index.md'),\n",
       " Document(metadata={'description': 'pydantic_core.core_schema'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_core_schema/index.md'),\n",
       " Document(metadata={'description': 'Color'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_color/index.md'),\n",
       " Document(metadata={'description': 'Coordinate'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_coordinate/index.md'),\n",
       " Document(metadata={'description': 'Country'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_country/index.md'),\n",
       " Document(metadata={'description': 'Currency'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_currency_code/index.md'),\n",
       " Document(metadata={'description': 'ISBN'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_isbn/index.md'),\n",
       " Document(metadata={'description': 'Language'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_language_code/index.md'),\n",
       " Document(metadata={'description': 'Mac Address'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_mac_address/index.md'),\n",
       " Document(metadata={'description': 'Payment'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_payment/index.md'),\n",
       " Document(metadata={'description': 'Pendulum'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_pendulum_dt/index.md'),\n",
       " Document(metadata={'description': 'Phone Numbers'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_phone_numbers/index.md'),\n",
       " Document(metadata={'description': 'Routing Numbers'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_routing_numbers/index.md'),\n",
       " Document(metadata={'description': 'Script Code'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_script_code/index.md'),\n",
       " Document(metadata={'description': 'Semantic Version'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_semantic_version/index.md'),\n",
       " Document(metadata={'description': 'Timezone Name'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_timezone_name/index.md'),\n",
       " Document(metadata={'description': 'ULID'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_extra_types_ulid/index.md'),\n",
       " Document(metadata={'description': 'Pydantic Settings'}, page_content='https://docs.pydantic.dev/latest/api/pydantic_settings/index.md'),\n",
       " Document(metadata={'description': 'RootModel'}, page_content='https://docs.pydantic.dev/latest/api/root_model/index.md'),\n",
       " Document(metadata={'description': 'Standard Library Types'}, page_content='https://docs.pydantic.dev/latest/api/standard_library_types/index.md'),\n",
       " Document(metadata={'description': 'TypeAdapter'}, page_content='https://docs.pydantic.dev/latest/api/type_adapter/index.md'),\n",
       " Document(metadata={'description': 'Pydantic Types'}, page_content='https://docs.pydantic.dev/latest/api/types/index.md'),\n",
       " Document(metadata={'description': 'Validate Call'}, page_content='https://docs.pydantic.dev/latest/api/validate_call/index.md'),\n",
       " Document(metadata={'description': 'Version Information'}, page_content='https://docs.pydantic.dev/latest/api/version/index.md'),\n",
       " Document(metadata={'description': 'Architecture'}, page_content='https://docs.pydantic.dev/latest/internals/architecture/index.md'),\n",
       " Document(metadata={'description': 'Resolving Annotations'}, page_content='https://docs.pydantic.dev/latest/internals/resolving_annotations/index.md'),\n",
       " Document(metadata={'description': 'Error Handling'}, page_content='https://docs.pydantic.dev/latest/errors/errors/index.md'),\n",
       " Document(metadata={'description': 'Usage Errors'}, page_content='https://docs.pydantic.dev/latest/errors/usage_errors/index.md'),\n",
       " Document(metadata={'description': 'Validation Errors'}, page_content='https://docs.pydantic.dev/latest/errors/validation_errors/index.md'),\n",
       " Document(metadata={'description': 'Custom Validators'}, page_content='https://docs.pydantic.dev/latest/examples/custom_validators/index.md'),\n",
       " Document(metadata={'description': 'Validating File Data'}, page_content='https://docs.pydantic.dev/latest/examples/files/index.md'),\n",
       " Document(metadata={'description': 'Databases'}, page_content='https://docs.pydantic.dev/latest/examples/orms/index.md'),\n",
       " Document(metadata={'description': 'Queues'}, page_content='https://docs.pydantic.dev/latest/examples/queues/index.md'),\n",
       " Document(metadata={'description': 'Web and API Requests'}, page_content='https://docs.pydantic.dev/latest/examples/requests/index.md'),\n",
       " Document(metadata={'description': 'AWS Lambda'}, page_content='https://docs.pydantic.dev/latest/integrations/aws_lambda/index.md'),\n",
       " Document(metadata={'description': 'datamodel-code-generator'}, page_content='https://docs.pydantic.dev/latest/integrations/datamodel_code_generator/index.md'),\n",
       " Document(metadata={'description': 'devtools'}, page_content='https://docs.pydantic.dev/latest/integrations/devtools/index.md'),\n",
       " Document(metadata={'description': 'Documentation'}, page_content='https://docs.pydantic.dev/latest/integrations/documentation/index.md'),\n",
       " Document(metadata={'description': 'Hypothesis'}, page_content='https://docs.pydantic.dev/latest/integrations/hypothesis/index.md'),\n",
       " Document(metadata={'description': 'Linting'}, page_content='https://docs.pydantic.dev/latest/integrations/linting/index.md'),\n",
       " Document(metadata={'description': 'LLMs'}, page_content='https://docs.pydantic.dev/latest/integrations/llms/index.md'),\n",
       " Document(metadata={'description': 'Pydantic Logfire'}, page_content='https://docs.pydantic.dev/latest/integrations/logfire/index.md'),\n",
       " Document(metadata={'description': 'Mypy'}, page_content='https://docs.pydantic.dev/latest/integrations/mypy/index.md'),\n",
       " Document(metadata={'description': 'PyCharm'}, page_content='https://docs.pydantic.dev/latest/integrations/pycharm/index.md'),\n",
       " Document(metadata={'description': 'Rich'}, page_content='https://docs.pydantic.dev/latest/integrations/rich/index.md'),\n",
       " Document(metadata={'description': 'Visual Studio Code'}, page_content='https://docs.pydantic.dev/latest/integrations/visual_studio_code/index.md')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 리스트 조회\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create VectorDB\n",
    "vectorstore = FAISS.from_documents(documents=document, embedding=embeddings)\n",
    "\n",
    "# Set Retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.pydantic.dev/latest/api/fields/index.md\n",
      "https://docs.pydantic.dev/latest/concepts/fields/index.md\n",
      "https://docs.pydantic.dev/latest/concepts/dataclasses/index.md\n",
      "https://docs.pydantic.dev/latest/api/dataclasses/index.md\n"
     ]
    }
   ],
   "source": [
    "# vector similarity search\n",
    "filtered_urls = []\n",
    "for doc in vectorstore.similarity_search(\"What is the Fields class?\"):\n",
    "    filtered_urls.append(doc.page_content)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Web Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # 본문만 추출 (사이트 구조에 따라 조정 필요)\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract text from filtered URLs\n",
    "page_texts = []\n",
    "for url in filtered_urls:\n",
    "    text = fetch_page_text(url)\n",
    "    page_texts.append({\"url\": url, \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://docs.pydantic.dev/latest/api/fields/index.md',\n",
       "  'text': 'Defining fields on models.\\n\\n## Field\\n\\n```python\\nField(\\n    default: ellipsis,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: _T,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    default_factory: (\\n        Callable[[], _T] | Callable[[dict[str, Any]], _T]\\n    ),\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: (\\n        Callable[[], Any]\\n        | Callable[[dict[str, Any]], Any]\\n        | None\\n    ) = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Fields](../../concepts/fields/)\\n\\nCreate a field for objects that can be configured.\\n\\nUsed to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\nNote\\n\\n- Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | Default value if the field is not set. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | `_Unset` | | `alias` | `str | None` | The name to use for the attribute when validating or serializing by alias. This is often used for things like converting between snake and camel case. | `_Unset` | | `alias_priority` | `int | None` | Priority of the alias. This affects whether an alias generator is used. | `_Unset` | | `validation_alias` | `str | AliasPath | AliasChoices | None` | Like alias, but only affects validation, not serialization. | `_Unset` | | `serialization_alias` | `str | None` | Like alias, but only affects serialization, not validation. | `_Unset` | | `title` | `str | None` | Human-readable title. | `_Unset` | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `_Unset` | | `description` | `str | None` | Human-readable description. | `_Unset` | | `examples` | `list[Any] | None` | Example values for this field. | `_Unset` | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | `_Unset` | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | `_Unset` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | `_Unset` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `_Unset` | | `frozen` | `bool | None` | Whether the field is frozen. If true, attempts to change the value on an instance will raise an error. | `_Unset` | | `validate_default` | `bool | None` | If True, apply validation to the default value every time you create an instance. Otherwise, for performance reasons, the default value of the field is trusted and not validated. | `_Unset` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `_Unset` | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `coerce_numbers_to_str` | `bool | None` | Whether to enable coercion of any Number type to str (not applicable in strict mode). | `_Unset` | | `strict` | `bool | None` | If True, strict validation is applied to the field. See Strict Mode for details. | `_Unset` | | `gt` | `SupportsGt | None` | Greater than. If set, value must be greater than this. Only applicable to numbers. | `_Unset` | | `ge` | `SupportsGe | None` | Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers. | `_Unset` | | `lt` | `SupportsLt | None` | Less than. If set, value must be less than this. Only applicable to numbers. | `_Unset` | | `le` | `SupportsLe | None` | Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers. | `_Unset` | | `multiple_of` | `float | None` | Value must be a multiple of this. Only applicable to numbers. | `_Unset` | | `min_length` | `int | None` | Minimum length for iterables. | `_Unset` | | `max_length` | `int | None` | Maximum length for iterables. | `_Unset` | | `pattern` | `str | Pattern[str] | None` | Pattern for strings (a regular expression). | `_Unset` | | `allow_inf_nan` | `bool | None` | Allow inf, -inf, nan. Only applicable to float and Decimal numbers. | `_Unset` | | `max_digits` | `int | None` | Maximum number of allow digits for strings. | `_Unset` | | `decimal_places` | `int | None` | Maximum number of decimal places allowed for numbers. | `_Unset` | | `union_mode` | `Literal[\\'smart\\', \\'left_to_right\\']` | The strategy to apply when validating a union. Can be smart (the default), or left_to_right. See Union Mode for details. | `_Unset` | | `fail_fast` | `bool | None` | If True, validation will stop on the first error. If False, all validation errors will be collected. This option can be applied only to iterable types (list, tuple, set, and frozenset). | `_Unset` | | `extra` | `Unpack[_EmptyKwargs]` | (Deprecated) Extra fields that will be included in the JSON schema. Warning The extra kwargs is deprecated. Use json_schema_extra instead. | `{}` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | A new FieldInfo. The return annotation is Any so Field can be used on type-annotated fields without causing a type error. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef Field(  # noqa: C901\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | Callable[[dict[str, Any]], Any] | None = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: str | AliasPath | AliasChoices | None = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: Callable[[str, FieldInfo], str] | None = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | types.Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: JsonDict | Callable[[JsonDict], None] | None = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | typing.Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: annotated_types.SupportsGt | None = _Unset,\\n    ge: annotated_types.SupportsGe | None = _Unset,\\n    lt: annotated_types.SupportsLt | None = _Unset,\\n    le: annotated_types.SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\\'smart\\', \\'left_to_right\\'] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs],\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Fields](../concepts/fields.md)\\n\\n    Create a field for objects that can be configured.\\n\\n    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\\n    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\n    Note:\\n        - Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\n    Args:\\n        default: Default value if the field is not set.\\n        default_factory: A callable to generate the default value. The callable can either take 0 arguments\\n            (in which case it is called as is) or a single argument containing the already validated data.\\n        alias: The name to use for the attribute when validating or serializing by alias.\\n            This is often used for things like converting between snake and camel case.\\n        alias_priority: Priority of the alias. This affects whether an alias generator is used.\\n        validation_alias: Like `alias`, but only affects validation, not serialization.\\n        serialization_alias: Like `alias`, but only affects serialization, not validation.\\n        title: Human-readable title.\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Human-readable description.\\n        examples: Example values for this field.\\n        exclude: Whether to exclude the field from the model serialization.\\n        discriminator: Field name or Discriminator for discriminating the type in a tagged union.\\n        deprecated: A deprecation message, an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport,\\n            or a boolean. If `True`, a default deprecation message will be emitted when accessing the field.\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        frozen: Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.\\n        validate_default: If `True`, apply validation to the default value every time you create an instance.\\n            Otherwise, for performance reasons, the default value of the field is trusted and not validated.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        init: Whether the field should be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        init_var: Whether the field should _only_ be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\\n        strict: If `True`, strict validation is applied to the field.\\n            See [Strict Mode](../concepts/strict_mode.md) for details.\\n        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\\n        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\\n        lt: Less than. If set, value must be less than this. Only applicable to numbers.\\n        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\\n        multiple_of: Value must be a multiple of this. Only applicable to numbers.\\n        min_length: Minimum length for iterables.\\n        max_length: Maximum length for iterables.\\n        pattern: Pattern for strings (a regular expression).\\n        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to float and [`Decimal`][decimal.Decimal] numbers.\\n        max_digits: Maximum number of allow digits for strings.\\n        decimal_places: Maximum number of decimal places allowed for numbers.\\n        union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.\\n            See [Union Mode](../concepts/unions.md#union-modes) for details.\\n        fail_fast: If `True`, validation will stop on the first error. If `False`, all validation errors will be collected.\\n            This option can be applied only to iterable types (list, tuple, set, and frozenset).\\n        extra: (Deprecated) Extra fields that will be included in the JSON schema.\\n\\n            !!! warning Deprecated\\n                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\\n\\n    Returns:\\n        A new [`FieldInfo`][pydantic.fields.FieldInfo]. The return annotation is `Any` so `Field` can be used on\\n            type-annotated fields without causing a type error.\\n    \"\"\"\\n    # Check deprecated and removed params from V1. This logic should eventually be removed.\\n    const = extra.pop(\\'const\\', None)  # type: ignore\\n    if const is not None:\\n        raise PydanticUserError(\\'`const` is removed, use `Literal` instead\\', code=\\'removed-kwargs\\')\\n\\n    min_items = extra.pop(\\'min_items\\', None)  # type: ignore\\n    if min_items is not None:\\n        warn(\\'`min_items` is deprecated and will be removed, use `min_length` instead\\', DeprecationWarning)\\n        if min_length in (None, _Unset):\\n            min_length = min_items  # type: ignore\\n\\n    max_items = extra.pop(\\'max_items\\', None)  # type: ignore\\n    if max_items is not None:\\n        warn(\\'`max_items` is deprecated and will be removed, use `max_length` instead\\', DeprecationWarning)\\n        if max_length in (None, _Unset):\\n            max_length = max_items  # type: ignore\\n\\n    unique_items = extra.pop(\\'unique_items\\', None)  # type: ignore\\n    if unique_items is not None:\\n        raise PydanticUserError(\\n            (\\n                \\'`unique_items` is removed, use `Set` instead\\'\\n                \\'(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)\\'\\n            ),\\n            code=\\'removed-kwargs\\',\\n        )\\n\\n    allow_mutation = extra.pop(\\'allow_mutation\\', None)  # type: ignore\\n    if allow_mutation is not None:\\n        warn(\\'`allow_mutation` is deprecated and will be removed. use `frozen` instead\\', DeprecationWarning)\\n        if allow_mutation is False:\\n            frozen = True\\n\\n    regex = extra.pop(\\'regex\\', None)  # type: ignore\\n    if regex is not None:\\n        raise PydanticUserError(\\'`regex` is removed. use `pattern` instead\\', code=\\'removed-kwargs\\')\\n\\n    if extra:\\n        warn(\\n            \\'Using extra keyword arguments on `Field` is deprecated and will be removed.\\'\\n            \\' Use `json_schema_extra` instead.\\'\\n            f\\' (Extra keys: {\", \".join(k.__repr__() for k in extra.keys())})\\',\\n            DeprecationWarning,\\n        )\\n        if not json_schema_extra or json_schema_extra is _Unset:\\n            json_schema_extra = extra  # type: ignore\\n\\n    if (\\n        validation_alias\\n        and validation_alias is not _Unset\\n        and not isinstance(validation_alias, (str, AliasChoices, AliasPath))\\n    ):\\n        raise TypeError(\\'Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`\\')\\n\\n    if serialization_alias in (_Unset, None) and isinstance(alias, str):\\n        serialization_alias = alias\\n\\n    if validation_alias in (_Unset, None):\\n        validation_alias = alias\\n\\n    include = extra.pop(\\'include\\', None)  # type: ignore\\n    if include is not None:\\n        warn(\\'`include` is deprecated and does nothing. It will be removed, use `exclude` instead\\', DeprecationWarning)\\n\\n    return FieldInfo.from_field(\\n        default,\\n        default_factory=default_factory,\\n        alias=alias,\\n        alias_priority=alias_priority,\\n        validation_alias=validation_alias,\\n        serialization_alias=serialization_alias,\\n        title=title,\\n        field_title_generator=field_title_generator,\\n        description=description,\\n        examples=examples,\\n        exclude=exclude,\\n        discriminator=discriminator,\\n        deprecated=deprecated,\\n        json_schema_extra=json_schema_extra,\\n        frozen=frozen,\\n        pattern=pattern,\\n        validate_default=validate_default,\\n        repr=repr,\\n        init=init,\\n        init_var=init_var,\\n        kw_only=kw_only,\\n        coerce_numbers_to_str=coerce_numbers_to_str,\\n        strict=strict,\\n        gt=gt,\\n        ge=ge,\\n        lt=lt,\\n        le=le,\\n        multiple_of=multiple_of,\\n        min_length=min_length,\\n        max_length=max_length,\\n        allow_inf_nan=allow_inf_nan,\\n        max_digits=max_digits,\\n        decimal_places=decimal_places,\\n        union_mode=union_mode,\\n        fail_fast=fail_fast,\\n    )\\n\\n```\\n\\n## FieldInfo\\n\\n```python\\nFieldInfo(**kwargs: Unpack[_FieldInfoInputs])\\n\\n```\\n\\nBases: `Representation`\\n\\nThis class holds information about a field.\\n\\n`FieldInfo` is used for any field definition regardless of whether the Field() function is explicitly used.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `FieldInfo` directly, you\\'ll only need to use it when accessing BaseModel `.model_fields` internals.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `annotation` | `type[Any] | None` | The type annotation of the field. | | `default` | `Any` | The default value of the field. | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | | `alias` | `str | None` | The alias name of the field. | | `alias_priority` | `int | None` | The priority of the field\\'s alias. | | `validation_alias` | `str | AliasPath | AliasChoices | None` | The validation alias of the field. | | `serialization_alias` | `str | None` | The serialization alias of the field. | | `title` | `str | None` | The title of the field. | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | The description of the field. | | `examples` | `list[Any] | None` | List of examples of the field. | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `frozen` | `bool | None` | Whether the field is frozen. | | `validate_default` | `bool | None` | Whether to validate the default value of the field. | | `repr` | `bool` | Whether to include the field in representation of the model. | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass, and not stored. | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. | | `metadata` | `list[Any]` | List of metadata constraints. |\\n\\nSee the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -> None:\\n    \"\"\"This class should generally not be initialized directly; instead, use the `pydantic.fields.Field` function\\n    or one of the constructor classmethods.\\n\\n    See the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n    \"\"\"\\n    self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset}\\n    kwargs = {k: _DefaultValues.get(k) if v is _Unset else v for k, v in kwargs.items()}  # type: ignore\\n    self.annotation = kwargs.get(\\'annotation\\')\\n\\n    default = kwargs.pop(\\'default\\', PydanticUndefined)\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n        self._attributes_set.pop(\\'default\\', None)\\n    else:\\n        self.default = default\\n\\n    self.default_factory = kwargs.pop(\\'default_factory\\', None)\\n\\n    if self.default is not PydanticUndefined and self.default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    self.alias = kwargs.pop(\\'alias\\', None)\\n    self.validation_alias = kwargs.pop(\\'validation_alias\\', None)\\n    self.serialization_alias = kwargs.pop(\\'serialization_alias\\', None)\\n    alias_is_set = any(alias is not None for alias in (self.alias, self.validation_alias, self.serialization_alias))\\n    self.alias_priority = kwargs.pop(\\'alias_priority\\', None) or 2 if alias_is_set else None\\n    self.title = kwargs.pop(\\'title\\', None)\\n    self.field_title_generator = kwargs.pop(\\'field_title_generator\\', None)\\n    self.description = kwargs.pop(\\'description\\', None)\\n    self.examples = kwargs.pop(\\'examples\\', None)\\n    self.exclude = kwargs.pop(\\'exclude\\', None)\\n    self.discriminator = kwargs.pop(\\'discriminator\\', None)\\n    # For compatibility with FastAPI<=0.110.0, we preserve the existing value if it is not overridden\\n    self.deprecated = kwargs.pop(\\'deprecated\\', getattr(self, \\'deprecated\\', None))\\n    self.repr = kwargs.pop(\\'repr\\', True)\\n    self.json_schema_extra = kwargs.pop(\\'json_schema_extra\\', None)\\n    self.validate_default = kwargs.pop(\\'validate_default\\', None)\\n    self.frozen = kwargs.pop(\\'frozen\\', None)\\n    # currently only used on dataclasses\\n    self.init = kwargs.pop(\\'init\\', None)\\n    self.init_var = kwargs.pop(\\'init_var\\', None)\\n    self.kw_only = kwargs.pop(\\'kw_only\\', None)\\n\\n    self.metadata = self._collect_metadata(kwargs)  # type: ignore\\n\\n    # Private attributes:\\n    self._qualifiers: set[Qualifier] = set()\\n    # Used to rebuild FieldInfo instances:\\n    self._complete = True\\n    self._original_annotation: Any = PydanticUndefined\\n    self._original_assignment: Any = PydanticUndefined\\n\\n```\\n\\n### from_field\\n\\n```python\\nfrom_field(\\n    default: Any = PydanticUndefined,\\n    **kwargs: Unpack[_FromFieldInfoInputs]\\n) -> FieldInfo\\n\\n```\\n\\nCreate a new `FieldInfo` object with the `Field` function.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The default value for the field. Defaults to Undefined. | `PydanticUndefined` | | `**kwargs` | `Unpack[_FromFieldInfoInputs]` | Additional arguments dictionary. | `{}` |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `TypeError` | If \\'annotation\\' is passed as a keyword argument. |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A new FieldInfo object with the given parameters. |\\n\\nExample\\n\\nThis is how you can create a field with default value like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = pydantic.Field(4)\\n\\n```\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_field(default: Any = PydanticUndefined, **kwargs: Unpack[_FromFieldInfoInputs]) -> FieldInfo:\\n    \"\"\"Create a new `FieldInfo` object with the `Field` function.\\n\\n    Args:\\n        default: The default value for the field. Defaults to Undefined.\\n        **kwargs: Additional arguments dictionary.\\n\\n    Raises:\\n        TypeError: If \\'annotation\\' is passed as a keyword argument.\\n\\n    Returns:\\n        A new FieldInfo object with the given parameters.\\n\\n    Example:\\n        This is how you can create a field with default value like this:\\n\\n        ```python\\n        import pydantic\\n\\n        class MyModel(pydantic.BaseModel):\\n            foo: int = pydantic.Field(4)\\n        ```\\n    \"\"\"\\n    if \\'annotation\\' in kwargs:\\n        raise TypeError(\\'\"annotation\" is not permitted as a Field keyword argument\\')\\n    return FieldInfo(default=default, **kwargs)\\n\\n````\\n\\n### from_annotation\\n\\n```python\\nfrom_annotation(\\n    annotation: type[Any],\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreates a `FieldInfo` instance from a bare annotation.\\n\\nThis function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int  # <-- like this\\n\\n```\\n\\nWe also account for the case where the annotation can be an instance of `Annotated` and where one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: Annotated[int, annotated_types.Gt(42)]\\n    bar: Annotated[int, pydantic.Field(gt=42)]\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | An annotation object. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | An instance of the field metadata. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotation(annotation: type[Any], *, _source: AnnotationSource = AnnotationSource.ANY) -> FieldInfo:\\n    \"\"\"Creates a `FieldInfo` instance from a bare annotation.\\n\\n    This function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n    ```python\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int  # <-- like this\\n    ```\\n\\n    We also account for the case where the annotation can be an instance of `Annotated` and where\\n    one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: Annotated[int, annotated_types.Gt(42)]\\n        bar: Annotated[int, pydantic.Field(gt=42)]\\n    ```\\n\\n    Args:\\n        annotation: An annotation object.\\n\\n    Returns:\\n        An instance of the field metadata.\\n    \"\"\"\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # No assigned value, this happens when using a bare `Final` qualifier (also for other\\n    # qualifiers, but they shouldn\\'t appear here). In this case we infer the type as `Any`\\n    # because we don\\'t have any assigned value.\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int`, or `field: Final[str]`:\\n        field_info = FieldInfo(annotation=type_expr, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)]`:\\n    field_info_annotations = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_info_annotations, annotation=type_expr)\\n\\n    new_field_info = field_info._copy()\\n    new_field_info.annotation = type_expr\\n    new_field_info.frozen = final or field_info.frozen\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            new_field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n        new_field_info.metadata = field_metadata\\n    new_field_info._qualifiers = inspected_ann.qualifiers\\n    return new_field_info\\n\\n````\\n\\n### from_annotated_attribute\\n\\n```python\\nfrom_annotated_attribute(\\n    annotation: type[Any],\\n    default: Any,\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreate `FieldInfo` from an annotation with a default value.\\n\\nThis is used in cases like the following:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = 4  # <-- like this\\n    bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n    spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | The type annotation of the field. | *required* | | `default` | `Any` | The default value of the field. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A field object with the passed values. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotated_attribute(\\n    annotation: type[Any], default: Any, *, _source: AnnotationSource = AnnotationSource.ANY\\n) -> FieldInfo:\\n    \"\"\"Create `FieldInfo` from an annotation with a default value.\\n\\n    This is used in cases like the following:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int = 4  # <-- like this\\n        bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n        spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n    ```\\n\\n    Args:\\n        annotation: The type annotation of the field.\\n        default: The default value of the field.\\n\\n    Returns:\\n        A field object with the passed values.\\n    \"\"\"\\n    if annotation is default:\\n        raise PydanticUserError(\\n            \\'Error when building FieldInfo from annotated attribute. \\'\\n            \"Make sure you don\\'t have any field name clashing with a type annotation.\",\\n            code=\\'unevaluable-type-annotation\\',\\n        )\\n\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # TODO infer from the default, this can be done in v3 once we treat final fields with\\n    # a default as proper fields and not class variables:\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if isinstance(default, FieldInfo):\\n        # e.g. `field: int = Field(...)`\\n        default_metadata = default.metadata.copy()\\n        default = copy(default)\\n        default.metadata = default_metadata\\n\\n        default.annotation = type_expr\\n        default.metadata += metadata\\n        merged_default = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            default,\\n            annotation=default.annotation,\\n        )\\n        merged_default.frozen = final or merged_default.frozen\\n        merged_default._qualifiers = inspected_ann.qualifiers\\n        return merged_default\\n\\n    if isinstance(default, dataclasses.Field):\\n        # `collect_dataclass_fields()` passes the dataclass Field as a default.\\n        pydantic_field = FieldInfo._from_dataclass_field(default)\\n        pydantic_field.annotation = type_expr\\n        pydantic_field.metadata += metadata\\n        pydantic_field = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            pydantic_field,\\n            annotation=pydantic_field.annotation,\\n        )\\n        pydantic_field.frozen = final or pydantic_field.frozen\\n        pydantic_field.init_var = \\'init_var\\' in inspected_ann.qualifiers\\n        pydantic_field.init = getattr(default, \\'init\\', None)\\n        pydantic_field.kw_only = getattr(default, \\'kw_only\\', None)\\n        pydantic_field._qualifiers = inspected_ann.qualifiers\\n        return pydantic_field\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\\n        field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\\n    field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n    field_info.metadata = field_metadata\\n    field_info._qualifiers = inspected_ann.qualifiers\\n    return field_info\\n\\n````\\n\\n### merge_field_infos\\n\\n```python\\nmerge_field_infos(\\n    *field_infos: FieldInfo, **overrides: Any\\n) -> FieldInfo\\n\\n```\\n\\nMerge `FieldInfo` instances keeping only explicitly set attributes.\\n\\nLater `FieldInfo` instances override earlier ones.\\n\\nReturns:\\n\\n| Name | Type | Description | | --- | --- | --- | | `FieldInfo` | `FieldInfo` | A merged FieldInfo instance. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\n@staticmethod\\ndef merge_field_infos(*field_infos: FieldInfo, **overrides: Any) -> FieldInfo:\\n    \"\"\"Merge `FieldInfo` instances keeping only explicitly set attributes.\\n\\n    Later `FieldInfo` instances override earlier ones.\\n\\n    Returns:\\n        FieldInfo: A merged FieldInfo instance.\\n    \"\"\"\\n    if len(field_infos) == 1:\\n        # No merging necessary, but we still need to make a copy and apply the overrides\\n        field_info = field_infos[0]._copy()\\n        field_info._attributes_set.update(overrides)\\n\\n        default_override = overrides.pop(\\'default\\', PydanticUndefined)\\n        if default_override is Ellipsis:\\n            default_override = PydanticUndefined\\n        if default_override is not PydanticUndefined:\\n            field_info.default = default_override\\n\\n        for k, v in overrides.items():\\n            setattr(field_info, k, v)\\n        return field_info  # type: ignore\\n\\n    merged_field_info_kwargs: dict[str, Any] = {}\\n    metadata = {}\\n    for field_info in field_infos:\\n        attributes_set = field_info._attributes_set.copy()\\n\\n        try:\\n            json_schema_extra = attributes_set.pop(\\'json_schema_extra\\')\\n            existing_json_schema_extra = merged_field_info_kwargs.get(\\'json_schema_extra\\')\\n\\n            if existing_json_schema_extra is None:\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n            if isinstance(existing_json_schema_extra, dict):\\n                if isinstance(json_schema_extra, dict):\\n                    merged_field_info_kwargs[\\'json_schema_extra\\'] = {\\n                        **existing_json_schema_extra,\\n                        **json_schema_extra,\\n                    }\\n                if callable(json_schema_extra):\\n                    warn(\\n                        \\'Composing `dict` and `callable` type `json_schema_extra` is not supported.\\'\\n                        \\'The `callable` type is being ignored.\\'\\n                        \"If you\\'d like support for this behavior, please open an issue on pydantic.\",\\n                        PydanticJsonSchemaWarning,\\n                    )\\n            elif callable(json_schema_extra):\\n                # if ever there\\'s a case of a callable, we\\'ll just keep the last json schema extra spec\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n        except KeyError:\\n            pass\\n\\n        # later FieldInfo instances override everything except json_schema_extra from earlier FieldInfo instances\\n        merged_field_info_kwargs.update(attributes_set)\\n\\n        for x in field_info.metadata:\\n            if not isinstance(x, FieldInfo):\\n                metadata[type(x)] = x\\n\\n    merged_field_info_kwargs.update(overrides)\\n    field_info = FieldInfo(**merged_field_info_kwargs)\\n    field_info.metadata = list(metadata.values())\\n    return field_info\\n\\n```\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n\\n### default_factory_takes_validated_data\\n\\n```python\\ndefault_factory_takes_validated_data: bool | None\\n\\n```\\n\\nWhether the provided default factory callable has a validated data parameter.\\n\\nReturns `None` if no default factory is set.\\n\\n### get_default\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: Literal[True],\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *, call_default_factory: Literal[False] = ...\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: bool = False,\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\nGet the default value.\\n\\nWe expose an option for whether to call the default_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via `model_construct`).\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `call_default_factory` | `bool` | Whether to call the default factory or not. | `False` | | `validated_data` | `dict[str, Any] | None` | The already validated data to be passed to the default factory. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value, calling the default factory if requested or None if not set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self, *, call_default_factory: bool = False, validated_data: dict[str, Any] | None = None) -> Any:\\n    \"\"\"Get the default value.\\n\\n    We expose an option for whether to call the default_factory (if present), as calling it may\\n    result in side effects that we want to avoid. However, there are times when it really should\\n    be called (namely, when instantiating a model via `model_construct`).\\n\\n    Args:\\n        call_default_factory: Whether to call the default factory or not.\\n        validated_data: The already validated data to be passed to the default factory.\\n\\n    Returns:\\n        The default value, calling the default factory if requested or `None` if not set.\\n    \"\"\"\\n    if self.default_factory is None:\\n        return _utils.smart_deepcopy(self.default)\\n    elif call_default_factory:\\n        if self.default_factory_takes_validated_data:\\n            fac = cast(\\'Callable[[dict[str, Any]], Any]\\', self.default_factory)\\n            if validated_data is None:\\n                raise ValueError(\\n                    \"The default factory requires the \\'validated_data\\' argument, which was not provided when calling \\'get_default\\'.\"\\n                )\\n            return fac(validated_data)\\n        else:\\n            fac = cast(\\'Callable[[], Any]\\', self.default_factory)\\n            return fac()\\n    else:\\n        return None\\n\\n```\\n\\n### is_required\\n\\n```python\\nis_required() -> bool\\n\\n```\\n\\nCheck if the field is required (i.e., does not have a default value or factory).\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool` | True if the field is required, False otherwise. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef is_required(self) -> bool:\\n    \"\"\"Check if the field is required (i.e., does not have a default value or factory).\\n\\n    Returns:\\n        `True` if the field is required, `False` otherwise.\\n    \"\"\"\\n    return self.default is PydanticUndefined and self.default_factory is None\\n\\n```\\n\\n### rebuild_annotation\\n\\n```python\\nrebuild_annotation() -> Any\\n\\n```\\n\\nAttempts to rebuild the original annotation for use in function signatures.\\n\\nIf metadata is present, it adds it to the original annotation using `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\nNote that because the metadata has been flattened, the original annotation may not be reconstructed exactly as originally provided, e.g. if the original type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The rebuilt annotation. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef rebuild_annotation(self) -> Any:\\n    \"\"\"Attempts to rebuild the original annotation for use in function signatures.\\n\\n    If metadata is present, it adds it to the original annotation using\\n    `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\n    Note that because the metadata has been flattened, the original annotation\\n    may not be reconstructed exactly as originally provided, e.g. if the original\\n    type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\n    Returns:\\n        The rebuilt annotation.\\n    \"\"\"\\n    if not self.metadata:\\n        return self.annotation\\n    else:\\n        # Annotated arguments must be a tuple\\n        return Annotated[(self.annotation, *self.metadata)]  # type: ignore\\n\\n```\\n\\n### apply_typevars_map\\n\\n```python\\napply_typevars_map(\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None\\n\\n```\\n\\nApply a `typevars_map` to the annotation.\\n\\nThis method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\nThis method applies the `typevars_map` to the annotation in place.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `typevars_map` | `Mapping[TypeVar, Any] | None` | A dictionary mapping type variables to their concrete types. | *required* | | `globalns` | `GlobalsNamespace | None` | The globals namespace to use during type annotation evaluation. | `None` | | `localns` | `MappingNamespace | None` | The locals namespace to use during type annotation evaluation. | `None` |\\n\\nSee Also\\n\\npydantic.\\\\_internal.\\\\_generics.replace_types is used for replacing the typevars with their concrete types.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef apply_typevars_map(\\n    self,\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None:\\n    \"\"\"Apply a `typevars_map` to the annotation.\\n\\n    This method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\n    This method applies the `typevars_map` to the annotation in place.\\n\\n    Args:\\n        typevars_map: A dictionary mapping type variables to their concrete types.\\n        globalns: The globals namespace to use during type annotation evaluation.\\n        localns: The locals namespace to use during type annotation evaluation.\\n\\n    See Also:\\n        pydantic._internal._generics.replace_types is used for replacing the typevars with\\n            their concrete types.\\n    \"\"\"\\n    annotation = _generics.replace_types(self.annotation, typevars_map)\\n    annotation, evaluated = _typing_extra.try_eval_type(annotation, globalns, localns)\\n    self.annotation = annotation\\n    if not evaluated:\\n        self._complete = False\\n        self._original_annotation = self.annotation\\n\\n```\\n\\n## PrivateAttr\\n\\n```python\\nPrivateAttr(\\n    default: _T, *, init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    *,\\n    default_factory: Callable[[], _T],\\n    init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(*, init: Literal[False] = False) -> Any\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Private Model Attributes](../../concepts/models/#private-model-attributes)\\n\\nIndicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\nPrivate attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\nPrivate attributes are stored in `__private_attributes__` on the model.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The attribute\\'s default value. Defaults to Undefined. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | None` | Callable that will be called when a default value is needed for this attribute. If both default and default_factory are set, an error will be raised. | `None` | | `init` | `Literal[False]` | Whether the attribute should be included in the constructor of the dataclass. Always False. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | An instance of ModelPrivateAttr class. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `ValueError` | If both default and default_factory are set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef PrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False,\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Private Model Attributes](../concepts/models.md#private-model-attributes)\\n\\n    Indicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\n    Private attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\n    Private attributes are stored in `__private_attributes__` on the model.\\n\\n    Args:\\n        default: The attribute\\'s default value. Defaults to Undefined.\\n        default_factory: Callable that will be\\n            called when a default value is needed for this attribute.\\n            If both `default` and `default_factory` are set, an error will be raised.\\n        init: Whether the attribute should be included in the constructor of the dataclass. Always `False`.\\n\\n    Returns:\\n        An instance of [`ModelPrivateAttr`][pydantic.fields.ModelPrivateAttr] class.\\n\\n    Raises:\\n        ValueError: If both `default` and `default_factory` are set.\\n    \"\"\"\\n    if default is not PydanticUndefined and default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    return ModelPrivateAttr(\\n        default,\\n        default_factory=default_factory,\\n    )\\n\\n```\\n\\n## ModelPrivateAttr\\n\\n```python\\nModelPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None\\n)\\n\\n```\\n\\nBases: `Representation`\\n\\nA descriptor for private attributes in class models.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `ModelPrivateAttr` instances directly, instead use `pydantic.fields.PrivateAttr`. (This is similar to `FieldInfo` vs. `Field`.)\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `default` | | The default value of the attribute if not provided. | | `default_factory` | | A callable function that generates the default value of the attribute if not provided. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(\\n    self, default: Any = PydanticUndefined, *, default_factory: typing.Callable[[], Any] | None = None\\n) -> None:\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n    else:\\n        self.default = default\\n    self.default_factory = default_factory\\n\\n```\\n\\n### get_default\\n\\n```python\\nget_default() -> Any\\n\\n```\\n\\nRetrieve the default value of the object.\\n\\nIf `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\nIf `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value of the object. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self) -> Any:\\n    \"\"\"Retrieve the default value of the object.\\n\\n    If `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\n    If `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\n    Returns:\\n        The default value of the object.\\n    \"\"\"\\n    return _utils.smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\\n\\n```\\n\\n## computed_field\\n\\n```python\\ncomputed_field(func: PropertyT) -> PropertyT\\n\\n```\\n\\n```python\\ncomputed_field(\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool = True,\\n    return_type: Any = PydanticUndefined\\n) -> Callable[[PropertyT], PropertyT]\\n\\n```\\n\\n```python\\ncomputed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | Callable[[PropertyT], PropertyT]\\n\\n```\\n\\nUsage Documentation\\n\\n[The `computed_field` decorator](../../concepts/fields/#the-computed_field-decorator)\\n\\nDecorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\nThis is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Rectangle(BaseModel):\\n    width: int\\n    length: int\\n\\n    @computed_field\\n    @property\\n    def area(self) -> int:\\n        return self.width * self.length\\n\\nprint(Rectangle(width=3, length=2).model_dump())\\n#> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n\\n```\\n\\nIf applied to functions not yet decorated with `@property` or `@cached_property`, the function is automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\nMypy Warning\\n\\nEven with the `@property` or `@cached_property` applied to your function before `@computed_field`, mypy may throw a `Decorated property not supported` error. See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information. To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n[pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n```python\\nimport random\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Square(BaseModel):\\n    width: float\\n\\n    @computed_field\\n    def area(self) -> float:  # converted to a `property` by `computed_field`\\n        return round(self.width**2, 2)\\n\\n    @area.setter\\n    def area(self, new_area: float) -> None:\\n        self.width = new_area**0.5\\n\\n    @computed_field(alias=\\'the magic number\\', repr=False)\\n    def random_number(self) -> int:\\n        return random.randint(0, 1_000)\\n\\nsquare = Square(width=1.3)\\n\\n# `random_number` does not appear in representation\\nprint(repr(square))\\n#> Square(width=1.3, area=1.69)\\n\\nprint(square.random_number)\\n#> 3\\n\\nsquare.area = 4\\n\\nprint(square.model_dump_json(by_alias=True))\\n#> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n\\n```\\n\\nOverriding with `computed_field`\\n\\nYou can\\'t override a field from a parent class with a `computed_field` in the child class. `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either. See the example below:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Parent(BaseModel):\\n    a: str\\n\\ntry:\\n\\n    class Child(Parent):\\n        @computed_field\\n        @property\\n        def a(self) -> str:\\n            return \\'new a\\'\\n\\nexcept TypeError as e:\\n    print(e)\\n    \\'\\'\\'\\n    Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n    \\'\\'\\'\\n\\n```\\n\\nPrivate properties decorated with `@computed_field` have `repr=False` by default.\\n\\n```python\\nfrom functools import cached_property\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Model(BaseModel):\\n    foo: int\\n\\n    @computed_field\\n    @cached_property\\n    def _private_cached_property(self) -> int:\\n        return -self.foo\\n\\n    @computed_field\\n    @property\\n    def _private_property(self) -> int:\\n        return -self.foo\\n\\nm = Model(foo=1)\\nprint(repr(m))\\n#> Model(foo=1)\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `func` | `PropertyT | None` | the function to wrap. | `None` | | `alias` | `str | None` | alias to use when serializing this computed field, only used when by_alias=True | `None` | | `alias_priority` | `int | None` | priority of the alias. This affects whether an alias generator is used | `None` | | `title` | `str | None` | Title to use when including this computed field in JSON Schema | `None` | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `None` | | `description` | `str | None` | Description to use when including this computed field in JSON Schema, defaults to the function\\'s docstring | `None` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message (or an instance of warnings.deprecated or the typing_extensions.deprecated backport). to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the deprecated decorator. | `None` | | `examples` | `list[Any] | None` | Example values to use when including this computed field in JSON Schema | `None` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `None` | | `repr` | `bool | None` | whether to include this computed field in model repr. Default is False for private properties and True for public properties. | `None` | | `return_type` | `Any` | optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a TypeError is raised. If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary objects. | `PydanticUndefined` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `PropertyT | Callable[[PropertyT], PropertyT]` | A proxy wrapper for the property. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\ndef computed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: typing.Callable[[str, ComputedFieldInfo], str] | None = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | typing.Callable[[PropertyT], PropertyT]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [The `computed_field` decorator](../concepts/fields.md#the-computed_field-decorator)\\n\\n    Decorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\n    This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Rectangle(BaseModel):\\n        width: int\\n        length: int\\n\\n        @computed_field\\n        @property\\n        def area(self) -> int:\\n            return self.width * self.length\\n\\n    print(Rectangle(width=3, length=2).model_dump())\\n    #> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n    ```\\n\\n    If applied to functions not yet decorated with `@property` or `@cached_property`, the function is\\n    automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE,\\n    and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\n    !!! warning \"Mypy Warning\"\\n        Even with the `@property` or `@cached_property` applied to your function before `@computed_field`,\\n        mypy may throw a `Decorated property not supported` error.\\n        See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information.\\n        To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n        [pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n    ```python\\n    import random\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Square(BaseModel):\\n        width: float\\n\\n        @computed_field\\n        def area(self) -> float:  # converted to a `property` by `computed_field`\\n            return round(self.width**2, 2)\\n\\n        @area.setter\\n        def area(self, new_area: float) -> None:\\n            self.width = new_area**0.5\\n\\n        @computed_field(alias=\\'the magic number\\', repr=False)\\n        def random_number(self) -> int:\\n            return random.randint(0, 1_000)\\n\\n    square = Square(width=1.3)\\n\\n    # `random_number` does not appear in representation\\n    print(repr(square))\\n    #> Square(width=1.3, area=1.69)\\n\\n    print(square.random_number)\\n    #> 3\\n\\n    square.area = 4\\n\\n    print(square.model_dump_json(by_alias=True))\\n    #> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n    ```\\n\\n    !!! warning \"Overriding with `computed_field`\"\\n        You can\\'t override a field from a parent class with a `computed_field` in the child class.\\n        `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either.\\n        See the example below:\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Parent(BaseModel):\\n        a: str\\n\\n    try:\\n\\n        class Child(Parent):\\n            @computed_field\\n            @property\\n            def a(self) -> str:\\n                return \\'new a\\'\\n\\n    except TypeError as e:\\n        print(e)\\n        \\'\\'\\'\\n        Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n        \\'\\'\\'\\n    ```\\n\\n    Private properties decorated with `@computed_field` have `repr=False` by default.\\n\\n    ```python\\n    from functools import cached_property\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Model(BaseModel):\\n        foo: int\\n\\n        @computed_field\\n        @cached_property\\n        def _private_cached_property(self) -> int:\\n            return -self.foo\\n\\n        @computed_field\\n        @property\\n        def _private_property(self) -> int:\\n            return -self.foo\\n\\n    m = Model(foo=1)\\n    print(repr(m))\\n    #> Model(foo=1)\\n    ```\\n\\n    Args:\\n        func: the function to wrap.\\n        alias: alias to use when serializing this computed field, only used when `by_alias=True`\\n        alias_priority: priority of the alias. This affects whether an alias generator is used\\n        title: Title to use when including this computed field in JSON Schema\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Description to use when including this computed field in JSON Schema, defaults to the function\\'s\\n            docstring\\n        deprecated: A deprecation message (or an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport).\\n            to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the\\n            `deprecated` decorator.\\n        examples: Example values to use when including this computed field in JSON Schema\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        repr: whether to include this computed field in model repr.\\n            Default is `False` for private properties and `True` for public properties.\\n        return_type: optional return for serialization logic to expect when serializing to JSON, if included\\n            this must be correct, otherwise a `TypeError` is raised.\\n            If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary\\n            objects.\\n\\n    Returns:\\n        A proxy wrapper for the property.\\n    \"\"\"\\n\\n    def dec(f: Any) -> Any:\\n        nonlocal description, deprecated, return_type, alias_priority\\n        unwrapped = _decorators.unwrap_wrapped_function(f)\\n\\n        if description is None and unwrapped.__doc__:\\n            description = inspect.cleandoc(unwrapped.__doc__)\\n\\n        if deprecated is None and hasattr(unwrapped, \\'__deprecated__\\'):\\n            deprecated = unwrapped.__deprecated__\\n\\n        # if the function isn\\'t already decorated with `@property` (or another descriptor), then we wrap it now\\n        f = _decorators.ensure_property(f)\\n        alias_priority = (alias_priority or 2) if alias is not None else None\\n\\n        if repr is None:\\n            repr_: bool = not _wrapped_property_is_private(property_=f)\\n        else:\\n            repr_ = repr\\n\\n        dec_info = ComputedFieldInfo(\\n            f,\\n            return_type,\\n            alias,\\n            alias_priority,\\n            title,\\n            field_title_generator,\\n            description,\\n            deprecated,\\n            examples,\\n            json_schema_extra,\\n            repr_,\\n        )\\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\\n\\n    if func is None:\\n        return dec\\n    else:\\n        return dec(func)\\n\\n````\\n\\n## ComputedFieldInfo\\n\\n```python\\nComputedFieldInfo(\\n    wrapped_property: property,\\n    return_type: Any,\\n    alias: str | None,\\n    alias_priority: int | None,\\n    title: str | None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ),\\n    description: str | None,\\n    deprecated: Deprecated | str | bool | None,\\n    examples: list[Any] | None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ),\\n    repr: bool,\\n)\\n\\n```\\n\\nA container for data from `@computed_field` so that we can access it while building the pydantic-core schema.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `decorator_repr` | `str` | A class variable representing the decorator string, \\'@computed_field\\'. | | `wrapped_property` | `property` | The wrapped computed field property. | | `return_type` | `Any` | The type of the computed field property\\'s return value. | | `alias` | `str | None` | The alias of the property to be used during serialization. | | `alias_priority` | `int | None` | The priority of the alias. This affects whether an alias generator is used. | | `title` | `str | None` | Title of the computed field to include in the serialization JSON schema. | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | Description of the computed field to include in the serialization JSON schema. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `examples` | `list[Any] | None` | Example values of the computed field to include in the serialization JSON schema. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `repr` | `bool` | A boolean indicating whether to include the field in the repr output. |\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n'},\n",
       " {'url': 'https://docs.pydantic.dev/latest/concepts/fields/index.md',\n",
       "  'text': 'API Documentation\\n\\npydantic.fields.Field\\n\\nIn this section, we will go through the available mechanisms to customize Pydantic model fields: default values, JSON Schema metadata, constraints, etc.\\n\\nTo do so, the Field() function is used a lot, and behaves the same way as the standard library field() function for dataclasses:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    name: str = Field(frozen=True)\\n\\n```\\n\\nNote\\n\\nEven though `name` is assigned a value, it is still required and has no default value. If you want to emphasize on the fact that a value must be provided, you can use the ellipsis:\\n\\n```python\\nclass Model(BaseModel):\\n    name: str = Field(..., frozen=True)\\n\\n```\\n\\nHowever, its usage is discouraged as it doesn\\'t play well with static type checkers.\\n\\n## The annotated pattern\\n\\nTo apply constraints or attach Field() functions to a model field, Pydantic supports the Annotated typing construct to attach metadata to an annotation:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field, WithJsonSchema\\n\\n\\nclass Model(BaseModel):\\n    name: Annotated[str, Field(strict=True), WithJsonSchema({\\'extra\\': \\'data\\'})]\\n\\n```\\n\\nAs far as static type checkers are concerned, `name` is still typed as `str`, but Pydantic leverages the available metadata to add validation logic, type constraints, etc.\\n\\nUsing this pattern has some advantages:\\n\\n- Using the `f: \\n = Field(...)` form can be confusing and might trick users into thinking `f` has a default value, while in reality it is still required.\\n- You can provide an arbitrary amount of metadata elements for a field. As shown in the example above, the Field() function only supports a limited set of constraints/metadata, and you may have to use different Pydantic utilities such as WithJsonSchema in some cases.\\n- Types can be made reusable (see the documentation on [custom types](../types/#using-the-annotated-pattern) using this pattern).\\n\\nHowever, note that certain arguments to the Field() function (namely, `default`, `default_factory`, and `alias`) are taken into account by static type checkers to synthesize a correct `__init__` method. The annotated pattern is *not* understood by them, so you should use the normal assignment form instead.\\n\\nTip\\n\\nThe annotated pattern can also be used to add metadata to specific parts of the type. For instance, [validation constraints](#field-constraints) can be added this way:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    int_list: list[Annotated[int, Field(gt=0)]]\\n    # Valid: [1, 3]\\n    # Invalid: [-1, 2]\\n\\n```\\n\\nBe careful not mixing *field* and *type* metadata:\\n\\n```python\\nclass Model(BaseModel):\\n    field_bad: Annotated[int, Field(deprecated=True)] | None = None  # (1)!\\n    field_ok: Annotated[int | None, Field(deprecated=True)] = None  # (2)!\\n\\n```\\n\\n1. The Field() function is applied to `int` type, hence the `deprecated` flag won\\'t have any effect. While this may be confusing given that the name of the Field() function would imply it should apply to the field, the API was designed when this function was the only way to provide metadata. You can alternatively make use of the [`annotated_types`](https://github.com/annotated-types/annotated-types) library which is now supported by Pydantic.\\n1. The Field() function is applied to the \"top-level\" union type, hence the `deprecated` flag will be applied to the field.\\n\\n## Default values\\n\\nDefault values for fields can be provided using the normal assignment syntax or by providing a value to the `default` argument:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    # Both fields aren\\'t required:\\n    name: str = \\'John Doe\\'\\n    age: int = Field(default=20)\\n\\n```\\n\\nWarning\\n\\n[In Pydantic V1](../../migration/#required-optional-and-nullable-fields), a type annotated as Any or wrapped by Optional would be given an implicit default of `None` even if no default was explicitly specified. This is no longer the case in Pydantic V2.\\n\\nYou can also pass a callable to the `default_factory` argument that will be called to generate a default value:\\n\\n```python\\nfrom uuid import uuid4\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    id: str = Field(default_factory=lambda: uuid4().hex)\\n\\n```\\n\\nThe default factory can also take a single required argument, in which case the already validated data will be passed as a dictionary.\\n\\n```python\\nfrom pydantic import BaseModel, EmailStr, Field\\n\\n\\nclass User(BaseModel):\\n    email: EmailStr\\n    username: str = Field(default_factory=lambda data: data[\\'email\\'])\\n\\n\\nuser = User(email=\\'user@example.com\\')\\nprint(user.username)\\n#> user@example.com\\n\\n```\\n\\nThe `data` argument will *only* contain the already validated data, based on the [order of model fields](../models/#field-ordering) (the above example would fail if `username` were to be defined before `email`).\\n\\n## Validate default values\\n\\nBy default, Pydantic will *not* validate default values. The `validate_default` field parameter (or the validate_default configuration value) can be used to enable this behavior:\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    age: int = Field(default=\\'twelve\\', validate_default=True)\\n\\n\\ntry:\\n    user = User()\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    age\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'twelve\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Mutable default values\\n\\nA common source of bugs in Python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call.\\n\\nThe dataclasses module actually raises an error in this case, indicating that you should use a [default factory](https://docs.python.org/3/library/dataclasses.html#default-factory-functions) instead.\\n\\nWhile the same thing can be done in Pydantic, it is not required. In the event that the default value is not hashable, Pydantic will create a deep copy of the default value when creating each instance of the model:\\n\\n```python\\nfrom pydantic import BaseModel\\n\\n\\nclass Model(BaseModel):\\n    item_counts: list[dict[str, int]] = [{}]\\n\\n\\nm1 = Model()\\nm1.item_counts[0][\\'a\\'] = 1\\nprint(m1.item_counts)\\n#> [{\\'a\\': 1}]\\n\\nm2 = Model()\\nprint(m2.item_counts)\\n#> [{}]\\n\\n```\\n\\n## Field aliases\\n\\nTip\\n\\nRead more about aliases in the [dedicated section](../alias/).\\n\\nFor validation and serialization, you can define an alias for a field.\\n\\nThere are three ways to define an alias:\\n\\n- `Field(alias=\\'foo\\')`\\n- `Field(validation_alias=\\'foo\\')`\\n- `Field(serialization_alias=\\'foo\\')`\\n\\nThe `alias` parameter is used for both validation *and* serialization. If you want to use *different* aliases for validation and serialization respectively, you can use the `validation_alias` and `serialization_alias` parameters, which will apply only in their respective use cases.\\n\\nHere is an example of using the `alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The alias `\\'username\\'` is used for instance creation and validation.\\n\\n1. We are using model_dump() to convert the model into a serializable format.\\n\\n   Note that the `by_alias` keyword argument defaults to `False`, and must be specified explicitly to dump models using the field (serialization) aliases.\\n\\n   You can also use ConfigDict.serialize_by_alias to configure this behavior at the model level.\\n\\n   When `by_alias=True`, the alias `\\'username\\'` used during serialization.\\n\\nIf you want to use an alias *only* for validation, you can use the `validation_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(validation_alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'name\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The validation alias `\\'username\\'` is used during validation.\\n1. The field name `\\'name\\'` is used during serialization.\\n\\nIf you only want to define an alias for *serialization*, you can use the `serialization_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(serialization_alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The field name `\\'name\\'` is used for validation.\\n1. The serialization alias `\\'username\\'` is used for serialization.\\n\\nAlias precedence and priority\\n\\nIn case you use `alias` together with `validation_alias` or `serialization_alias` at the same time, the `validation_alias` will have priority over `alias` for validation, and `serialization_alias` will have priority over `alias` for serialization.\\n\\nIf you provide a value for the alias_generator model setting, you can control the order of precedence for field alias and generated aliases via the `alias_priority` field parameter. You can read more about alias precedence [here](../alias/#alias-precedence).\\n\\nStatic type checking/IDE support\\n\\nIf you provide a value for the `alias` field parameter, static type checkers will use this alias instead of the actual field name to synthesize the `__init__` method:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n\\nThis means that when using the validate_by_name model setting (which allows both the field name and alias to be used during model validation), type checkers will error when the actual field name is used:\\n\\n```python\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True)\\n\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. *Not* accepted by type checkers.\\n\\nIf you still want type checkers to use the field name and not the alias, the [annotated pattern](#the-annotated-pattern) can be used (which is only understood by Pydantic):\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True, validate_by_alias=True)\\n\\n    name: Annotated[str, Field(alias=\\'username\\')]\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nuser = User(username=\\'johndoe\\')  # (2)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n1. *Not* accepted by type checkers.\\n\\n### Validation Alias\\n\\nEven though Pydantic treats `alias` and `validation_alias` the same when creating model instances, type checkers only understand the `alias` field parameter. As a workaround, you can instead specify both an `alias` and serialization_alias`(identical to the field name), as the`serialization_alias`will override the`alias\\\\` during serialization:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(validation_alias=\\'myValidationAlias\\')\\n\\n```\\n\\nwith:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(\\n        alias=\\'myValidationAlias\\',\\n        serialization_alias=\\'my_field\\',\\n    )\\n\\n\\nm = MyModel(myValidationAlias=1)\\nprint(m.model_dump(by_alias=True))\\n#> {\\'my_field\\': 1}\\n\\n```\\n\\n## Numeric Constraints\\n\\nThere are some keyword arguments that can be used to constrain numeric values:\\n\\n- `gt` - greater than\\n- `lt` - less than\\n- `ge` - greater than or equal to\\n- `le` - less than or equal to\\n- `multiple_of` - a multiple of the given number\\n- `allow_inf_nan` - allow `\\'inf\\'`, `\\'-inf\\'`, `\\'nan\\'` values\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: int = Field(gt=0)\\n    non_negative: int = Field(ge=0)\\n    negative: int = Field(lt=0)\\n    non_positive: int = Field(le=0)\\n    even: int = Field(multiple_of=2)\\n    love_for_pydantic: float = Field(allow_inf_nan=True)\\n\\n\\nfoo = Foo(\\n    positive=1,\\n    non_negative=0,\\n    negative=-1,\\n    non_positive=0,\\n    even=2,\\n    love_for_pydantic=float(\\'inf\\'),\\n)\\nprint(foo)\\n\"\"\"\\npositive=1 non_negative=0 negative=-1 non_positive=0 even=2 love_for_pydantic=inf\\n\"\"\"\\n\\n```\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `gt` and `lt` constraints will be translated to `exclusiveMinimum` and `exclusiveMaximum`.\\n- `ge` and `le` constraints will be translated to `minimum` and `maximum`.\\n- `multiple_of` constraint will be translated to `multipleOf`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"positive\": {\\n      \"title\": \"Positive\",\\n      \"type\": \"integer\",\\n      \"exclusiveMinimum\": 0\\n    },\\n    \"non_negative\": {\\n      \"title\": \"Non Negative\",\\n      \"type\": \"integer\",\\n      \"minimum\": 0\\n    },\\n    \"negative\": {\\n      \"title\": \"Negative\",\\n      \"type\": \"integer\",\\n      \"exclusiveMaximum\": 0\\n    },\\n    \"non_positive\": {\\n      \"title\": \"Non Positive\",\\n      \"type\": \"integer\",\\n      \"maximum\": 0\\n    },\\n    \"even\": {\\n      \"title\": \"Even\",\\n      \"type\": \"integer\",\\n      \"multipleOf\": 2\\n    },\\n    \"love_for_pydantic\": {\\n      \"title\": \"Love For Pydantic\",\\n      \"type\": \"number\"\\n    }\\n  },\\n  \"required\": [\\n    \"positive\",\\n    \"non_negative\",\\n    \"negative\",\\n    \"non_positive\",\\n    \"even\",\\n    \"love_for_pydantic\"\\n  ]\\n}\\n\\n```\\n\\nSee the [JSON Schema Draft 2020-12](https://json-schema.org/understanding-json-schema/reference/numeric.html#numeric-types) for more details.\\n\\nConstraints on compound types\\n\\nIn case you use field constraints with compound types, an error can happen in some cases. To avoid potential issues, you can use `Annotated`:\\n\\n```python\\nfrom typing import Annotated, Optional\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: Optional[Annotated[int, Field(gt=0)]]\\n    # Can error in some cases, not recommended:\\n    non_negative: Optional[int] = Field(ge=0)\\n\\n```\\n\\n## String Constraints\\n\\nAPI Documentation\\n\\npydantic.types.StringConstraints\\n\\nThere are fields that can be used to constrain strings:\\n\\n- `min_length`: Minimum length of the string.\\n- `max_length`: Maximum length of the string.\\n- `pattern`: A regular expression that the string must match.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    short: str = Field(min_length=3)\\n    long: str = Field(max_length=10)\\n    regex: str = Field(pattern=r\\'^\\\\d*$\\')  # (1)!\\n\\n\\nfoo = Foo(short=\\'foo\\', long=\\'foobarbaz\\', regex=\\'123\\')\\nprint(foo)\\n#> short=\\'foo\\' long=\\'foobarbaz\\' regex=\\'123\\'\\n\\n```\\n\\n1. Only digits are allowed.\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `min_length` constraint will be translated to `minLength`.\\n- `max_length` constraint will be translated to `maxLength`.\\n- `pattern` constraint will be translated to `pattern`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"short\": {\\n      \"title\": \"Short\",\\n      \"type\": \"string\",\\n      \"minLength\": 3\\n    },\\n    \"long\": {\\n      \"title\": \"Long\",\\n      \"type\": \"string\",\\n      \"maxLength\": 10\\n    },\\n    \"regex\": {\\n      \"title\": \"Regex\",\\n      \"type\": \"string\",\\n      \"pattern\": \"^\\\\\\\\d*$\"\\n    }\\n  },\\n  \"required\": [\\n    \"short\",\\n    \"long\",\\n    \"regex\"\\n  ]\\n}\\n\\n```\\n\\n## Decimal Constraints\\n\\nThere are fields that can be used to constrain decimals:\\n\\n- `max_digits`: Maximum number of digits within the `Decimal`. It does not include a zero before the decimal point or trailing decimal zeroes.\\n- `decimal_places`: Maximum number of decimal places allowed. It does not include trailing decimal zeroes.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom decimal import Decimal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    precise: Decimal = Field(max_digits=5, decimal_places=2)\\n\\n\\nfoo = Foo(precise=Decimal(\\'123.45\\'))\\nprint(foo)\\n#> precise=Decimal(\\'123.45\\')\\n\\n```\\n\\n## Dataclass Constraints\\n\\nThere are fields that can be used to constrain dataclasses:\\n\\n- `init`: Whether the field should be included in the `__init__` of the dataclass.\\n- `init_var`: Whether the field should be seen as an [init-only field](https://docs.python.org/3/library/dataclasses.html#init-only-variables) in the dataclass.\\n- `kw_only`: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Foo:\\n    bar: str\\n    baz: str = Field(init_var=True)\\n    qux: str = Field(kw_only=True)\\n\\n\\nclass Model(BaseModel):\\n    foo: Foo\\n\\n\\nmodel = Model(foo=Foo(\\'bar\\', baz=\\'baz\\', qux=\\'qux\\'))\\nprint(model.model_dump())  # (1)!\\n#> {\\'foo\\': {\\'bar\\': \\'bar\\', \\'qux\\': \\'qux\\'}}\\n\\n```\\n\\n1. The `baz` field is not included in the `model_dump()` output, since it is an init-only field.\\n\\n## Field Representation\\n\\nThe parameter `repr` can be used to control whether the field should be included in the string representation of the model.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(repr=True)  # (1)!\\n    age: int = Field(repr=False)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user)\\n#> name=\\'John\\'\\n\\n```\\n\\n1. This is the default value.\\n\\n## Discriminator\\n\\nThe parameter `discriminator` can be used to control the field that will be used to discriminate between different models in a union. It takes either the name of a field or a `Discriminator` instance. The `Discriminator` approach can be useful when the discriminator fields aren\\'t the same for all the models in the `Union`.\\n\\nThe following example shows how to use `discriminator` with a field name:\\n\\n```python\\nfrom typing import Literal, Union\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Cat, Dog] = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\n```python\\nfrom typing import Literal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Cat | Dog = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\nThe following example shows how to use the `discriminator` keyword argument with a `Discriminator` instance:\\n\\n```python\\nfrom typing import Annotated, Literal, Union\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Annotated[Cat, Tag(\\'cat\\')], Annotated[Dog, Tag(\\'dog\\')]] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\n```python\\nfrom typing import Annotated, Literal\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Annotated[Cat, Tag(\\'cat\\')] | Annotated[Dog, Tag(\\'dog\\')] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\nYou can also take advantage of `Annotated` to define your discriminated unions. See the [Discriminated Unions](../unions/#discriminated-unions) docs for more details.\\n\\n## Strict Mode\\n\\nThe `strict` parameter on a Field specifies whether the field should be validated in \"strict mode\". In strict mode, Pydantic throws an error during validation instead of coercing data on the field where `strict=True`.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(strict=True)\\n    age: int = Field(strict=False)  # (1)!\\n\\n\\nuser = User(name=\\'John\\', age=\\'42\\')  # (2)!\\nprint(user)\\n#> name=\\'John\\' age=42\\n\\n```\\n\\n1. This is the default value.\\n1. The `age` field is not validated in the strict mode. Therefore, it can be assigned a string.\\n\\nSee [Strict Mode](../strict_mode/) for more details.\\n\\nSee [Conversion Table](../conversion_table/) for more details on how Pydantic converts data in both strict and lax modes.\\n\\n## Immutability\\n\\nThe parameter `frozen` is used to emulate the frozen dataclass behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability).\\n\\nSee the [frozen dataclass documentation](https://docs.python.org/3/library/dataclasses.html#frozen-instances) for more details.\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(frozen=True)\\n    age: int\\n\\n\\nuser = User(name=\\'John\\', age=42)\\n\\ntry:\\n    user.name = \\'Jane\\'  # (1)!\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    name\\n      Field is frozen [type=frozen_field, input_value=\\'Jane\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n1. Since `name` field is frozen, the assignment is not allowed.\\n\\n## Exclude\\n\\nThe `exclude` parameter can be used to control which fields should be excluded from the model when exporting the model.\\n\\nSee the following example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str\\n    age: int = Field(exclude=True)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user.model_dump())  # (1)!\\n#> {\\'name\\': \\'John\\'}\\n\\n```\\n\\n1. The `age` field is not included in the `model_dump()` output, since it is excluded.\\n\\nSee the [Serialization](../serialization/#model-and-field-level-include-and-exclude) section for more details.\\n\\n## Deprecated fields\\n\\nThe `deprecated` parameter can be used to mark a field as being deprecated. Doing so will result in:\\n\\n- a runtime deprecation warning emitted when accessing the field.\\n- `\"deprecated\": true` being set in the generated JSON schema.\\n\\nYou can set the `deprecated` parameter as one of:\\n\\n- A string, which will be used as the deprecation message.\\n- An instance of the `warnings.deprecated` decorator (or the `typing_extensions` backport).\\n- A boolean, which will be used to mark the field as deprecated with a default `\\'deprecated\\'` deprecation message.\\n\\n### `deprecated` as a string\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=\\'This is deprecated\\')]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\n### `deprecated` via the `warnings.deprecated` decorator\\n\\nNote\\n\\nYou can only use the `deprecated` decorator in this way if you have `typing_extensions` >= 4.9.0 installed.\\n\\n```python\\nimport importlib.metadata\\nfrom typing import Annotated, deprecated\\n\\nfrom packaging.version import Version\\n\\nfrom pydantic import BaseModel, Field\\n\\nif Version(importlib.metadata.version(\\'typing_extensions\\')) >= Version(\\'4.9\\'):\\n\\n    class Model(BaseModel):\\n        deprecated_field: Annotated[int, deprecated(\\'This is deprecated\\')]\\n\\n        # Or explicitly using `Field`:\\n        alt_form: Annotated[\\n            int, Field(deprecated=deprecated(\\'This is deprecated\\'))\\n        ]\\n\\n```\\n\\n### `deprecated` as a boolean\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=True)]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\nSupport for `category` and `stacklevel`\\n\\nThe current implementation of this feature does not take into account the `category` and `stacklevel` arguments to the `deprecated` decorator. This might land in a future version of Pydantic.\\n\\nAccessing a deprecated field in validators\\n\\nWhen accessing a deprecated field inside a validator, the deprecation warning will be emitted. You can use catch_warnings to explicitly ignore it:\\n\\n```python\\nimport warnings\\n\\nfrom typing_extensions import Self\\n\\nfrom pydantic import BaseModel, Field, model_validator\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: int = Field(deprecated=\\'This is deprecated\\')\\n\\n    @model_validator(mode=\\'after\\')\\n    def validate_model(self) -> Self:\\n        with warnings.catch_warnings():\\n            warnings.simplefilter(\\'ignore\\', DeprecationWarning)\\n            self.deprecated_field = self.deprecated_field * 2\\n\\n```\\n\\n## Customizing JSON Schema\\n\\nSome field parameters are used exclusively to customize the generated JSON schema. The parameters in question are:\\n\\n- `title`\\n- `description`\\n- `examples`\\n- `json_schema_extra`\\n\\nRead more about JSON schema customization / modification with fields in the [Customizing JSON Schema](../json_schema/#field-level-customization) section of the JSON schema docs.\\n\\n## The `computed_field` decorator\\n\\nAPI Documentation\\n\\ncomputed_field\\n\\nThe computed_field decorator can be used to include property or cached_property attributes when serializing a model or dataclass. The property will also be taken into account in the JSON Schema (in serialization mode).\\n\\nNote\\n\\nProperties can be useful for fields that are computed from other fields, or for fields that are expensive to be computed (and thus, are cached if using cached_property).\\n\\nHowever, note that Pydantic will *not* perform any additional logic on the wrapped property (validation, cache invalidation, etc.).\\n\\nHere\\'s an example of the JSON schema (in serialization mode) generated for a model with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property  # (1)!\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nprint(Box.model_json_schema(mode=\\'serialization\\'))\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'width\\': {\\'title\\': \\'Width\\', \\'type\\': \\'number\\'},\\n        \\'height\\': {\\'title\\': \\'Height\\', \\'type\\': \\'number\\'},\\n        \\'depth\\': {\\'title\\': \\'Depth\\', \\'type\\': \\'number\\'},\\n        \\'volume\\': {\\'readOnly\\': True, \\'title\\': \\'Volume\\', \\'type\\': \\'number\\'},\\n    },\\n    \\'required\\': [\\'width\\', \\'height\\', \\'depth\\', \\'volume\\'],\\n    \\'title\\': \\'Box\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n1. If not specified, computed_field will implicitly convert the method to a property. However, it is preferable to explicitly use the @property decorator for type checking purposes.\\n\\nHere\\'s an example using the `model_dump` method with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nb = Box(width=1, height=2, depth=3)\\nprint(b.model_dump())\\n#> {\\'width\\': 1.0, \\'height\\': 2.0, \\'depth\\': 3.0, \\'volume\\': 6.0}\\n\\n```\\n\\nAs with regular fields, computed fields can be marked as being deprecated:\\n\\n```python\\nfrom typing_extensions import deprecated\\n\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    @deprecated(\"\\'volume\\' is deprecated\")\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n```\\n'},\n",
       " {'url': 'https://docs.pydantic.dev/latest/concepts/dataclasses/index.md',\n",
       "  'text': 'API Documentation\\n\\npydantic.dataclasses.dataclass\\n\\nIf you don\\'t want to use Pydantic\\'s BaseModel you can instead get the same data validation on standard dataclasses.\\n\\n```python\\nfrom datetime import datetime\\nfrom typing import Optional\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: Optional[datetime] = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\n```python\\nfrom datetime import datetime\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: datetime | None = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\nNote\\n\\nKeep in mind that Pydantic dataclasses are **not** a replacement for [Pydantic models](../models/). They provide a similar functionality to stdlib dataclasses with the addition of Pydantic validation.\\n\\nThere are cases where subclassing using Pydantic models is the better choice.\\n\\nFor more information and discussion see [pydantic/pydantic#710](https://github.com/pydantic/pydantic/issues/710).\\n\\nSimilarities between Pydantic dataclasses and models include support for:\\n\\n- [Configuration](#dataclass-config) support\\n- [Nested](../models/#nested-models) classes\\n- [Generics](../models/#generic-models)\\n\\nSome differences between Pydantic dataclasses and models include:\\n\\n- [validators](#validators-and-initialization-hooks)\\n- The behavior with the extra configuration value\\n\\nSimilarly to Pydantic models, arguments used to instantiate the dataclass are [copied](../models/#attribute-copies).\\n\\nTo make use of the [various methods](../models/#model-methods-and-properties) to validate, dump and generate a JSON Schema, you can wrap the dataclass with a TypeAdapter and make use of its methods.\\n\\nYou can use both the Pydantic\\'s Field() and the stdlib\\'s field() functions:\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: Optional[int] = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: Optional[int] = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: int | None = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: int | None = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\nThe Pydantic `@dataclass` decorator accepts the same arguments as the standard decorator, with the addition of a `config` parameter.\\n\\n## Dataclass config\\n\\nIf you want to modify the configuration like you would with a BaseModel, you have two options:\\n\\n- Use the `config` argument of the decorator.\\n- Define the configuration with the `__pydantic_config__` attribute.\\n\\n```python\\nfrom pydantic import ConfigDict\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n# Option 1 -- using the decorator argument:\\n@dataclass(config=ConfigDict(validate_assignment=True))  # (1)!\\nclass MyDataclass1:\\n    a: int\\n\\n\\n# Option 2 -- using an attribute:\\n@dataclass\\nclass MyDataclass2:\\n    a: int\\n\\n    __pydantic_config__ = ConfigDict(validate_assignment=True)\\n\\n```\\n\\n1. You can read more about `validate_assignment` in the API reference.\\n\\nNote\\n\\nWhile Pydantic dataclasses support the extra configuration value, some default behavior of stdlib dataclasses may prevail. For example, any extra fields present on a Pydantic dataclass with extra set to `\\'allow\\'` are omitted in the dataclass\\' string representation. There is also no way to provide validation [using the `__pydantic_extra__` attribute](../models/#extra-data).\\n\\n## Rebuilding dataclass schema\\n\\nThe rebuild_dataclass() can be used to rebuild the core schema of the dataclass. See the [rebuilding model schema](../models/#rebuilding-model-schema) section for more details.\\n\\n## Stdlib dataclasses and Pydantic dataclasses\\n\\n### Inherit from stdlib dataclasses\\n\\nStdlib dataclasses (nested or not) can also be inherited and Pydantic will automatically validate all the inherited fields.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass Z:\\n    z: int\\n\\n\\n@dataclasses.dataclass\\nclass Y(Z):\\n    y: int = 0\\n\\n\\n@pydantic.dataclasses.dataclass\\nclass X(Y):\\n    x: int = 0\\n\\n\\nfoo = X(x=b\\'1\\', y=\\'2\\', z=\\'3\\')\\nprint(foo)\\n#> X(z=3, y=2, x=1)\\n\\ntry:\\n    X(z=\\'pika\\')\\nexcept pydantic.ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for X\\n    z\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'pika\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Usage of stdlib dataclasses with `BaseModel`\\n\\nWhen a standard library dataclass is used within a Pydantic model, a Pydantic dataclass or a TypeAdapter, validation will be applied (and the [configuration](#dataclass-config) stays the same). This means that using a stdlib or a Pydantic dataclass as a field annotation is functionally equivalent.\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: Optional[User] = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: User | None = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n### Using custom types\\n\\nAs said above, validation is applied on standard library dataclasses. If you make use of custom types, you will get an error when trying to refer to the dataclass. To circumvent the issue, you can set the arbitrary_types_allowed configuration value on the dataclass:\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict\\nfrom pydantic.errors import PydanticSchemaGenerationError\\n\\n\\nclass ArbitraryType:\\n    def __init__(self, value):\\n        self.value = value\\n\\n    def __repr__(self):\\n        return f\\'ArbitraryType(value={self.value!r})\\'\\n\\n\\n@dataclasses.dataclass\\nclass DC:\\n    a: ArbitraryType\\n    b: str\\n\\n\\n# valid as it is a stdlib dataclass without validation:\\nmy_dc = DC(a=ArbitraryType(value=3), b=\\'qwe\\')\\n\\ntry:\\n\\n    class Model(BaseModel):\\n        dc: DC\\n        other: str\\n\\n    # invalid as dc is now validated with pydantic, and ArbitraryType is not a known type\\n    Model(dc=my_dc, other=\\'other\\')\\n\\nexcept PydanticSchemaGenerationError as e:\\n    print(e.message)\\n    \"\"\"\\n    Unable to generate pydantic-core schema for \\n. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\\n\\n    If you got this error by calling handler(\\n) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(\\n)` since we do not call `__get_pydantic_core_schema__` on `\\n` otherwise to avoid infinite recursion.\\n    \"\"\"\\n\\n\\n# valid as we set arbitrary_types_allowed=True, and that config pushes down to the nested vanilla dataclass\\nclass Model(BaseModel):\\n    model_config = ConfigDict(arbitrary_types_allowed=True)\\n\\n    dc: DC\\n    other: str\\n\\n\\nm = Model(dc=my_dc, other=\\'other\\')\\nprint(repr(m))\\n#> Model(dc=DC(a=ArbitraryType(value=3), b=\\'qwe\\'), other=\\'other\\')\\n\\n```\\n\\n### Checking if a dataclass is a Pydantic dataclass\\n\\nPydantic dataclasses are still considered dataclasses, so using dataclasses.is_dataclass will return `True`. To check if a type is specifically a pydantic dataclass you can use the is_pydantic_dataclass function.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass StdLibDataclass:\\n    id: int\\n\\n\\nPydanticDataclass = pydantic.dataclasses.dataclass(StdLibDataclass)\\n\\nprint(dataclasses.is_dataclass(StdLibDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(StdLibDataclass))\\n#> False\\n\\nprint(dataclasses.is_dataclass(PydanticDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(PydanticDataclass))\\n#> True\\n\\n```\\n\\n## Validators and initialization hooks\\n\\nValidators also work with Pydantic dataclasses:\\n\\n```python\\nfrom pydantic import field_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass DemoDataclass:\\n    product_id: str  # should be a five-digit string, may have leading zeros\\n\\n    @field_validator(\\'product_id\\', mode=\\'before\\')\\n    @classmethod\\n    def convert_int_serial(cls, v):\\n        if isinstance(v, int):\\n            v = str(v).zfill(5)\\n        return v\\n\\n\\nprint(DemoDataclass(product_id=\\'01234\\'))\\n#> DemoDataclass(product_id=\\'01234\\')\\nprint(DemoDataclass(product_id=2468))\\n#> DemoDataclass(product_id=\\'02468\\')\\n\\n```\\n\\nThe dataclass __post_init__() method is also supported, and will be called between the calls to *before* and *after* model validators.\\n\\nExample\\n\\n```python\\nfrom pydantic_core import ArgsKwargs\\nfrom typing_extensions import Self\\n\\nfrom pydantic import model_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Birth:\\n    year: int\\n    month: int\\n    day: int\\n\\n\\n@dataclass\\nclass User:\\n    birth: Birth\\n\\n    @model_validator(mode=\\'before\\')\\n    @classmethod\\n    def before(cls, values: ArgsKwargs) -> ArgsKwargs:\\n        print(f\\'First: {values}\\')  # (1)!\\n        \"\"\"\\n        First: ArgsKwargs((), {\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n        \"\"\"\\n        return values\\n\\n    @model_validator(mode=\\'after\\')\\n    def after(self) -> Self:\\n        print(f\\'Third: {self}\\')\\n        #> Third: User(birth=Birth(year=1995, month=3, day=2))\\n        return self\\n\\n    def __post_init__(self):\\n        print(f\\'Second: {self.birth}\\')\\n        #> Second: Birth(year=1995, month=3, day=2)\\n\\n\\nuser = User(**{\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n\\n```\\n\\n1. Unlike Pydantic models, the `values` parameter is of type ArgsKwargs\\n'},\n",
       " {'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md',\n",
       "  'text': 'Provide an enhanced dataclass that performs validation.\\n\\n## dataclass\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool = False,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False\\n) -> (\\n    Callable[[type[_T]], type[PydanticDataclass]]\\n    | type[PydanticDataclass]\\n)\\n\\n```\\n\\nUsage Documentation\\n\\n[`dataclasses`](../../concepts/dataclasses/)\\n\\nA decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`, but with added validation.\\n\\nThis function should be used similarly to `dataclasses.dataclass`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `_cls` | `type[_T] | None` | The target dataclass. | `None` | | `init` | `Literal[False]` | Included for signature compatibility with dataclasses.dataclass, and is passed through to dataclasses.dataclass when appropriate. If specified, must be set to False, as pydantic inserts its own __init__ function. | `False` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `True` | | `eq` | `bool` | Determines if a __eq__ method should be generated for the class. | `True` | | `order` | `bool` | Determines if comparison magic methods should be generated, such as __lt__, but not __eq__. | `False` | | `unsafe_hash` | `bool` | Determines if a __hash__ method should be included in the class, as in dataclasses.dataclass. | `False` | | `frozen` | `bool | None` | Determines if the generated class should be a \\'frozen\\' dataclass, which does not allow its attributes to be modified after it has been initialized. If not set, the value from the provided config argument will be used (and will default to False otherwise). | `None` | | `config` | `ConfigDict | type[object] | None` | The Pydantic config to use for the dataclass. | `None` | | `validate_on_init` | `bool | None` | A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses are validated on init. | `None` | | `kw_only` | `bool` | Determines if __init__ method parameters must be specified by keyword only. Defaults to False. | `False` | | `slots` | `bool` | Determines if the generated class should be a \\'slots\\' dataclass, which does not allow the addition of new attributes after instantiation. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]` | A decorator that accepts a class as its argument and returns a Pydantic dataclass. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `AssertionError` | Raised if init is not False or validate_on_init is False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\n@dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))\\ndef dataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False,\\n) -> Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [`dataclasses`](../concepts/dataclasses.md)\\n\\n    A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,\\n    but with added validation.\\n\\n    This function should be used similarly to `dataclasses.dataclass`.\\n\\n    Args:\\n        _cls: The target `dataclass`.\\n        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to\\n            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its\\n            own  `__init__` function.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        eq: Determines if a `__eq__` method should be generated for the class.\\n        order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.\\n        unsafe_hash: Determines if a `__hash__` method should be included in the class, as in `dataclasses.dataclass`.\\n        frozen: Determines if the generated class should be a \\'frozen\\' `dataclass`, which does not allow its\\n            attributes to be modified after it has been initialized. If not set, the value from the provided `config` argument will be used (and will default to `False` otherwise).\\n        config: The Pydantic config to use for the `dataclass`.\\n        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses\\n            are validated on init.\\n        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.\\n        slots: Determines if the generated class should be a \\'slots\\' `dataclass`, which does not allow the addition of\\n            new attributes after instantiation.\\n\\n    Returns:\\n        A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.\\n\\n    Raises:\\n        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.\\n    \"\"\"\\n    assert init is False, \\'pydantic.dataclasses.dataclass only supports init=False\\'\\n    assert validate_on_init is not False, \\'validate_on_init=False is no longer supported\\'\\n\\n    if sys.version_info >= (3, 10):\\n        kwargs = {\\'kw_only\\': kw_only, \\'slots\\': slots}\\n    else:\\n        kwargs = {}\\n\\n    def make_pydantic_fields_compatible(cls: type[Any]) -> None:\\n        \"\"\"Make sure that stdlib `dataclasses` understands `Field` kwargs like `kw_only`\\n        To do that, we simply change\\n          `x: int = pydantic.Field(..., kw_only=True)`\\n        into\\n          `x: int = dataclasses.field(default=pydantic.Field(..., kw_only=True), kw_only=True)`\\n        \"\"\"\\n        for annotation_cls in cls.__mro__:\\n            annotations: dict[str, Any] = getattr(annotation_cls, \\'__annotations__\\', {})\\n            for field_name in annotations:\\n                field_value = getattr(cls, field_name, None)\\n                # Process only if this is an instance of `FieldInfo`.\\n                if not isinstance(field_value, FieldInfo):\\n                    continue\\n\\n                # Initialize arguments for the standard `dataclasses.field`.\\n                field_args: dict = {\\'default\\': field_value}\\n\\n                # Handle `kw_only` for Python 3.10+\\n                if sys.version_info >= (3, 10) and field_value.kw_only:\\n                    field_args[\\'kw_only\\'] = True\\n\\n                # Set `repr` attribute if it\\'s explicitly specified to be not `True`.\\n                if field_value.repr is not True:\\n                    field_args[\\'repr\\'] = field_value.repr\\n\\n                setattr(cls, field_name, dataclasses.field(**field_args))\\n                # In Python 3.9, when subclassing, information is pulled from cls.__dict__[\\'__annotations__\\']\\n                # for annotations, so we must make sure it\\'s initialized before we add to it.\\n                if cls.__dict__.get(\\'__annotations__\\') is None:\\n                    cls.__annotations__ = {}\\n                cls.__annotations__[field_name] = annotations[field_name]\\n\\n    def create_dataclass(cls: type[Any]) -> type[PydanticDataclass]:\\n        \"\"\"Create a Pydantic dataclass from a regular dataclass.\\n\\n        Args:\\n            cls: The class to create the Pydantic dataclass from.\\n\\n        Returns:\\n            A Pydantic dataclass.\\n        \"\"\"\\n        from ._internal._utils import is_model_class\\n\\n        if is_model_class(cls):\\n            raise PydanticUserError(\\n                f\\'Cannot create a Pydantic dataclass from {cls.__name__} as it is already a Pydantic model\\',\\n                code=\\'dataclass-on-model\\',\\n            )\\n\\n        original_cls = cls\\n\\n        # we warn on conflicting config specifications, but only if the class doesn\\'t have a dataclass base\\n        # because a dataclass base might provide a __pydantic_config__ attribute that we don\\'t want to warn about\\n        has_dataclass_base = any(dataclasses.is_dataclass(base) for base in cls.__bases__)\\n        if not has_dataclass_base and config is not None and hasattr(cls, \\'__pydantic_config__\\'):\\n            warn(\\n                f\\'`config` is set via both the `dataclass` decorator and `__pydantic_config__` for dataclass {cls.__name__}. \\'\\n                f\\'The `config` specification from `dataclass` decorator will take priority.\\',\\n                category=UserWarning,\\n                stacklevel=2,\\n            )\\n\\n        # if config is not explicitly provided, try to read it from the type\\n        config_dict = config if config is not None else getattr(cls, \\'__pydantic_config__\\', None)\\n        config_wrapper = _config.ConfigWrapper(config_dict)\\n        decorators = _decorators.DecoratorInfos.build(cls)\\n\\n        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator\\n        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,\\n        # since dataclasses.dataclass will set this as the __doc__\\n        original_doc = cls.__doc__\\n\\n        if _pydantic_dataclasses.is_builtin_dataclass(cls):\\n            # Don\\'t preserve the docstring for vanilla dataclasses, as it may include the signature\\n            # This matches v1 behavior, and there was an explicit test for it\\n            original_doc = None\\n\\n            # We don\\'t want to add validation to the existing std lib dataclass, so we will subclass it\\n            #   If the class is generic, we need to make sure the subclass also inherits from Generic\\n            #   with all the same parameters.\\n            bases = (cls,)\\n            if issubclass(cls, Generic):\\n                generic_base = Generic[cls.__parameters__]  # type: ignore\\n                bases = bases + (generic_base,)\\n            cls = types.new_class(cls.__name__, bases)\\n\\n        make_pydantic_fields_compatible(cls)\\n\\n        # Respect frozen setting from dataclass constructor and fallback to config setting if not provided\\n        if frozen is not None:\\n            frozen_ = frozen\\n            if config_wrapper.frozen:\\n                # It\\'s not recommended to define both, as the setting from the dataclass decorator will take priority.\\n                warn(\\n                    f\\'`frozen` is set via both the `dataclass` decorator and `config` for dataclass {cls.__name__!r}.\\'\\n                    \\'This is not recommended. The `frozen` specification on `dataclass` will take priority.\\',\\n                    category=UserWarning,\\n                    stacklevel=2,\\n                )\\n        else:\\n            frozen_ = config_wrapper.frozen or False\\n\\n        cls = dataclasses.dataclass(  # type: ignore[call-overload]\\n            cls,\\n            # the value of init here doesn\\'t affect anything except that it makes it easier to generate a signature\\n            init=True,\\n            repr=repr,\\n            eq=eq,\\n            order=order,\\n            unsafe_hash=unsafe_hash,\\n            frozen=frozen_,\\n            **kwargs,\\n        )\\n\\n        # This is an undocumented attribute to distinguish stdlib/Pydantic dataclasses.\\n        # It should be set as early as possible:\\n        cls.__is_pydantic_dataclass__ = True\\n\\n        cls.__pydantic_decorators__ = decorators  # type: ignore\\n        cls.__doc__ = original_doc\\n        cls.__module__ = original_cls.__module__\\n        cls.__qualname__ = original_cls.__qualname__\\n        cls.__pydantic_fields_complete__ = classmethod(_pydantic_fields_complete)\\n        cls.__pydantic_complete__ = False  # `complete_dataclass` will set it to `True` if successful.\\n        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:\\n        # fetch the parent ns using `parent_frame_namespace` (if the dataclass was defined in a function),\\n        # and possibly cache it (see the `__pydantic_parent_namespace__` logic for models).\\n        _pydantic_dataclasses.complete_dataclass(cls, config_wrapper, raise_errors=False)\\n        return cls\\n\\n    return create_dataclass if _cls is None else create_dataclass(_cls)\\n\\n```\\n\\n## rebuild_dataclass\\n\\n```python\\nrebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None\\n) -> bool | None\\n\\n```\\n\\nTry to rebuild the pydantic-core schema for the dataclass.\\n\\nThis may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.\\n\\nThis is analogous to `BaseModel.model_rebuild`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `cls` | `type[PydanticDataclass]` | The class to rebuild the pydantic-core schema for. | *required* | | `force` | `bool` | Whether to force the rebuilding of the schema, defaults to False. | `False` | | `raise_errors` | `bool` | Whether to raise errors, defaults to True. | `True` | | `_parent_namespace_depth` | `int` | The depth level of the parent namespace, defaults to 2. | `2` | | `_types_namespace` | `MappingNamespace | None` | The types namespace, defaults to None. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool | None` | Returns None if the schema is already \"complete\" and rebuilding was not required. | | `bool | None` | If rebuilding was required, returns True if rebuilding was successful, otherwise False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef rebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None,\\n) -> bool | None:\\n    \"\"\"Try to rebuild the pydantic-core schema for the dataclass.\\n\\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\\n    the initial attempt to build the schema, and automatic rebuilding fails.\\n\\n    This is analogous to `BaseModel.model_rebuild`.\\n\\n    Args:\\n        cls: The class to rebuild the pydantic-core schema for.\\n        force: Whether to force the rebuilding of the schema, defaults to `False`.\\n        raise_errors: Whether to raise errors, defaults to `True`.\\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\\n        _types_namespace: The types namespace, defaults to `None`.\\n\\n    Returns:\\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\\n    \"\"\"\\n    if not force and cls.__pydantic_complete__:\\n        return None\\n\\n    for attr in (\\'__pydantic_core_schema__\\', \\'__pydantic_validator__\\', \\'__pydantic_serializer__\\'):\\n        if attr in cls.__dict__:\\n            # Deleting the validator/serializer is necessary as otherwise they can get reused in\\n            # pydantic-core. Same applies for the core schema that can be reused in schema generation.\\n            delattr(cls, attr)\\n\\n    cls.__pydantic_complete__ = False\\n\\n    if _types_namespace is not None:\\n        rebuild_ns = _types_namespace\\n    elif _parent_namespace_depth > 0:\\n        rebuild_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}\\n    else:\\n        rebuild_ns = {}\\n\\n    ns_resolver = _namespace_utils.NsResolver(\\n        parent_namespace=rebuild_ns,\\n    )\\n\\n    return _pydantic_dataclasses.complete_dataclass(\\n        cls,\\n        _config.ConfigWrapper(cls.__pydantic_config__, check=False),\\n        raise_errors=raise_errors,\\n        ns_resolver=ns_resolver,\\n        # We could provide a different config instead (with `\\'defer_build\\'` set to `True`)\\n        # of this explicit `_force_build` argument, but because config can come from the\\n        # decorator parameter or the `__pydantic_config__` attribute, `complete_dataclass`\\n        # will overwrite `__pydantic_config__` with the provided config above:\\n        _force_build=True,\\n    )\\n\\n```\\n\\n## is_pydantic_dataclass\\n\\n```python\\nis_pydantic_dataclass(\\n    class_: type[Any],\\n) -> TypeGuard[type[PydanticDataclass]]\\n\\n```\\n\\nWhether a class is a pydantic dataclass.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `class_` | `type[Any]` | The class. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `TypeGuard[type[PydanticDataclass]]` | True if the class is a pydantic dataclass, False otherwise. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef is_pydantic_dataclass(class_: type[Any], /) -> TypeGuard[type[PydanticDataclass]]:\\n    \"\"\"Whether a class is a pydantic dataclass.\\n\\n    Args:\\n        class_: The class.\\n\\n    Returns:\\n        `True` if the class is a pydantic dataclass, `False` otherwise.\\n    \"\"\"\\n    try:\\n        return \\'__is_pydantic_dataclass__\\' in class_.__dict__ and dataclasses.is_dataclass(class_)\\n    except AttributeError:\\n        return False\\n\\n```\\n'}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap the extracted texts in a document object.\n",
    "context_document = []\n",
    "for i in page_texts:\n",
    "    doc = Document(page_content=i[\"text\"], metadata={\"url\": i[\"url\"]})\n",
    "    context_document.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'url': 'https://docs.pydantic.dev/latest/api/fields/index.md'}, page_content='Defining fields on models.\\n\\n## Field\\n\\n```python\\nField(\\n    default: ellipsis,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: _T,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    default_factory: (\\n        Callable[[], _T] | Callable[[dict[str, Any]], _T]\\n    ),\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: (\\n        Callable[[], Any]\\n        | Callable[[dict[str, Any]], Any]\\n        | None\\n    ) = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Fields](../../concepts/fields/)\\n\\nCreate a field for objects that can be configured.\\n\\nUsed to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\nNote\\n\\n- Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | Default value if the field is not set. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | `_Unset` | | `alias` | `str | None` | The name to use for the attribute when validating or serializing by alias. This is often used for things like converting between snake and camel case. | `_Unset` | | `alias_priority` | `int | None` | Priority of the alias. This affects whether an alias generator is used. | `_Unset` | | `validation_alias` | `str | AliasPath | AliasChoices | None` | Like alias, but only affects validation, not serialization. | `_Unset` | | `serialization_alias` | `str | None` | Like alias, but only affects serialization, not validation. | `_Unset` | | `title` | `str | None` | Human-readable title. | `_Unset` | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `_Unset` | | `description` | `str | None` | Human-readable description. | `_Unset` | | `examples` | `list[Any] | None` | Example values for this field. | `_Unset` | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | `_Unset` | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | `_Unset` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | `_Unset` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `_Unset` | | `frozen` | `bool | None` | Whether the field is frozen. If true, attempts to change the value on an instance will raise an error. | `_Unset` | | `validate_default` | `bool | None` | If True, apply validation to the default value every time you create an instance. Otherwise, for performance reasons, the default value of the field is trusted and not validated. | `_Unset` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `_Unset` | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `coerce_numbers_to_str` | `bool | None` | Whether to enable coercion of any Number type to str (not applicable in strict mode). | `_Unset` | | `strict` | `bool | None` | If True, strict validation is applied to the field. See Strict Mode for details. | `_Unset` | | `gt` | `SupportsGt | None` | Greater than. If set, value must be greater than this. Only applicable to numbers. | `_Unset` | | `ge` | `SupportsGe | None` | Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers. | `_Unset` | | `lt` | `SupportsLt | None` | Less than. If set, value must be less than this. Only applicable to numbers. | `_Unset` | | `le` | `SupportsLe | None` | Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers. | `_Unset` | | `multiple_of` | `float | None` | Value must be a multiple of this. Only applicable to numbers. | `_Unset` | | `min_length` | `int | None` | Minimum length for iterables. | `_Unset` | | `max_length` | `int | None` | Maximum length for iterables. | `_Unset` | | `pattern` | `str | Pattern[str] | None` | Pattern for strings (a regular expression). | `_Unset` | | `allow_inf_nan` | `bool | None` | Allow inf, -inf, nan. Only applicable to float and Decimal numbers. | `_Unset` | | `max_digits` | `int | None` | Maximum number of allow digits for strings. | `_Unset` | | `decimal_places` | `int | None` | Maximum number of decimal places allowed for numbers. | `_Unset` | | `union_mode` | `Literal[\\'smart\\', \\'left_to_right\\']` | The strategy to apply when validating a union. Can be smart (the default), or left_to_right. See Union Mode for details. | `_Unset` | | `fail_fast` | `bool | None` | If True, validation will stop on the first error. If False, all validation errors will be collected. This option can be applied only to iterable types (list, tuple, set, and frozenset). | `_Unset` | | `extra` | `Unpack[_EmptyKwargs]` | (Deprecated) Extra fields that will be included in the JSON schema. Warning The extra kwargs is deprecated. Use json_schema_extra instead. | `{}` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | A new FieldInfo. The return annotation is Any so Field can be used on type-annotated fields without causing a type error. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef Field(  # noqa: C901\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | Callable[[dict[str, Any]], Any] | None = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: str | AliasPath | AliasChoices | None = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: Callable[[str, FieldInfo], str] | None = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | types.Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: JsonDict | Callable[[JsonDict], None] | None = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | typing.Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: annotated_types.SupportsGt | None = _Unset,\\n    ge: annotated_types.SupportsGe | None = _Unset,\\n    lt: annotated_types.SupportsLt | None = _Unset,\\n    le: annotated_types.SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\\'smart\\', \\'left_to_right\\'] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs],\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Fields](../concepts/fields.md)\\n\\n    Create a field for objects that can be configured.\\n\\n    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\\n    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\n    Note:\\n        - Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\n    Args:\\n        default: Default value if the field is not set.\\n        default_factory: A callable to generate the default value. The callable can either take 0 arguments\\n            (in which case it is called as is) or a single argument containing the already validated data.\\n        alias: The name to use for the attribute when validating or serializing by alias.\\n            This is often used for things like converting between snake and camel case.\\n        alias_priority: Priority of the alias. This affects whether an alias generator is used.\\n        validation_alias: Like `alias`, but only affects validation, not serialization.\\n        serialization_alias: Like `alias`, but only affects serialization, not validation.\\n        title: Human-readable title.\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Human-readable description.\\n        examples: Example values for this field.\\n        exclude: Whether to exclude the field from the model serialization.\\n        discriminator: Field name or Discriminator for discriminating the type in a tagged union.\\n        deprecated: A deprecation message, an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport,\\n            or a boolean. If `True`, a default deprecation message will be emitted when accessing the field.\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        frozen: Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.\\n        validate_default: If `True`, apply validation to the default value every time you create an instance.\\n            Otherwise, for performance reasons, the default value of the field is trusted and not validated.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        init: Whether the field should be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        init_var: Whether the field should _only_ be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\\n        strict: If `True`, strict validation is applied to the field.\\n            See [Strict Mode](../concepts/strict_mode.md) for details.\\n        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\\n        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\\n        lt: Less than. If set, value must be less than this. Only applicable to numbers.\\n        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\\n        multiple_of: Value must be a multiple of this. Only applicable to numbers.\\n        min_length: Minimum length for iterables.\\n        max_length: Maximum length for iterables.\\n        pattern: Pattern for strings (a regular expression).\\n        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to float and [`Decimal`][decimal.Decimal] numbers.\\n        max_digits: Maximum number of allow digits for strings.\\n        decimal_places: Maximum number of decimal places allowed for numbers.\\n        union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.\\n            See [Union Mode](../concepts/unions.md#union-modes) for details.\\n        fail_fast: If `True`, validation will stop on the first error. If `False`, all validation errors will be collected.\\n            This option can be applied only to iterable types (list, tuple, set, and frozenset).\\n        extra: (Deprecated) Extra fields that will be included in the JSON schema.\\n\\n            !!! warning Deprecated\\n                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\\n\\n    Returns:\\n        A new [`FieldInfo`][pydantic.fields.FieldInfo]. The return annotation is `Any` so `Field` can be used on\\n            type-annotated fields without causing a type error.\\n    \"\"\"\\n    # Check deprecated and removed params from V1. This logic should eventually be removed.\\n    const = extra.pop(\\'const\\', None)  # type: ignore\\n    if const is not None:\\n        raise PydanticUserError(\\'`const` is removed, use `Literal` instead\\', code=\\'removed-kwargs\\')\\n\\n    min_items = extra.pop(\\'min_items\\', None)  # type: ignore\\n    if min_items is not None:\\n        warn(\\'`min_items` is deprecated and will be removed, use `min_length` instead\\', DeprecationWarning)\\n        if min_length in (None, _Unset):\\n            min_length = min_items  # type: ignore\\n\\n    max_items = extra.pop(\\'max_items\\', None)  # type: ignore\\n    if max_items is not None:\\n        warn(\\'`max_items` is deprecated and will be removed, use `max_length` instead\\', DeprecationWarning)\\n        if max_length in (None, _Unset):\\n            max_length = max_items  # type: ignore\\n\\n    unique_items = extra.pop(\\'unique_items\\', None)  # type: ignore\\n    if unique_items is not None:\\n        raise PydanticUserError(\\n            (\\n                \\'`unique_items` is removed, use `Set` instead\\'\\n                \\'(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)\\'\\n            ),\\n            code=\\'removed-kwargs\\',\\n        )\\n\\n    allow_mutation = extra.pop(\\'allow_mutation\\', None)  # type: ignore\\n    if allow_mutation is not None:\\n        warn(\\'`allow_mutation` is deprecated and will be removed. use `frozen` instead\\', DeprecationWarning)\\n        if allow_mutation is False:\\n            frozen = True\\n\\n    regex = extra.pop(\\'regex\\', None)  # type: ignore\\n    if regex is not None:\\n        raise PydanticUserError(\\'`regex` is removed. use `pattern` instead\\', code=\\'removed-kwargs\\')\\n\\n    if extra:\\n        warn(\\n            \\'Using extra keyword arguments on `Field` is deprecated and will be removed.\\'\\n            \\' Use `json_schema_extra` instead.\\'\\n            f\\' (Extra keys: {\", \".join(k.__repr__() for k in extra.keys())})\\',\\n            DeprecationWarning,\\n        )\\n        if not json_schema_extra or json_schema_extra is _Unset:\\n            json_schema_extra = extra  # type: ignore\\n\\n    if (\\n        validation_alias\\n        and validation_alias is not _Unset\\n        and not isinstance(validation_alias, (str, AliasChoices, AliasPath))\\n    ):\\n        raise TypeError(\\'Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`\\')\\n\\n    if serialization_alias in (_Unset, None) and isinstance(alias, str):\\n        serialization_alias = alias\\n\\n    if validation_alias in (_Unset, None):\\n        validation_alias = alias\\n\\n    include = extra.pop(\\'include\\', None)  # type: ignore\\n    if include is not None:\\n        warn(\\'`include` is deprecated and does nothing. It will be removed, use `exclude` instead\\', DeprecationWarning)\\n\\n    return FieldInfo.from_field(\\n        default,\\n        default_factory=default_factory,\\n        alias=alias,\\n        alias_priority=alias_priority,\\n        validation_alias=validation_alias,\\n        serialization_alias=serialization_alias,\\n        title=title,\\n        field_title_generator=field_title_generator,\\n        description=description,\\n        examples=examples,\\n        exclude=exclude,\\n        discriminator=discriminator,\\n        deprecated=deprecated,\\n        json_schema_extra=json_schema_extra,\\n        frozen=frozen,\\n        pattern=pattern,\\n        validate_default=validate_default,\\n        repr=repr,\\n        init=init,\\n        init_var=init_var,\\n        kw_only=kw_only,\\n        coerce_numbers_to_str=coerce_numbers_to_str,\\n        strict=strict,\\n        gt=gt,\\n        ge=ge,\\n        lt=lt,\\n        le=le,\\n        multiple_of=multiple_of,\\n        min_length=min_length,\\n        max_length=max_length,\\n        allow_inf_nan=allow_inf_nan,\\n        max_digits=max_digits,\\n        decimal_places=decimal_places,\\n        union_mode=union_mode,\\n        fail_fast=fail_fast,\\n    )\\n\\n```\\n\\n## FieldInfo\\n\\n```python\\nFieldInfo(**kwargs: Unpack[_FieldInfoInputs])\\n\\n```\\n\\nBases: `Representation`\\n\\nThis class holds information about a field.\\n\\n`FieldInfo` is used for any field definition regardless of whether the Field() function is explicitly used.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `FieldInfo` directly, you\\'ll only need to use it when accessing BaseModel `.model_fields` internals.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `annotation` | `type[Any] | None` | The type annotation of the field. | | `default` | `Any` | The default value of the field. | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | | `alias` | `str | None` | The alias name of the field. | | `alias_priority` | `int | None` | The priority of the field\\'s alias. | | `validation_alias` | `str | AliasPath | AliasChoices | None` | The validation alias of the field. | | `serialization_alias` | `str | None` | The serialization alias of the field. | | `title` | `str | None` | The title of the field. | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | The description of the field. | | `examples` | `list[Any] | None` | List of examples of the field. | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `frozen` | `bool | None` | Whether the field is frozen. | | `validate_default` | `bool | None` | Whether to validate the default value of the field. | | `repr` | `bool` | Whether to include the field in representation of the model. | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass, and not stored. | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. | | `metadata` | `list[Any]` | List of metadata constraints. |\\n\\nSee the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -> None:\\n    \"\"\"This class should generally not be initialized directly; instead, use the `pydantic.fields.Field` function\\n    or one of the constructor classmethods.\\n\\n    See the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n    \"\"\"\\n    self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset}\\n    kwargs = {k: _DefaultValues.get(k) if v is _Unset else v for k, v in kwargs.items()}  # type: ignore\\n    self.annotation = kwargs.get(\\'annotation\\')\\n\\n    default = kwargs.pop(\\'default\\', PydanticUndefined)\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n        self._attributes_set.pop(\\'default\\', None)\\n    else:\\n        self.default = default\\n\\n    self.default_factory = kwargs.pop(\\'default_factory\\', None)\\n\\n    if self.default is not PydanticUndefined and self.default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    self.alias = kwargs.pop(\\'alias\\', None)\\n    self.validation_alias = kwargs.pop(\\'validation_alias\\', None)\\n    self.serialization_alias = kwargs.pop(\\'serialization_alias\\', None)\\n    alias_is_set = any(alias is not None for alias in (self.alias, self.validation_alias, self.serialization_alias))\\n    self.alias_priority = kwargs.pop(\\'alias_priority\\', None) or 2 if alias_is_set else None\\n    self.title = kwargs.pop(\\'title\\', None)\\n    self.field_title_generator = kwargs.pop(\\'field_title_generator\\', None)\\n    self.description = kwargs.pop(\\'description\\', None)\\n    self.examples = kwargs.pop(\\'examples\\', None)\\n    self.exclude = kwargs.pop(\\'exclude\\', None)\\n    self.discriminator = kwargs.pop(\\'discriminator\\', None)\\n    # For compatibility with FastAPI<=0.110.0, we preserve the existing value if it is not overridden\\n    self.deprecated = kwargs.pop(\\'deprecated\\', getattr(self, \\'deprecated\\', None))\\n    self.repr = kwargs.pop(\\'repr\\', True)\\n    self.json_schema_extra = kwargs.pop(\\'json_schema_extra\\', None)\\n    self.validate_default = kwargs.pop(\\'validate_default\\', None)\\n    self.frozen = kwargs.pop(\\'frozen\\', None)\\n    # currently only used on dataclasses\\n    self.init = kwargs.pop(\\'init\\', None)\\n    self.init_var = kwargs.pop(\\'init_var\\', None)\\n    self.kw_only = kwargs.pop(\\'kw_only\\', None)\\n\\n    self.metadata = self._collect_metadata(kwargs)  # type: ignore\\n\\n    # Private attributes:\\n    self._qualifiers: set[Qualifier] = set()\\n    # Used to rebuild FieldInfo instances:\\n    self._complete = True\\n    self._original_annotation: Any = PydanticUndefined\\n    self._original_assignment: Any = PydanticUndefined\\n\\n```\\n\\n### from_field\\n\\n```python\\nfrom_field(\\n    default: Any = PydanticUndefined,\\n    **kwargs: Unpack[_FromFieldInfoInputs]\\n) -> FieldInfo\\n\\n```\\n\\nCreate a new `FieldInfo` object with the `Field` function.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The default value for the field. Defaults to Undefined. | `PydanticUndefined` | | `**kwargs` | `Unpack[_FromFieldInfoInputs]` | Additional arguments dictionary. | `{}` |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `TypeError` | If \\'annotation\\' is passed as a keyword argument. |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A new FieldInfo object with the given parameters. |\\n\\nExample\\n\\nThis is how you can create a field with default value like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = pydantic.Field(4)\\n\\n```\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_field(default: Any = PydanticUndefined, **kwargs: Unpack[_FromFieldInfoInputs]) -> FieldInfo:\\n    \"\"\"Create a new `FieldInfo` object with the `Field` function.\\n\\n    Args:\\n        default: The default value for the field. Defaults to Undefined.\\n        **kwargs: Additional arguments dictionary.\\n\\n    Raises:\\n        TypeError: If \\'annotation\\' is passed as a keyword argument.\\n\\n    Returns:\\n        A new FieldInfo object with the given parameters.\\n\\n    Example:\\n        This is how you can create a field with default value like this:\\n\\n        ```python\\n        import pydantic\\n\\n        class MyModel(pydantic.BaseModel):\\n            foo: int = pydantic.Field(4)\\n        ```\\n    \"\"\"\\n    if \\'annotation\\' in kwargs:\\n        raise TypeError(\\'\"annotation\" is not permitted as a Field keyword argument\\')\\n    return FieldInfo(default=default, **kwargs)\\n\\n````\\n\\n### from_annotation\\n\\n```python\\nfrom_annotation(\\n    annotation: type[Any],\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreates a `FieldInfo` instance from a bare annotation.\\n\\nThis function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int  # <-- like this\\n\\n```\\n\\nWe also account for the case where the annotation can be an instance of `Annotated` and where one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: Annotated[int, annotated_types.Gt(42)]\\n    bar: Annotated[int, pydantic.Field(gt=42)]\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | An annotation object. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | An instance of the field metadata. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotation(annotation: type[Any], *, _source: AnnotationSource = AnnotationSource.ANY) -> FieldInfo:\\n    \"\"\"Creates a `FieldInfo` instance from a bare annotation.\\n\\n    This function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n    ```python\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int  # <-- like this\\n    ```\\n\\n    We also account for the case where the annotation can be an instance of `Annotated` and where\\n    one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: Annotated[int, annotated_types.Gt(42)]\\n        bar: Annotated[int, pydantic.Field(gt=42)]\\n    ```\\n\\n    Args:\\n        annotation: An annotation object.\\n\\n    Returns:\\n        An instance of the field metadata.\\n    \"\"\"\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # No assigned value, this happens when using a bare `Final` qualifier (also for other\\n    # qualifiers, but they shouldn\\'t appear here). In this case we infer the type as `Any`\\n    # because we don\\'t have any assigned value.\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int`, or `field: Final[str]`:\\n        field_info = FieldInfo(annotation=type_expr, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)]`:\\n    field_info_annotations = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_info_annotations, annotation=type_expr)\\n\\n    new_field_info = field_info._copy()\\n    new_field_info.annotation = type_expr\\n    new_field_info.frozen = final or field_info.frozen\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            new_field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n        new_field_info.metadata = field_metadata\\n    new_field_info._qualifiers = inspected_ann.qualifiers\\n    return new_field_info\\n\\n````\\n\\n### from_annotated_attribute\\n\\n```python\\nfrom_annotated_attribute(\\n    annotation: type[Any],\\n    default: Any,\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreate `FieldInfo` from an annotation with a default value.\\n\\nThis is used in cases like the following:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = 4  # <-- like this\\n    bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n    spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | The type annotation of the field. | *required* | | `default` | `Any` | The default value of the field. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A field object with the passed values. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotated_attribute(\\n    annotation: type[Any], default: Any, *, _source: AnnotationSource = AnnotationSource.ANY\\n) -> FieldInfo:\\n    \"\"\"Create `FieldInfo` from an annotation with a default value.\\n\\n    This is used in cases like the following:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int = 4  # <-- like this\\n        bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n        spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n    ```\\n\\n    Args:\\n        annotation: The type annotation of the field.\\n        default: The default value of the field.\\n\\n    Returns:\\n        A field object with the passed values.\\n    \"\"\"\\n    if annotation is default:\\n        raise PydanticUserError(\\n            \\'Error when building FieldInfo from annotated attribute. \\'\\n            \"Make sure you don\\'t have any field name clashing with a type annotation.\",\\n            code=\\'unevaluable-type-annotation\\',\\n        )\\n\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # TODO infer from the default, this can be done in v3 once we treat final fields with\\n    # a default as proper fields and not class variables:\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if isinstance(default, FieldInfo):\\n        # e.g. `field: int = Field(...)`\\n        default_metadata = default.metadata.copy()\\n        default = copy(default)\\n        default.metadata = default_metadata\\n\\n        default.annotation = type_expr\\n        default.metadata += metadata\\n        merged_default = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            default,\\n            annotation=default.annotation,\\n        )\\n        merged_default.frozen = final or merged_default.frozen\\n        merged_default._qualifiers = inspected_ann.qualifiers\\n        return merged_default\\n\\n    if isinstance(default, dataclasses.Field):\\n        # `collect_dataclass_fields()` passes the dataclass Field as a default.\\n        pydantic_field = FieldInfo._from_dataclass_field(default)\\n        pydantic_field.annotation = type_expr\\n        pydantic_field.metadata += metadata\\n        pydantic_field = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            pydantic_field,\\n            annotation=pydantic_field.annotation,\\n        )\\n        pydantic_field.frozen = final or pydantic_field.frozen\\n        pydantic_field.init_var = \\'init_var\\' in inspected_ann.qualifiers\\n        pydantic_field.init = getattr(default, \\'init\\', None)\\n        pydantic_field.kw_only = getattr(default, \\'kw_only\\', None)\\n        pydantic_field._qualifiers = inspected_ann.qualifiers\\n        return pydantic_field\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\\n        field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\\n    field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n    field_info.metadata = field_metadata\\n    field_info._qualifiers = inspected_ann.qualifiers\\n    return field_info\\n\\n````\\n\\n### merge_field_infos\\n\\n```python\\nmerge_field_infos(\\n    *field_infos: FieldInfo, **overrides: Any\\n) -> FieldInfo\\n\\n```\\n\\nMerge `FieldInfo` instances keeping only explicitly set attributes.\\n\\nLater `FieldInfo` instances override earlier ones.\\n\\nReturns:\\n\\n| Name | Type | Description | | --- | --- | --- | | `FieldInfo` | `FieldInfo` | A merged FieldInfo instance. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\n@staticmethod\\ndef merge_field_infos(*field_infos: FieldInfo, **overrides: Any) -> FieldInfo:\\n    \"\"\"Merge `FieldInfo` instances keeping only explicitly set attributes.\\n\\n    Later `FieldInfo` instances override earlier ones.\\n\\n    Returns:\\n        FieldInfo: A merged FieldInfo instance.\\n    \"\"\"\\n    if len(field_infos) == 1:\\n        # No merging necessary, but we still need to make a copy and apply the overrides\\n        field_info = field_infos[0]._copy()\\n        field_info._attributes_set.update(overrides)\\n\\n        default_override = overrides.pop(\\'default\\', PydanticUndefined)\\n        if default_override is Ellipsis:\\n            default_override = PydanticUndefined\\n        if default_override is not PydanticUndefined:\\n            field_info.default = default_override\\n\\n        for k, v in overrides.items():\\n            setattr(field_info, k, v)\\n        return field_info  # type: ignore\\n\\n    merged_field_info_kwargs: dict[str, Any] = {}\\n    metadata = {}\\n    for field_info in field_infos:\\n        attributes_set = field_info._attributes_set.copy()\\n\\n        try:\\n            json_schema_extra = attributes_set.pop(\\'json_schema_extra\\')\\n            existing_json_schema_extra = merged_field_info_kwargs.get(\\'json_schema_extra\\')\\n\\n            if existing_json_schema_extra is None:\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n            if isinstance(existing_json_schema_extra, dict):\\n                if isinstance(json_schema_extra, dict):\\n                    merged_field_info_kwargs[\\'json_schema_extra\\'] = {\\n                        **existing_json_schema_extra,\\n                        **json_schema_extra,\\n                    }\\n                if callable(json_schema_extra):\\n                    warn(\\n                        \\'Composing `dict` and `callable` type `json_schema_extra` is not supported.\\'\\n                        \\'The `callable` type is being ignored.\\'\\n                        \"If you\\'d like support for this behavior, please open an issue on pydantic.\",\\n                        PydanticJsonSchemaWarning,\\n                    )\\n            elif callable(json_schema_extra):\\n                # if ever there\\'s a case of a callable, we\\'ll just keep the last json schema extra spec\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n        except KeyError:\\n            pass\\n\\n        # later FieldInfo instances override everything except json_schema_extra from earlier FieldInfo instances\\n        merged_field_info_kwargs.update(attributes_set)\\n\\n        for x in field_info.metadata:\\n            if not isinstance(x, FieldInfo):\\n                metadata[type(x)] = x\\n\\n    merged_field_info_kwargs.update(overrides)\\n    field_info = FieldInfo(**merged_field_info_kwargs)\\n    field_info.metadata = list(metadata.values())\\n    return field_info\\n\\n```\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n\\n### default_factory_takes_validated_data\\n\\n```python\\ndefault_factory_takes_validated_data: bool | None\\n\\n```\\n\\nWhether the provided default factory callable has a validated data parameter.\\n\\nReturns `None` if no default factory is set.\\n\\n### get_default\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: Literal[True],\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *, call_default_factory: Literal[False] = ...\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: bool = False,\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\nGet the default value.\\n\\nWe expose an option for whether to call the default_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via `model_construct`).\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `call_default_factory` | `bool` | Whether to call the default factory or not. | `False` | | `validated_data` | `dict[str, Any] | None` | The already validated data to be passed to the default factory. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value, calling the default factory if requested or None if not set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self, *, call_default_factory: bool = False, validated_data: dict[str, Any] | None = None) -> Any:\\n    \"\"\"Get the default value.\\n\\n    We expose an option for whether to call the default_factory (if present), as calling it may\\n    result in side effects that we want to avoid. However, there are times when it really should\\n    be called (namely, when instantiating a model via `model_construct`).\\n\\n    Args:\\n        call_default_factory: Whether to call the default factory or not.\\n        validated_data: The already validated data to be passed to the default factory.\\n\\n    Returns:\\n        The default value, calling the default factory if requested or `None` if not set.\\n    \"\"\"\\n    if self.default_factory is None:\\n        return _utils.smart_deepcopy(self.default)\\n    elif call_default_factory:\\n        if self.default_factory_takes_validated_data:\\n            fac = cast(\\'Callable[[dict[str, Any]], Any]\\', self.default_factory)\\n            if validated_data is None:\\n                raise ValueError(\\n                    \"The default factory requires the \\'validated_data\\' argument, which was not provided when calling \\'get_default\\'.\"\\n                )\\n            return fac(validated_data)\\n        else:\\n            fac = cast(\\'Callable[[], Any]\\', self.default_factory)\\n            return fac()\\n    else:\\n        return None\\n\\n```\\n\\n### is_required\\n\\n```python\\nis_required() -> bool\\n\\n```\\n\\nCheck if the field is required (i.e., does not have a default value or factory).\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool` | True if the field is required, False otherwise. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef is_required(self) -> bool:\\n    \"\"\"Check if the field is required (i.e., does not have a default value or factory).\\n\\n    Returns:\\n        `True` if the field is required, `False` otherwise.\\n    \"\"\"\\n    return self.default is PydanticUndefined and self.default_factory is None\\n\\n```\\n\\n### rebuild_annotation\\n\\n```python\\nrebuild_annotation() -> Any\\n\\n```\\n\\nAttempts to rebuild the original annotation for use in function signatures.\\n\\nIf metadata is present, it adds it to the original annotation using `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\nNote that because the metadata has been flattened, the original annotation may not be reconstructed exactly as originally provided, e.g. if the original type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The rebuilt annotation. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef rebuild_annotation(self) -> Any:\\n    \"\"\"Attempts to rebuild the original annotation for use in function signatures.\\n\\n    If metadata is present, it adds it to the original annotation using\\n    `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\n    Note that because the metadata has been flattened, the original annotation\\n    may not be reconstructed exactly as originally provided, e.g. if the original\\n    type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\n    Returns:\\n        The rebuilt annotation.\\n    \"\"\"\\n    if not self.metadata:\\n        return self.annotation\\n    else:\\n        # Annotated arguments must be a tuple\\n        return Annotated[(self.annotation, *self.metadata)]  # type: ignore\\n\\n```\\n\\n### apply_typevars_map\\n\\n```python\\napply_typevars_map(\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None\\n\\n```\\n\\nApply a `typevars_map` to the annotation.\\n\\nThis method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\nThis method applies the `typevars_map` to the annotation in place.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `typevars_map` | `Mapping[TypeVar, Any] | None` | A dictionary mapping type variables to their concrete types. | *required* | | `globalns` | `GlobalsNamespace | None` | The globals namespace to use during type annotation evaluation. | `None` | | `localns` | `MappingNamespace | None` | The locals namespace to use during type annotation evaluation. | `None` |\\n\\nSee Also\\n\\npydantic.\\\\_internal.\\\\_generics.replace_types is used for replacing the typevars with their concrete types.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef apply_typevars_map(\\n    self,\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None:\\n    \"\"\"Apply a `typevars_map` to the annotation.\\n\\n    This method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\n    This method applies the `typevars_map` to the annotation in place.\\n\\n    Args:\\n        typevars_map: A dictionary mapping type variables to their concrete types.\\n        globalns: The globals namespace to use during type annotation evaluation.\\n        localns: The locals namespace to use during type annotation evaluation.\\n\\n    See Also:\\n        pydantic._internal._generics.replace_types is used for replacing the typevars with\\n            their concrete types.\\n    \"\"\"\\n    annotation = _generics.replace_types(self.annotation, typevars_map)\\n    annotation, evaluated = _typing_extra.try_eval_type(annotation, globalns, localns)\\n    self.annotation = annotation\\n    if not evaluated:\\n        self._complete = False\\n        self._original_annotation = self.annotation\\n\\n```\\n\\n## PrivateAttr\\n\\n```python\\nPrivateAttr(\\n    default: _T, *, init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    *,\\n    default_factory: Callable[[], _T],\\n    init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(*, init: Literal[False] = False) -> Any\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Private Model Attributes](../../concepts/models/#private-model-attributes)\\n\\nIndicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\nPrivate attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\nPrivate attributes are stored in `__private_attributes__` on the model.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The attribute\\'s default value. Defaults to Undefined. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | None` | Callable that will be called when a default value is needed for this attribute. If both default and default_factory are set, an error will be raised. | `None` | | `init` | `Literal[False]` | Whether the attribute should be included in the constructor of the dataclass. Always False. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | An instance of ModelPrivateAttr class. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `ValueError` | If both default and default_factory are set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef PrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False,\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Private Model Attributes](../concepts/models.md#private-model-attributes)\\n\\n    Indicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\n    Private attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\n    Private attributes are stored in `__private_attributes__` on the model.\\n\\n    Args:\\n        default: The attribute\\'s default value. Defaults to Undefined.\\n        default_factory: Callable that will be\\n            called when a default value is needed for this attribute.\\n            If both `default` and `default_factory` are set, an error will be raised.\\n        init: Whether the attribute should be included in the constructor of the dataclass. Always `False`.\\n\\n    Returns:\\n        An instance of [`ModelPrivateAttr`][pydantic.fields.ModelPrivateAttr] class.\\n\\n    Raises:\\n        ValueError: If both `default` and `default_factory` are set.\\n    \"\"\"\\n    if default is not PydanticUndefined and default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    return ModelPrivateAttr(\\n        default,\\n        default_factory=default_factory,\\n    )\\n\\n```\\n\\n## ModelPrivateAttr\\n\\n```python\\nModelPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None\\n)\\n\\n```\\n\\nBases: `Representation`\\n\\nA descriptor for private attributes in class models.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `ModelPrivateAttr` instances directly, instead use `pydantic.fields.PrivateAttr`. (This is similar to `FieldInfo` vs. `Field`.)\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `default` | | The default value of the attribute if not provided. | | `default_factory` | | A callable function that generates the default value of the attribute if not provided. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(\\n    self, default: Any = PydanticUndefined, *, default_factory: typing.Callable[[], Any] | None = None\\n) -> None:\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n    else:\\n        self.default = default\\n    self.default_factory = default_factory\\n\\n```\\n\\n### get_default\\n\\n```python\\nget_default() -> Any\\n\\n```\\n\\nRetrieve the default value of the object.\\n\\nIf `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\nIf `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value of the object. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self) -> Any:\\n    \"\"\"Retrieve the default value of the object.\\n\\n    If `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\n    If `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\n    Returns:\\n        The default value of the object.\\n    \"\"\"\\n    return _utils.smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\\n\\n```\\n\\n## computed_field\\n\\n```python\\ncomputed_field(func: PropertyT) -> PropertyT\\n\\n```\\n\\n```python\\ncomputed_field(\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool = True,\\n    return_type: Any = PydanticUndefined\\n) -> Callable[[PropertyT], PropertyT]\\n\\n```\\n\\n```python\\ncomputed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | Callable[[PropertyT], PropertyT]\\n\\n```\\n\\nUsage Documentation\\n\\n[The `computed_field` decorator](../../concepts/fields/#the-computed_field-decorator)\\n\\nDecorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\nThis is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Rectangle(BaseModel):\\n    width: int\\n    length: int\\n\\n    @computed_field\\n    @property\\n    def area(self) -> int:\\n        return self.width * self.length\\n\\nprint(Rectangle(width=3, length=2).model_dump())\\n#> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n\\n```\\n\\nIf applied to functions not yet decorated with `@property` or `@cached_property`, the function is automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\nMypy Warning\\n\\nEven with the `@property` or `@cached_property` applied to your function before `@computed_field`, mypy may throw a `Decorated property not supported` error. See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information. To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n[pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n```python\\nimport random\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Square(BaseModel):\\n    width: float\\n\\n    @computed_field\\n    def area(self) -> float:  # converted to a `property` by `computed_field`\\n        return round(self.width**2, 2)\\n\\n    @area.setter\\n    def area(self, new_area: float) -> None:\\n        self.width = new_area**0.5\\n\\n    @computed_field(alias=\\'the magic number\\', repr=False)\\n    def random_number(self) -> int:\\n        return random.randint(0, 1_000)\\n\\nsquare = Square(width=1.3)\\n\\n# `random_number` does not appear in representation\\nprint(repr(square))\\n#> Square(width=1.3, area=1.69)\\n\\nprint(square.random_number)\\n#> 3\\n\\nsquare.area = 4\\n\\nprint(square.model_dump_json(by_alias=True))\\n#> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n\\n```\\n\\nOverriding with `computed_field`\\n\\nYou can\\'t override a field from a parent class with a `computed_field` in the child class. `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either. See the example below:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Parent(BaseModel):\\n    a: str\\n\\ntry:\\n\\n    class Child(Parent):\\n        @computed_field\\n        @property\\n        def a(self) -> str:\\n            return \\'new a\\'\\n\\nexcept TypeError as e:\\n    print(e)\\n    \\'\\'\\'\\n    Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n    \\'\\'\\'\\n\\n```\\n\\nPrivate properties decorated with `@computed_field` have `repr=False` by default.\\n\\n```python\\nfrom functools import cached_property\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Model(BaseModel):\\n    foo: int\\n\\n    @computed_field\\n    @cached_property\\n    def _private_cached_property(self) -> int:\\n        return -self.foo\\n\\n    @computed_field\\n    @property\\n    def _private_property(self) -> int:\\n        return -self.foo\\n\\nm = Model(foo=1)\\nprint(repr(m))\\n#> Model(foo=1)\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `func` | `PropertyT | None` | the function to wrap. | `None` | | `alias` | `str | None` | alias to use when serializing this computed field, only used when by_alias=True | `None` | | `alias_priority` | `int | None` | priority of the alias. This affects whether an alias generator is used | `None` | | `title` | `str | None` | Title to use when including this computed field in JSON Schema | `None` | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `None` | | `description` | `str | None` | Description to use when including this computed field in JSON Schema, defaults to the function\\'s docstring | `None` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message (or an instance of warnings.deprecated or the typing_extensions.deprecated backport). to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the deprecated decorator. | `None` | | `examples` | `list[Any] | None` | Example values to use when including this computed field in JSON Schema | `None` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `None` | | `repr` | `bool | None` | whether to include this computed field in model repr. Default is False for private properties and True for public properties. | `None` | | `return_type` | `Any` | optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a TypeError is raised. If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary objects. | `PydanticUndefined` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `PropertyT | Callable[[PropertyT], PropertyT]` | A proxy wrapper for the property. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\ndef computed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: typing.Callable[[str, ComputedFieldInfo], str] | None = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | typing.Callable[[PropertyT], PropertyT]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [The `computed_field` decorator](../concepts/fields.md#the-computed_field-decorator)\\n\\n    Decorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\n    This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Rectangle(BaseModel):\\n        width: int\\n        length: int\\n\\n        @computed_field\\n        @property\\n        def area(self) -> int:\\n            return self.width * self.length\\n\\n    print(Rectangle(width=3, length=2).model_dump())\\n    #> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n    ```\\n\\n    If applied to functions not yet decorated with `@property` or `@cached_property`, the function is\\n    automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE,\\n    and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\n    !!! warning \"Mypy Warning\"\\n        Even with the `@property` or `@cached_property` applied to your function before `@computed_field`,\\n        mypy may throw a `Decorated property not supported` error.\\n        See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information.\\n        To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n        [pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n    ```python\\n    import random\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Square(BaseModel):\\n        width: float\\n\\n        @computed_field\\n        def area(self) -> float:  # converted to a `property` by `computed_field`\\n            return round(self.width**2, 2)\\n\\n        @area.setter\\n        def area(self, new_area: float) -> None:\\n            self.width = new_area**0.5\\n\\n        @computed_field(alias=\\'the magic number\\', repr=False)\\n        def random_number(self) -> int:\\n            return random.randint(0, 1_000)\\n\\n    square = Square(width=1.3)\\n\\n    # `random_number` does not appear in representation\\n    print(repr(square))\\n    #> Square(width=1.3, area=1.69)\\n\\n    print(square.random_number)\\n    #> 3\\n\\n    square.area = 4\\n\\n    print(square.model_dump_json(by_alias=True))\\n    #> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n    ```\\n\\n    !!! warning \"Overriding with `computed_field`\"\\n        You can\\'t override a field from a parent class with a `computed_field` in the child class.\\n        `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either.\\n        See the example below:\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Parent(BaseModel):\\n        a: str\\n\\n    try:\\n\\n        class Child(Parent):\\n            @computed_field\\n            @property\\n            def a(self) -> str:\\n                return \\'new a\\'\\n\\n    except TypeError as e:\\n        print(e)\\n        \\'\\'\\'\\n        Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n        \\'\\'\\'\\n    ```\\n\\n    Private properties decorated with `@computed_field` have `repr=False` by default.\\n\\n    ```python\\n    from functools import cached_property\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Model(BaseModel):\\n        foo: int\\n\\n        @computed_field\\n        @cached_property\\n        def _private_cached_property(self) -> int:\\n            return -self.foo\\n\\n        @computed_field\\n        @property\\n        def _private_property(self) -> int:\\n            return -self.foo\\n\\n    m = Model(foo=1)\\n    print(repr(m))\\n    #> Model(foo=1)\\n    ```\\n\\n    Args:\\n        func: the function to wrap.\\n        alias: alias to use when serializing this computed field, only used when `by_alias=True`\\n        alias_priority: priority of the alias. This affects whether an alias generator is used\\n        title: Title to use when including this computed field in JSON Schema\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Description to use when including this computed field in JSON Schema, defaults to the function\\'s\\n            docstring\\n        deprecated: A deprecation message (or an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport).\\n            to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the\\n            `deprecated` decorator.\\n        examples: Example values to use when including this computed field in JSON Schema\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        repr: whether to include this computed field in model repr.\\n            Default is `False` for private properties and `True` for public properties.\\n        return_type: optional return for serialization logic to expect when serializing to JSON, if included\\n            this must be correct, otherwise a `TypeError` is raised.\\n            If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary\\n            objects.\\n\\n    Returns:\\n        A proxy wrapper for the property.\\n    \"\"\"\\n\\n    def dec(f: Any) -> Any:\\n        nonlocal description, deprecated, return_type, alias_priority\\n        unwrapped = _decorators.unwrap_wrapped_function(f)\\n\\n        if description is None and unwrapped.__doc__:\\n            description = inspect.cleandoc(unwrapped.__doc__)\\n\\n        if deprecated is None and hasattr(unwrapped, \\'__deprecated__\\'):\\n            deprecated = unwrapped.__deprecated__\\n\\n        # if the function isn\\'t already decorated with `@property` (or another descriptor), then we wrap it now\\n        f = _decorators.ensure_property(f)\\n        alias_priority = (alias_priority or 2) if alias is not None else None\\n\\n        if repr is None:\\n            repr_: bool = not _wrapped_property_is_private(property_=f)\\n        else:\\n            repr_ = repr\\n\\n        dec_info = ComputedFieldInfo(\\n            f,\\n            return_type,\\n            alias,\\n            alias_priority,\\n            title,\\n            field_title_generator,\\n            description,\\n            deprecated,\\n            examples,\\n            json_schema_extra,\\n            repr_,\\n        )\\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\\n\\n    if func is None:\\n        return dec\\n    else:\\n        return dec(func)\\n\\n````\\n\\n## ComputedFieldInfo\\n\\n```python\\nComputedFieldInfo(\\n    wrapped_property: property,\\n    return_type: Any,\\n    alias: str | None,\\n    alias_priority: int | None,\\n    title: str | None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ),\\n    description: str | None,\\n    deprecated: Deprecated | str | bool | None,\\n    examples: list[Any] | None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ),\\n    repr: bool,\\n)\\n\\n```\\n\\nA container for data from `@computed_field` so that we can access it while building the pydantic-core schema.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `decorator_repr` | `str` | A class variable representing the decorator string, \\'@computed_field\\'. | | `wrapped_property` | `property` | The wrapped computed field property. | | `return_type` | `Any` | The type of the computed field property\\'s return value. | | `alias` | `str | None` | The alias of the property to be used during serialization. | | `alias_priority` | `int | None` | The priority of the alias. This affects whether an alias generator is used. | | `title` | `str | None` | Title of the computed field to include in the serialization JSON schema. | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | Description of the computed field to include in the serialization JSON schema. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `examples` | `list[Any] | None` | Example values of the computed field to include in the serialization JSON schema. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `repr` | `bool` | A boolean indicating whether to include the field in the repr output. |\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n'),\n",
       " Document(metadata={'url': 'https://docs.pydantic.dev/latest/concepts/fields/index.md'}, page_content='API Documentation\\n\\npydantic.fields.Field\\n\\nIn this section, we will go through the available mechanisms to customize Pydantic model fields: default values, JSON Schema metadata, constraints, etc.\\n\\nTo do so, the Field() function is used a lot, and behaves the same way as the standard library field() function for dataclasses:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    name: str = Field(frozen=True)\\n\\n```\\n\\nNote\\n\\nEven though `name` is assigned a value, it is still required and has no default value. If you want to emphasize on the fact that a value must be provided, you can use the ellipsis:\\n\\n```python\\nclass Model(BaseModel):\\n    name: str = Field(..., frozen=True)\\n\\n```\\n\\nHowever, its usage is discouraged as it doesn\\'t play well with static type checkers.\\n\\n## The annotated pattern\\n\\nTo apply constraints or attach Field() functions to a model field, Pydantic supports the Annotated typing construct to attach metadata to an annotation:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field, WithJsonSchema\\n\\n\\nclass Model(BaseModel):\\n    name: Annotated[str, Field(strict=True), WithJsonSchema({\\'extra\\': \\'data\\'})]\\n\\n```\\n\\nAs far as static type checkers are concerned, `name` is still typed as `str`, but Pydantic leverages the available metadata to add validation logic, type constraints, etc.\\n\\nUsing this pattern has some advantages:\\n\\n- Using the `f: \\n = Field(...)` form can be confusing and might trick users into thinking `f` has a default value, while in reality it is still required.\\n- You can provide an arbitrary amount of metadata elements for a field. As shown in the example above, the Field() function only supports a limited set of constraints/metadata, and you may have to use different Pydantic utilities such as WithJsonSchema in some cases.\\n- Types can be made reusable (see the documentation on [custom types](../types/#using-the-annotated-pattern) using this pattern).\\n\\nHowever, note that certain arguments to the Field() function (namely, `default`, `default_factory`, and `alias`) are taken into account by static type checkers to synthesize a correct `__init__` method. The annotated pattern is *not* understood by them, so you should use the normal assignment form instead.\\n\\nTip\\n\\nThe annotated pattern can also be used to add metadata to specific parts of the type. For instance, [validation constraints](#field-constraints) can be added this way:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    int_list: list[Annotated[int, Field(gt=0)]]\\n    # Valid: [1, 3]\\n    # Invalid: [-1, 2]\\n\\n```\\n\\nBe careful not mixing *field* and *type* metadata:\\n\\n```python\\nclass Model(BaseModel):\\n    field_bad: Annotated[int, Field(deprecated=True)] | None = None  # (1)!\\n    field_ok: Annotated[int | None, Field(deprecated=True)] = None  # (2)!\\n\\n```\\n\\n1. The Field() function is applied to `int` type, hence the `deprecated` flag won\\'t have any effect. While this may be confusing given that the name of the Field() function would imply it should apply to the field, the API was designed when this function was the only way to provide metadata. You can alternatively make use of the [`annotated_types`](https://github.com/annotated-types/annotated-types) library which is now supported by Pydantic.\\n1. The Field() function is applied to the \"top-level\" union type, hence the `deprecated` flag will be applied to the field.\\n\\n## Default values\\n\\nDefault values for fields can be provided using the normal assignment syntax or by providing a value to the `default` argument:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    # Both fields aren\\'t required:\\n    name: str = \\'John Doe\\'\\n    age: int = Field(default=20)\\n\\n```\\n\\nWarning\\n\\n[In Pydantic V1](../../migration/#required-optional-and-nullable-fields), a type annotated as Any or wrapped by Optional would be given an implicit default of `None` even if no default was explicitly specified. This is no longer the case in Pydantic V2.\\n\\nYou can also pass a callable to the `default_factory` argument that will be called to generate a default value:\\n\\n```python\\nfrom uuid import uuid4\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    id: str = Field(default_factory=lambda: uuid4().hex)\\n\\n```\\n\\nThe default factory can also take a single required argument, in which case the already validated data will be passed as a dictionary.\\n\\n```python\\nfrom pydantic import BaseModel, EmailStr, Field\\n\\n\\nclass User(BaseModel):\\n    email: EmailStr\\n    username: str = Field(default_factory=lambda data: data[\\'email\\'])\\n\\n\\nuser = User(email=\\'user@example.com\\')\\nprint(user.username)\\n#> user@example.com\\n\\n```\\n\\nThe `data` argument will *only* contain the already validated data, based on the [order of model fields](../models/#field-ordering) (the above example would fail if `username` were to be defined before `email`).\\n\\n## Validate default values\\n\\nBy default, Pydantic will *not* validate default values. The `validate_default` field parameter (or the validate_default configuration value) can be used to enable this behavior:\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    age: int = Field(default=\\'twelve\\', validate_default=True)\\n\\n\\ntry:\\n    user = User()\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    age\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'twelve\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Mutable default values\\n\\nA common source of bugs in Python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call.\\n\\nThe dataclasses module actually raises an error in this case, indicating that you should use a [default factory](https://docs.python.org/3/library/dataclasses.html#default-factory-functions) instead.\\n\\nWhile the same thing can be done in Pydantic, it is not required. In the event that the default value is not hashable, Pydantic will create a deep copy of the default value when creating each instance of the model:\\n\\n```python\\nfrom pydantic import BaseModel\\n\\n\\nclass Model(BaseModel):\\n    item_counts: list[dict[str, int]] = [{}]\\n\\n\\nm1 = Model()\\nm1.item_counts[0][\\'a\\'] = 1\\nprint(m1.item_counts)\\n#> [{\\'a\\': 1}]\\n\\nm2 = Model()\\nprint(m2.item_counts)\\n#> [{}]\\n\\n```\\n\\n## Field aliases\\n\\nTip\\n\\nRead more about aliases in the [dedicated section](../alias/).\\n\\nFor validation and serialization, you can define an alias for a field.\\n\\nThere are three ways to define an alias:\\n\\n- `Field(alias=\\'foo\\')`\\n- `Field(validation_alias=\\'foo\\')`\\n- `Field(serialization_alias=\\'foo\\')`\\n\\nThe `alias` parameter is used for both validation *and* serialization. If you want to use *different* aliases for validation and serialization respectively, you can use the `validation_alias` and `serialization_alias` parameters, which will apply only in their respective use cases.\\n\\nHere is an example of using the `alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The alias `\\'username\\'` is used for instance creation and validation.\\n\\n1. We are using model_dump() to convert the model into a serializable format.\\n\\n   Note that the `by_alias` keyword argument defaults to `False`, and must be specified explicitly to dump models using the field (serialization) aliases.\\n\\n   You can also use ConfigDict.serialize_by_alias to configure this behavior at the model level.\\n\\n   When `by_alias=True`, the alias `\\'username\\'` used during serialization.\\n\\nIf you want to use an alias *only* for validation, you can use the `validation_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(validation_alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'name\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The validation alias `\\'username\\'` is used during validation.\\n1. The field name `\\'name\\'` is used during serialization.\\n\\nIf you only want to define an alias for *serialization*, you can use the `serialization_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(serialization_alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The field name `\\'name\\'` is used for validation.\\n1. The serialization alias `\\'username\\'` is used for serialization.\\n\\nAlias precedence and priority\\n\\nIn case you use `alias` together with `validation_alias` or `serialization_alias` at the same time, the `validation_alias` will have priority over `alias` for validation, and `serialization_alias` will have priority over `alias` for serialization.\\n\\nIf you provide a value for the alias_generator model setting, you can control the order of precedence for field alias and generated aliases via the `alias_priority` field parameter. You can read more about alias precedence [here](../alias/#alias-precedence).\\n\\nStatic type checking/IDE support\\n\\nIf you provide a value for the `alias` field parameter, static type checkers will use this alias instead of the actual field name to synthesize the `__init__` method:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n\\nThis means that when using the validate_by_name model setting (which allows both the field name and alias to be used during model validation), type checkers will error when the actual field name is used:\\n\\n```python\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True)\\n\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. *Not* accepted by type checkers.\\n\\nIf you still want type checkers to use the field name and not the alias, the [annotated pattern](#the-annotated-pattern) can be used (which is only understood by Pydantic):\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True, validate_by_alias=True)\\n\\n    name: Annotated[str, Field(alias=\\'username\\')]\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nuser = User(username=\\'johndoe\\')  # (2)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n1. *Not* accepted by type checkers.\\n\\n### Validation Alias\\n\\nEven though Pydantic treats `alias` and `validation_alias` the same when creating model instances, type checkers only understand the `alias` field parameter. As a workaround, you can instead specify both an `alias` and serialization_alias`(identical to the field name), as the`serialization_alias`will override the`alias\\\\` during serialization:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(validation_alias=\\'myValidationAlias\\')\\n\\n```\\n\\nwith:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(\\n        alias=\\'myValidationAlias\\',\\n        serialization_alias=\\'my_field\\',\\n    )\\n\\n\\nm = MyModel(myValidationAlias=1)\\nprint(m.model_dump(by_alias=True))\\n#> {\\'my_field\\': 1}\\n\\n```\\n\\n## Numeric Constraints\\n\\nThere are some keyword arguments that can be used to constrain numeric values:\\n\\n- `gt` - greater than\\n- `lt` - less than\\n- `ge` - greater than or equal to\\n- `le` - less than or equal to\\n- `multiple_of` - a multiple of the given number\\n- `allow_inf_nan` - allow `\\'inf\\'`, `\\'-inf\\'`, `\\'nan\\'` values\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: int = Field(gt=0)\\n    non_negative: int = Field(ge=0)\\n    negative: int = Field(lt=0)\\n    non_positive: int = Field(le=0)\\n    even: int = Field(multiple_of=2)\\n    love_for_pydantic: float = Field(allow_inf_nan=True)\\n\\n\\nfoo = Foo(\\n    positive=1,\\n    non_negative=0,\\n    negative=-1,\\n    non_positive=0,\\n    even=2,\\n    love_for_pydantic=float(\\'inf\\'),\\n)\\nprint(foo)\\n\"\"\"\\npositive=1 non_negative=0 negative=-1 non_positive=0 even=2 love_for_pydantic=inf\\n\"\"\"\\n\\n```\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `gt` and `lt` constraints will be translated to `exclusiveMinimum` and `exclusiveMaximum`.\\n- `ge` and `le` constraints will be translated to `minimum` and `maximum`.\\n- `multiple_of` constraint will be translated to `multipleOf`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"positive\": {\\n      \"title\": \"Positive\",\\n      \"type\": \"integer\",\\n      \"exclusiveMinimum\": 0\\n    },\\n    \"non_negative\": {\\n      \"title\": \"Non Negative\",\\n      \"type\": \"integer\",\\n      \"minimum\": 0\\n    },\\n    \"negative\": {\\n      \"title\": \"Negative\",\\n      \"type\": \"integer\",\\n      \"exclusiveMaximum\": 0\\n    },\\n    \"non_positive\": {\\n      \"title\": \"Non Positive\",\\n      \"type\": \"integer\",\\n      \"maximum\": 0\\n    },\\n    \"even\": {\\n      \"title\": \"Even\",\\n      \"type\": \"integer\",\\n      \"multipleOf\": 2\\n    },\\n    \"love_for_pydantic\": {\\n      \"title\": \"Love For Pydantic\",\\n      \"type\": \"number\"\\n    }\\n  },\\n  \"required\": [\\n    \"positive\",\\n    \"non_negative\",\\n    \"negative\",\\n    \"non_positive\",\\n    \"even\",\\n    \"love_for_pydantic\"\\n  ]\\n}\\n\\n```\\n\\nSee the [JSON Schema Draft 2020-12](https://json-schema.org/understanding-json-schema/reference/numeric.html#numeric-types) for more details.\\n\\nConstraints on compound types\\n\\nIn case you use field constraints with compound types, an error can happen in some cases. To avoid potential issues, you can use `Annotated`:\\n\\n```python\\nfrom typing import Annotated, Optional\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: Optional[Annotated[int, Field(gt=0)]]\\n    # Can error in some cases, not recommended:\\n    non_negative: Optional[int] = Field(ge=0)\\n\\n```\\n\\n## String Constraints\\n\\nAPI Documentation\\n\\npydantic.types.StringConstraints\\n\\nThere are fields that can be used to constrain strings:\\n\\n- `min_length`: Minimum length of the string.\\n- `max_length`: Maximum length of the string.\\n- `pattern`: A regular expression that the string must match.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    short: str = Field(min_length=3)\\n    long: str = Field(max_length=10)\\n    regex: str = Field(pattern=r\\'^\\\\d*$\\')  # (1)!\\n\\n\\nfoo = Foo(short=\\'foo\\', long=\\'foobarbaz\\', regex=\\'123\\')\\nprint(foo)\\n#> short=\\'foo\\' long=\\'foobarbaz\\' regex=\\'123\\'\\n\\n```\\n\\n1. Only digits are allowed.\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `min_length` constraint will be translated to `minLength`.\\n- `max_length` constraint will be translated to `maxLength`.\\n- `pattern` constraint will be translated to `pattern`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"short\": {\\n      \"title\": \"Short\",\\n      \"type\": \"string\",\\n      \"minLength\": 3\\n    },\\n    \"long\": {\\n      \"title\": \"Long\",\\n      \"type\": \"string\",\\n      \"maxLength\": 10\\n    },\\n    \"regex\": {\\n      \"title\": \"Regex\",\\n      \"type\": \"string\",\\n      \"pattern\": \"^\\\\\\\\d*$\"\\n    }\\n  },\\n  \"required\": [\\n    \"short\",\\n    \"long\",\\n    \"regex\"\\n  ]\\n}\\n\\n```\\n\\n## Decimal Constraints\\n\\nThere are fields that can be used to constrain decimals:\\n\\n- `max_digits`: Maximum number of digits within the `Decimal`. It does not include a zero before the decimal point or trailing decimal zeroes.\\n- `decimal_places`: Maximum number of decimal places allowed. It does not include trailing decimal zeroes.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom decimal import Decimal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    precise: Decimal = Field(max_digits=5, decimal_places=2)\\n\\n\\nfoo = Foo(precise=Decimal(\\'123.45\\'))\\nprint(foo)\\n#> precise=Decimal(\\'123.45\\')\\n\\n```\\n\\n## Dataclass Constraints\\n\\nThere are fields that can be used to constrain dataclasses:\\n\\n- `init`: Whether the field should be included in the `__init__` of the dataclass.\\n- `init_var`: Whether the field should be seen as an [init-only field](https://docs.python.org/3/library/dataclasses.html#init-only-variables) in the dataclass.\\n- `kw_only`: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Foo:\\n    bar: str\\n    baz: str = Field(init_var=True)\\n    qux: str = Field(kw_only=True)\\n\\n\\nclass Model(BaseModel):\\n    foo: Foo\\n\\n\\nmodel = Model(foo=Foo(\\'bar\\', baz=\\'baz\\', qux=\\'qux\\'))\\nprint(model.model_dump())  # (1)!\\n#> {\\'foo\\': {\\'bar\\': \\'bar\\', \\'qux\\': \\'qux\\'}}\\n\\n```\\n\\n1. The `baz` field is not included in the `model_dump()` output, since it is an init-only field.\\n\\n## Field Representation\\n\\nThe parameter `repr` can be used to control whether the field should be included in the string representation of the model.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(repr=True)  # (1)!\\n    age: int = Field(repr=False)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user)\\n#> name=\\'John\\'\\n\\n```\\n\\n1. This is the default value.\\n\\n## Discriminator\\n\\nThe parameter `discriminator` can be used to control the field that will be used to discriminate between different models in a union. It takes either the name of a field or a `Discriminator` instance. The `Discriminator` approach can be useful when the discriminator fields aren\\'t the same for all the models in the `Union`.\\n\\nThe following example shows how to use `discriminator` with a field name:\\n\\n```python\\nfrom typing import Literal, Union\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Cat, Dog] = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\n```python\\nfrom typing import Literal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Cat | Dog = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\nThe following example shows how to use the `discriminator` keyword argument with a `Discriminator` instance:\\n\\n```python\\nfrom typing import Annotated, Literal, Union\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Annotated[Cat, Tag(\\'cat\\')], Annotated[Dog, Tag(\\'dog\\')]] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\n```python\\nfrom typing import Annotated, Literal\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Annotated[Cat, Tag(\\'cat\\')] | Annotated[Dog, Tag(\\'dog\\')] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\nYou can also take advantage of `Annotated` to define your discriminated unions. See the [Discriminated Unions](../unions/#discriminated-unions) docs for more details.\\n\\n## Strict Mode\\n\\nThe `strict` parameter on a Field specifies whether the field should be validated in \"strict mode\". In strict mode, Pydantic throws an error during validation instead of coercing data on the field where `strict=True`.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(strict=True)\\n    age: int = Field(strict=False)  # (1)!\\n\\n\\nuser = User(name=\\'John\\', age=\\'42\\')  # (2)!\\nprint(user)\\n#> name=\\'John\\' age=42\\n\\n```\\n\\n1. This is the default value.\\n1. The `age` field is not validated in the strict mode. Therefore, it can be assigned a string.\\n\\nSee [Strict Mode](../strict_mode/) for more details.\\n\\nSee [Conversion Table](../conversion_table/) for more details on how Pydantic converts data in both strict and lax modes.\\n\\n## Immutability\\n\\nThe parameter `frozen` is used to emulate the frozen dataclass behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability).\\n\\nSee the [frozen dataclass documentation](https://docs.python.org/3/library/dataclasses.html#frozen-instances) for more details.\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(frozen=True)\\n    age: int\\n\\n\\nuser = User(name=\\'John\\', age=42)\\n\\ntry:\\n    user.name = \\'Jane\\'  # (1)!\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    name\\n      Field is frozen [type=frozen_field, input_value=\\'Jane\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n1. Since `name` field is frozen, the assignment is not allowed.\\n\\n## Exclude\\n\\nThe `exclude` parameter can be used to control which fields should be excluded from the model when exporting the model.\\n\\nSee the following example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str\\n    age: int = Field(exclude=True)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user.model_dump())  # (1)!\\n#> {\\'name\\': \\'John\\'}\\n\\n```\\n\\n1. The `age` field is not included in the `model_dump()` output, since it is excluded.\\n\\nSee the [Serialization](../serialization/#model-and-field-level-include-and-exclude) section for more details.\\n\\n## Deprecated fields\\n\\nThe `deprecated` parameter can be used to mark a field as being deprecated. Doing so will result in:\\n\\n- a runtime deprecation warning emitted when accessing the field.\\n- `\"deprecated\": true` being set in the generated JSON schema.\\n\\nYou can set the `deprecated` parameter as one of:\\n\\n- A string, which will be used as the deprecation message.\\n- An instance of the `warnings.deprecated` decorator (or the `typing_extensions` backport).\\n- A boolean, which will be used to mark the field as deprecated with a default `\\'deprecated\\'` deprecation message.\\n\\n### `deprecated` as a string\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=\\'This is deprecated\\')]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\n### `deprecated` via the `warnings.deprecated` decorator\\n\\nNote\\n\\nYou can only use the `deprecated` decorator in this way if you have `typing_extensions` >= 4.9.0 installed.\\n\\n```python\\nimport importlib.metadata\\nfrom typing import Annotated, deprecated\\n\\nfrom packaging.version import Version\\n\\nfrom pydantic import BaseModel, Field\\n\\nif Version(importlib.metadata.version(\\'typing_extensions\\')) >= Version(\\'4.9\\'):\\n\\n    class Model(BaseModel):\\n        deprecated_field: Annotated[int, deprecated(\\'This is deprecated\\')]\\n\\n        # Or explicitly using `Field`:\\n        alt_form: Annotated[\\n            int, Field(deprecated=deprecated(\\'This is deprecated\\'))\\n        ]\\n\\n```\\n\\n### `deprecated` as a boolean\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=True)]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\nSupport for `category` and `stacklevel`\\n\\nThe current implementation of this feature does not take into account the `category` and `stacklevel` arguments to the `deprecated` decorator. This might land in a future version of Pydantic.\\n\\nAccessing a deprecated field in validators\\n\\nWhen accessing a deprecated field inside a validator, the deprecation warning will be emitted. You can use catch_warnings to explicitly ignore it:\\n\\n```python\\nimport warnings\\n\\nfrom typing_extensions import Self\\n\\nfrom pydantic import BaseModel, Field, model_validator\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: int = Field(deprecated=\\'This is deprecated\\')\\n\\n    @model_validator(mode=\\'after\\')\\n    def validate_model(self) -> Self:\\n        with warnings.catch_warnings():\\n            warnings.simplefilter(\\'ignore\\', DeprecationWarning)\\n            self.deprecated_field = self.deprecated_field * 2\\n\\n```\\n\\n## Customizing JSON Schema\\n\\nSome field parameters are used exclusively to customize the generated JSON schema. The parameters in question are:\\n\\n- `title`\\n- `description`\\n- `examples`\\n- `json_schema_extra`\\n\\nRead more about JSON schema customization / modification with fields in the [Customizing JSON Schema](../json_schema/#field-level-customization) section of the JSON schema docs.\\n\\n## The `computed_field` decorator\\n\\nAPI Documentation\\n\\ncomputed_field\\n\\nThe computed_field decorator can be used to include property or cached_property attributes when serializing a model or dataclass. The property will also be taken into account in the JSON Schema (in serialization mode).\\n\\nNote\\n\\nProperties can be useful for fields that are computed from other fields, or for fields that are expensive to be computed (and thus, are cached if using cached_property).\\n\\nHowever, note that Pydantic will *not* perform any additional logic on the wrapped property (validation, cache invalidation, etc.).\\n\\nHere\\'s an example of the JSON schema (in serialization mode) generated for a model with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property  # (1)!\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nprint(Box.model_json_schema(mode=\\'serialization\\'))\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'width\\': {\\'title\\': \\'Width\\', \\'type\\': \\'number\\'},\\n        \\'height\\': {\\'title\\': \\'Height\\', \\'type\\': \\'number\\'},\\n        \\'depth\\': {\\'title\\': \\'Depth\\', \\'type\\': \\'number\\'},\\n        \\'volume\\': {\\'readOnly\\': True, \\'title\\': \\'Volume\\', \\'type\\': \\'number\\'},\\n    },\\n    \\'required\\': [\\'width\\', \\'height\\', \\'depth\\', \\'volume\\'],\\n    \\'title\\': \\'Box\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n1. If not specified, computed_field will implicitly convert the method to a property. However, it is preferable to explicitly use the @property decorator for type checking purposes.\\n\\nHere\\'s an example using the `model_dump` method with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nb = Box(width=1, height=2, depth=3)\\nprint(b.model_dump())\\n#> {\\'width\\': 1.0, \\'height\\': 2.0, \\'depth\\': 3.0, \\'volume\\': 6.0}\\n\\n```\\n\\nAs with regular fields, computed fields can be marked as being deprecated:\\n\\n```python\\nfrom typing_extensions import deprecated\\n\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    @deprecated(\"\\'volume\\' is deprecated\")\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n```\\n'),\n",
       " Document(metadata={'url': 'https://docs.pydantic.dev/latest/concepts/dataclasses/index.md'}, page_content='API Documentation\\n\\npydantic.dataclasses.dataclass\\n\\nIf you don\\'t want to use Pydantic\\'s BaseModel you can instead get the same data validation on standard dataclasses.\\n\\n```python\\nfrom datetime import datetime\\nfrom typing import Optional\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: Optional[datetime] = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\n```python\\nfrom datetime import datetime\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: datetime | None = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\nNote\\n\\nKeep in mind that Pydantic dataclasses are **not** a replacement for [Pydantic models](../models/). They provide a similar functionality to stdlib dataclasses with the addition of Pydantic validation.\\n\\nThere are cases where subclassing using Pydantic models is the better choice.\\n\\nFor more information and discussion see [pydantic/pydantic#710](https://github.com/pydantic/pydantic/issues/710).\\n\\nSimilarities between Pydantic dataclasses and models include support for:\\n\\n- [Configuration](#dataclass-config) support\\n- [Nested](../models/#nested-models) classes\\n- [Generics](../models/#generic-models)\\n\\nSome differences between Pydantic dataclasses and models include:\\n\\n- [validators](#validators-and-initialization-hooks)\\n- The behavior with the extra configuration value\\n\\nSimilarly to Pydantic models, arguments used to instantiate the dataclass are [copied](../models/#attribute-copies).\\n\\nTo make use of the [various methods](../models/#model-methods-and-properties) to validate, dump and generate a JSON Schema, you can wrap the dataclass with a TypeAdapter and make use of its methods.\\n\\nYou can use both the Pydantic\\'s Field() and the stdlib\\'s field() functions:\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: Optional[int] = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: Optional[int] = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: int | None = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: int | None = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\nThe Pydantic `@dataclass` decorator accepts the same arguments as the standard decorator, with the addition of a `config` parameter.\\n\\n## Dataclass config\\n\\nIf you want to modify the configuration like you would with a BaseModel, you have two options:\\n\\n- Use the `config` argument of the decorator.\\n- Define the configuration with the `__pydantic_config__` attribute.\\n\\n```python\\nfrom pydantic import ConfigDict\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n# Option 1 -- using the decorator argument:\\n@dataclass(config=ConfigDict(validate_assignment=True))  # (1)!\\nclass MyDataclass1:\\n    a: int\\n\\n\\n# Option 2 -- using an attribute:\\n@dataclass\\nclass MyDataclass2:\\n    a: int\\n\\n    __pydantic_config__ = ConfigDict(validate_assignment=True)\\n\\n```\\n\\n1. You can read more about `validate_assignment` in the API reference.\\n\\nNote\\n\\nWhile Pydantic dataclasses support the extra configuration value, some default behavior of stdlib dataclasses may prevail. For example, any extra fields present on a Pydantic dataclass with extra set to `\\'allow\\'` are omitted in the dataclass\\' string representation. There is also no way to provide validation [using the `__pydantic_extra__` attribute](../models/#extra-data).\\n\\n## Rebuilding dataclass schema\\n\\nThe rebuild_dataclass() can be used to rebuild the core schema of the dataclass. See the [rebuilding model schema](../models/#rebuilding-model-schema) section for more details.\\n\\n## Stdlib dataclasses and Pydantic dataclasses\\n\\n### Inherit from stdlib dataclasses\\n\\nStdlib dataclasses (nested or not) can also be inherited and Pydantic will automatically validate all the inherited fields.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass Z:\\n    z: int\\n\\n\\n@dataclasses.dataclass\\nclass Y(Z):\\n    y: int = 0\\n\\n\\n@pydantic.dataclasses.dataclass\\nclass X(Y):\\n    x: int = 0\\n\\n\\nfoo = X(x=b\\'1\\', y=\\'2\\', z=\\'3\\')\\nprint(foo)\\n#> X(z=3, y=2, x=1)\\n\\ntry:\\n    X(z=\\'pika\\')\\nexcept pydantic.ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for X\\n    z\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'pika\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Usage of stdlib dataclasses with `BaseModel`\\n\\nWhen a standard library dataclass is used within a Pydantic model, a Pydantic dataclass or a TypeAdapter, validation will be applied (and the [configuration](#dataclass-config) stays the same). This means that using a stdlib or a Pydantic dataclass as a field annotation is functionally equivalent.\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: Optional[User] = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: User | None = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n### Using custom types\\n\\nAs said above, validation is applied on standard library dataclasses. If you make use of custom types, you will get an error when trying to refer to the dataclass. To circumvent the issue, you can set the arbitrary_types_allowed configuration value on the dataclass:\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict\\nfrom pydantic.errors import PydanticSchemaGenerationError\\n\\n\\nclass ArbitraryType:\\n    def __init__(self, value):\\n        self.value = value\\n\\n    def __repr__(self):\\n        return f\\'ArbitraryType(value={self.value!r})\\'\\n\\n\\n@dataclasses.dataclass\\nclass DC:\\n    a: ArbitraryType\\n    b: str\\n\\n\\n# valid as it is a stdlib dataclass without validation:\\nmy_dc = DC(a=ArbitraryType(value=3), b=\\'qwe\\')\\n\\ntry:\\n\\n    class Model(BaseModel):\\n        dc: DC\\n        other: str\\n\\n    # invalid as dc is now validated with pydantic, and ArbitraryType is not a known type\\n    Model(dc=my_dc, other=\\'other\\')\\n\\nexcept PydanticSchemaGenerationError as e:\\n    print(e.message)\\n    \"\"\"\\n    Unable to generate pydantic-core schema for \\n. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\\n\\n    If you got this error by calling handler(\\n) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(\\n)` since we do not call `__get_pydantic_core_schema__` on `\\n` otherwise to avoid infinite recursion.\\n    \"\"\"\\n\\n\\n# valid as we set arbitrary_types_allowed=True, and that config pushes down to the nested vanilla dataclass\\nclass Model(BaseModel):\\n    model_config = ConfigDict(arbitrary_types_allowed=True)\\n\\n    dc: DC\\n    other: str\\n\\n\\nm = Model(dc=my_dc, other=\\'other\\')\\nprint(repr(m))\\n#> Model(dc=DC(a=ArbitraryType(value=3), b=\\'qwe\\'), other=\\'other\\')\\n\\n```\\n\\n### Checking if a dataclass is a Pydantic dataclass\\n\\nPydantic dataclasses are still considered dataclasses, so using dataclasses.is_dataclass will return `True`. To check if a type is specifically a pydantic dataclass you can use the is_pydantic_dataclass function.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass StdLibDataclass:\\n    id: int\\n\\n\\nPydanticDataclass = pydantic.dataclasses.dataclass(StdLibDataclass)\\n\\nprint(dataclasses.is_dataclass(StdLibDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(StdLibDataclass))\\n#> False\\n\\nprint(dataclasses.is_dataclass(PydanticDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(PydanticDataclass))\\n#> True\\n\\n```\\n\\n## Validators and initialization hooks\\n\\nValidators also work with Pydantic dataclasses:\\n\\n```python\\nfrom pydantic import field_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass DemoDataclass:\\n    product_id: str  # should be a five-digit string, may have leading zeros\\n\\n    @field_validator(\\'product_id\\', mode=\\'before\\')\\n    @classmethod\\n    def convert_int_serial(cls, v):\\n        if isinstance(v, int):\\n            v = str(v).zfill(5)\\n        return v\\n\\n\\nprint(DemoDataclass(product_id=\\'01234\\'))\\n#> DemoDataclass(product_id=\\'01234\\')\\nprint(DemoDataclass(product_id=2468))\\n#> DemoDataclass(product_id=\\'02468\\')\\n\\n```\\n\\nThe dataclass __post_init__() method is also supported, and will be called between the calls to *before* and *after* model validators.\\n\\nExample\\n\\n```python\\nfrom pydantic_core import ArgsKwargs\\nfrom typing_extensions import Self\\n\\nfrom pydantic import model_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Birth:\\n    year: int\\n    month: int\\n    day: int\\n\\n\\n@dataclass\\nclass User:\\n    birth: Birth\\n\\n    @model_validator(mode=\\'before\\')\\n    @classmethod\\n    def before(cls, values: ArgsKwargs) -> ArgsKwargs:\\n        print(f\\'First: {values}\\')  # (1)!\\n        \"\"\"\\n        First: ArgsKwargs((), {\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n        \"\"\"\\n        return values\\n\\n    @model_validator(mode=\\'after\\')\\n    def after(self) -> Self:\\n        print(f\\'Third: {self}\\')\\n        #> Third: User(birth=Birth(year=1995, month=3, day=2))\\n        return self\\n\\n    def __post_init__(self):\\n        print(f\\'Second: {self.birth}\\')\\n        #> Second: Birth(year=1995, month=3, day=2)\\n\\n\\nuser = User(**{\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n\\n```\\n\\n1. Unlike Pydantic models, the `values` parameter is of type ArgsKwargs\\n'),\n",
       " Document(metadata={'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md'}, page_content='Provide an enhanced dataclass that performs validation.\\n\\n## dataclass\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool = False,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False\\n) -> (\\n    Callable[[type[_T]], type[PydanticDataclass]]\\n    | type[PydanticDataclass]\\n)\\n\\n```\\n\\nUsage Documentation\\n\\n[`dataclasses`](../../concepts/dataclasses/)\\n\\nA decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`, but with added validation.\\n\\nThis function should be used similarly to `dataclasses.dataclass`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `_cls` | `type[_T] | None` | The target dataclass. | `None` | | `init` | `Literal[False]` | Included for signature compatibility with dataclasses.dataclass, and is passed through to dataclasses.dataclass when appropriate. If specified, must be set to False, as pydantic inserts its own __init__ function. | `False` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `True` | | `eq` | `bool` | Determines if a __eq__ method should be generated for the class. | `True` | | `order` | `bool` | Determines if comparison magic methods should be generated, such as __lt__, but not __eq__. | `False` | | `unsafe_hash` | `bool` | Determines if a __hash__ method should be included in the class, as in dataclasses.dataclass. | `False` | | `frozen` | `bool | None` | Determines if the generated class should be a \\'frozen\\' dataclass, which does not allow its attributes to be modified after it has been initialized. If not set, the value from the provided config argument will be used (and will default to False otherwise). | `None` | | `config` | `ConfigDict | type[object] | None` | The Pydantic config to use for the dataclass. | `None` | | `validate_on_init` | `bool | None` | A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses are validated on init. | `None` | | `kw_only` | `bool` | Determines if __init__ method parameters must be specified by keyword only. Defaults to False. | `False` | | `slots` | `bool` | Determines if the generated class should be a \\'slots\\' dataclass, which does not allow the addition of new attributes after instantiation. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]` | A decorator that accepts a class as its argument and returns a Pydantic dataclass. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `AssertionError` | Raised if init is not False or validate_on_init is False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\n@dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))\\ndef dataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False,\\n) -> Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [`dataclasses`](../concepts/dataclasses.md)\\n\\n    A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,\\n    but with added validation.\\n\\n    This function should be used similarly to `dataclasses.dataclass`.\\n\\n    Args:\\n        _cls: The target `dataclass`.\\n        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to\\n            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its\\n            own  `__init__` function.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        eq: Determines if a `__eq__` method should be generated for the class.\\n        order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.\\n        unsafe_hash: Determines if a `__hash__` method should be included in the class, as in `dataclasses.dataclass`.\\n        frozen: Determines if the generated class should be a \\'frozen\\' `dataclass`, which does not allow its\\n            attributes to be modified after it has been initialized. If not set, the value from the provided `config` argument will be used (and will default to `False` otherwise).\\n        config: The Pydantic config to use for the `dataclass`.\\n        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses\\n            are validated on init.\\n        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.\\n        slots: Determines if the generated class should be a \\'slots\\' `dataclass`, which does not allow the addition of\\n            new attributes after instantiation.\\n\\n    Returns:\\n        A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.\\n\\n    Raises:\\n        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.\\n    \"\"\"\\n    assert init is False, \\'pydantic.dataclasses.dataclass only supports init=False\\'\\n    assert validate_on_init is not False, \\'validate_on_init=False is no longer supported\\'\\n\\n    if sys.version_info >= (3, 10):\\n        kwargs = {\\'kw_only\\': kw_only, \\'slots\\': slots}\\n    else:\\n        kwargs = {}\\n\\n    def make_pydantic_fields_compatible(cls: type[Any]) -> None:\\n        \"\"\"Make sure that stdlib `dataclasses` understands `Field` kwargs like `kw_only`\\n        To do that, we simply change\\n          `x: int = pydantic.Field(..., kw_only=True)`\\n        into\\n          `x: int = dataclasses.field(default=pydantic.Field(..., kw_only=True), kw_only=True)`\\n        \"\"\"\\n        for annotation_cls in cls.__mro__:\\n            annotations: dict[str, Any] = getattr(annotation_cls, \\'__annotations__\\', {})\\n            for field_name in annotations:\\n                field_value = getattr(cls, field_name, None)\\n                # Process only if this is an instance of `FieldInfo`.\\n                if not isinstance(field_value, FieldInfo):\\n                    continue\\n\\n                # Initialize arguments for the standard `dataclasses.field`.\\n                field_args: dict = {\\'default\\': field_value}\\n\\n                # Handle `kw_only` for Python 3.10+\\n                if sys.version_info >= (3, 10) and field_value.kw_only:\\n                    field_args[\\'kw_only\\'] = True\\n\\n                # Set `repr` attribute if it\\'s explicitly specified to be not `True`.\\n                if field_value.repr is not True:\\n                    field_args[\\'repr\\'] = field_value.repr\\n\\n                setattr(cls, field_name, dataclasses.field(**field_args))\\n                # In Python 3.9, when subclassing, information is pulled from cls.__dict__[\\'__annotations__\\']\\n                # for annotations, so we must make sure it\\'s initialized before we add to it.\\n                if cls.__dict__.get(\\'__annotations__\\') is None:\\n                    cls.__annotations__ = {}\\n                cls.__annotations__[field_name] = annotations[field_name]\\n\\n    def create_dataclass(cls: type[Any]) -> type[PydanticDataclass]:\\n        \"\"\"Create a Pydantic dataclass from a regular dataclass.\\n\\n        Args:\\n            cls: The class to create the Pydantic dataclass from.\\n\\n        Returns:\\n            A Pydantic dataclass.\\n        \"\"\"\\n        from ._internal._utils import is_model_class\\n\\n        if is_model_class(cls):\\n            raise PydanticUserError(\\n                f\\'Cannot create a Pydantic dataclass from {cls.__name__} as it is already a Pydantic model\\',\\n                code=\\'dataclass-on-model\\',\\n            )\\n\\n        original_cls = cls\\n\\n        # we warn on conflicting config specifications, but only if the class doesn\\'t have a dataclass base\\n        # because a dataclass base might provide a __pydantic_config__ attribute that we don\\'t want to warn about\\n        has_dataclass_base = any(dataclasses.is_dataclass(base) for base in cls.__bases__)\\n        if not has_dataclass_base and config is not None and hasattr(cls, \\'__pydantic_config__\\'):\\n            warn(\\n                f\\'`config` is set via both the `dataclass` decorator and `__pydantic_config__` for dataclass {cls.__name__}. \\'\\n                f\\'The `config` specification from `dataclass` decorator will take priority.\\',\\n                category=UserWarning,\\n                stacklevel=2,\\n            )\\n\\n        # if config is not explicitly provided, try to read it from the type\\n        config_dict = config if config is not None else getattr(cls, \\'__pydantic_config__\\', None)\\n        config_wrapper = _config.ConfigWrapper(config_dict)\\n        decorators = _decorators.DecoratorInfos.build(cls)\\n\\n        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator\\n        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,\\n        # since dataclasses.dataclass will set this as the __doc__\\n        original_doc = cls.__doc__\\n\\n        if _pydantic_dataclasses.is_builtin_dataclass(cls):\\n            # Don\\'t preserve the docstring for vanilla dataclasses, as it may include the signature\\n            # This matches v1 behavior, and there was an explicit test for it\\n            original_doc = None\\n\\n            # We don\\'t want to add validation to the existing std lib dataclass, so we will subclass it\\n            #   If the class is generic, we need to make sure the subclass also inherits from Generic\\n            #   with all the same parameters.\\n            bases = (cls,)\\n            if issubclass(cls, Generic):\\n                generic_base = Generic[cls.__parameters__]  # type: ignore\\n                bases = bases + (generic_base,)\\n            cls = types.new_class(cls.__name__, bases)\\n\\n        make_pydantic_fields_compatible(cls)\\n\\n        # Respect frozen setting from dataclass constructor and fallback to config setting if not provided\\n        if frozen is not None:\\n            frozen_ = frozen\\n            if config_wrapper.frozen:\\n                # It\\'s not recommended to define both, as the setting from the dataclass decorator will take priority.\\n                warn(\\n                    f\\'`frozen` is set via both the `dataclass` decorator and `config` for dataclass {cls.__name__!r}.\\'\\n                    \\'This is not recommended. The `frozen` specification on `dataclass` will take priority.\\',\\n                    category=UserWarning,\\n                    stacklevel=2,\\n                )\\n        else:\\n            frozen_ = config_wrapper.frozen or False\\n\\n        cls = dataclasses.dataclass(  # type: ignore[call-overload]\\n            cls,\\n            # the value of init here doesn\\'t affect anything except that it makes it easier to generate a signature\\n            init=True,\\n            repr=repr,\\n            eq=eq,\\n            order=order,\\n            unsafe_hash=unsafe_hash,\\n            frozen=frozen_,\\n            **kwargs,\\n        )\\n\\n        # This is an undocumented attribute to distinguish stdlib/Pydantic dataclasses.\\n        # It should be set as early as possible:\\n        cls.__is_pydantic_dataclass__ = True\\n\\n        cls.__pydantic_decorators__ = decorators  # type: ignore\\n        cls.__doc__ = original_doc\\n        cls.__module__ = original_cls.__module__\\n        cls.__qualname__ = original_cls.__qualname__\\n        cls.__pydantic_fields_complete__ = classmethod(_pydantic_fields_complete)\\n        cls.__pydantic_complete__ = False  # `complete_dataclass` will set it to `True` if successful.\\n        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:\\n        # fetch the parent ns using `parent_frame_namespace` (if the dataclass was defined in a function),\\n        # and possibly cache it (see the `__pydantic_parent_namespace__` logic for models).\\n        _pydantic_dataclasses.complete_dataclass(cls, config_wrapper, raise_errors=False)\\n        return cls\\n\\n    return create_dataclass if _cls is None else create_dataclass(_cls)\\n\\n```\\n\\n## rebuild_dataclass\\n\\n```python\\nrebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None\\n) -> bool | None\\n\\n```\\n\\nTry to rebuild the pydantic-core schema for the dataclass.\\n\\nThis may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.\\n\\nThis is analogous to `BaseModel.model_rebuild`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `cls` | `type[PydanticDataclass]` | The class to rebuild the pydantic-core schema for. | *required* | | `force` | `bool` | Whether to force the rebuilding of the schema, defaults to False. | `False` | | `raise_errors` | `bool` | Whether to raise errors, defaults to True. | `True` | | `_parent_namespace_depth` | `int` | The depth level of the parent namespace, defaults to 2. | `2` | | `_types_namespace` | `MappingNamespace | None` | The types namespace, defaults to None. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool | None` | Returns None if the schema is already \"complete\" and rebuilding was not required. | | `bool | None` | If rebuilding was required, returns True if rebuilding was successful, otherwise False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef rebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None,\\n) -> bool | None:\\n    \"\"\"Try to rebuild the pydantic-core schema for the dataclass.\\n\\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\\n    the initial attempt to build the schema, and automatic rebuilding fails.\\n\\n    This is analogous to `BaseModel.model_rebuild`.\\n\\n    Args:\\n        cls: The class to rebuild the pydantic-core schema for.\\n        force: Whether to force the rebuilding of the schema, defaults to `False`.\\n        raise_errors: Whether to raise errors, defaults to `True`.\\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\\n        _types_namespace: The types namespace, defaults to `None`.\\n\\n    Returns:\\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\\n    \"\"\"\\n    if not force and cls.__pydantic_complete__:\\n        return None\\n\\n    for attr in (\\'__pydantic_core_schema__\\', \\'__pydantic_validator__\\', \\'__pydantic_serializer__\\'):\\n        if attr in cls.__dict__:\\n            # Deleting the validator/serializer is necessary as otherwise they can get reused in\\n            # pydantic-core. Same applies for the core schema that can be reused in schema generation.\\n            delattr(cls, attr)\\n\\n    cls.__pydantic_complete__ = False\\n\\n    if _types_namespace is not None:\\n        rebuild_ns = _types_namespace\\n    elif _parent_namespace_depth > 0:\\n        rebuild_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}\\n    else:\\n        rebuild_ns = {}\\n\\n    ns_resolver = _namespace_utils.NsResolver(\\n        parent_namespace=rebuild_ns,\\n    )\\n\\n    return _pydantic_dataclasses.complete_dataclass(\\n        cls,\\n        _config.ConfigWrapper(cls.__pydantic_config__, check=False),\\n        raise_errors=raise_errors,\\n        ns_resolver=ns_resolver,\\n        # We could provide a different config instead (with `\\'defer_build\\'` set to `True`)\\n        # of this explicit `_force_build` argument, but because config can come from the\\n        # decorator parameter or the `__pydantic_config__` attribute, `complete_dataclass`\\n        # will overwrite `__pydantic_config__` with the provided config above:\\n        _force_build=True,\\n    )\\n\\n```\\n\\n## is_pydantic_dataclass\\n\\n```python\\nis_pydantic_dataclass(\\n    class_: type[Any],\\n) -> TypeGuard[type[PydanticDataclass]]\\n\\n```\\n\\nWhether a class is a pydantic dataclass.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `class_` | `type[Any]` | The class. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `TypeGuard[type[PydanticDataclass]]` | True if the class is a pydantic dataclass, False otherwise. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef is_pydantic_dataclass(class_: type[Any], /) -> TypeGuard[type[PydanticDataclass]]:\\n    \"\"\"Whether a class is a pydantic dataclass.\\n\\n    Args:\\n        class_: The class.\\n\\n    Returns:\\n        `True` if the class is a pydantic dataclass, `False` otherwise.\\n    \"\"\"\\n    try:\\n        return \\'__is_pydantic_dataclass__\\' in class_.__dict__ and dataclasses.is_dataclass(class_)\\n    except AttributeError:\\n        return False\\n\\n```\\n')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the extracted text and store it in a vectorDB\n",
    "embeddings_context = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "context_vectorstore = FAISS.from_documents(\n",
    "    documents=context_document, embedding=embeddings_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set context retriever\n",
    "retriever = context_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Context Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_context = []\n",
    "for doc in context_vectorstore.similarity_search(\"What is the Fields class?\"):\n",
    "    filtered_txt = doc.page_content\n",
    "    filtered_url = doc.metadata[\"url\"]\n",
    "    filtered_context.append({\"context\": filtered_txt, \"url\": url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'context': 'Defining fields on models.\\n\\n## Field\\n\\n```python\\nField(\\n    default: ellipsis,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: _T,\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    default_factory: (\\n        Callable[[], _T] | Callable[[dict[str, Any]], _T]\\n    ),\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> _T\\n\\n```\\n\\n```python\\nField(\\n    *,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\n```python\\nField(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: (\\n        Callable[[], Any]\\n        | Callable[[dict[str, Any]], Any]\\n        | None\\n    ) = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: (\\n        str | AliasPath | AliasChoices | None\\n    ) = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: (\\n        Callable[[str, FieldInfo], str] | None\\n    ) = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: SupportsGt | None = _Unset,\\n    ge: SupportsGe | None = _Unset,\\n    lt: SupportsLt | None = _Unset,\\n    le: SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs]\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Fields](../../concepts/fields/)\\n\\nCreate a field for objects that can be configured.\\n\\nUsed to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\nNote\\n\\n- Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | Default value if the field is not set. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | `_Unset` | | `alias` | `str | None` | The name to use for the attribute when validating or serializing by alias. This is often used for things like converting between snake and camel case. | `_Unset` | | `alias_priority` | `int | None` | Priority of the alias. This affects whether an alias generator is used. | `_Unset` | | `validation_alias` | `str | AliasPath | AliasChoices | None` | Like alias, but only affects validation, not serialization. | `_Unset` | | `serialization_alias` | `str | None` | Like alias, but only affects serialization, not validation. | `_Unset` | | `title` | `str | None` | Human-readable title. | `_Unset` | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `_Unset` | | `description` | `str | None` | Human-readable description. | `_Unset` | | `examples` | `list[Any] | None` | Example values for this field. | `_Unset` | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | `_Unset` | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | `_Unset` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | `_Unset` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `_Unset` | | `frozen` | `bool | None` | Whether the field is frozen. If true, attempts to change the value on an instance will raise an error. | `_Unset` | | `validate_default` | `bool | None` | If True, apply validation to the default value every time you create an instance. Otherwise, for performance reasons, the default value of the field is trusted and not validated. | `_Unset` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `_Unset` | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. (Only applies to dataclasses.) | `_Unset` | | `coerce_numbers_to_str` | `bool | None` | Whether to enable coercion of any Number type to str (not applicable in strict mode). | `_Unset` | | `strict` | `bool | None` | If True, strict validation is applied to the field. See Strict Mode for details. | `_Unset` | | `gt` | `SupportsGt | None` | Greater than. If set, value must be greater than this. Only applicable to numbers. | `_Unset` | | `ge` | `SupportsGe | None` | Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers. | `_Unset` | | `lt` | `SupportsLt | None` | Less than. If set, value must be less than this. Only applicable to numbers. | `_Unset` | | `le` | `SupportsLe | None` | Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers. | `_Unset` | | `multiple_of` | `float | None` | Value must be a multiple of this. Only applicable to numbers. | `_Unset` | | `min_length` | `int | None` | Minimum length for iterables. | `_Unset` | | `max_length` | `int | None` | Maximum length for iterables. | `_Unset` | | `pattern` | `str | Pattern[str] | None` | Pattern for strings (a regular expression). | `_Unset` | | `allow_inf_nan` | `bool | None` | Allow inf, -inf, nan. Only applicable to float and Decimal numbers. | `_Unset` | | `max_digits` | `int | None` | Maximum number of allow digits for strings. | `_Unset` | | `decimal_places` | `int | None` | Maximum number of decimal places allowed for numbers. | `_Unset` | | `union_mode` | `Literal[\\'smart\\', \\'left_to_right\\']` | The strategy to apply when validating a union. Can be smart (the default), or left_to_right. See Union Mode for details. | `_Unset` | | `fail_fast` | `bool | None` | If True, validation will stop on the first error. If False, all validation errors will be collected. This option can be applied only to iterable types (list, tuple, set, and frozenset). | `_Unset` | | `extra` | `Unpack[_EmptyKwargs]` | (Deprecated) Extra fields that will be included in the JSON schema. Warning The extra kwargs is deprecated. Use json_schema_extra instead. | `{}` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | A new FieldInfo. The return annotation is Any so Field can be used on type-annotated fields without causing a type error. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef Field(  # noqa: C901\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | Callable[[dict[str, Any]], Any] | None = _Unset,\\n    alias: str | None = _Unset,\\n    alias_priority: int | None = _Unset,\\n    validation_alias: str | AliasPath | AliasChoices | None = _Unset,\\n    serialization_alias: str | None = _Unset,\\n    title: str | None = _Unset,\\n    field_title_generator: Callable[[str, FieldInfo], str] | None = _Unset,\\n    description: str | None = _Unset,\\n    examples: list[Any] | None = _Unset,\\n    exclude: bool | None = _Unset,\\n    discriminator: str | types.Discriminator | None = _Unset,\\n    deprecated: Deprecated | str | bool | None = _Unset,\\n    json_schema_extra: JsonDict | Callable[[JsonDict], None] | None = _Unset,\\n    frozen: bool | None = _Unset,\\n    validate_default: bool | None = _Unset,\\n    repr: bool = _Unset,\\n    init: bool | None = _Unset,\\n    init_var: bool | None = _Unset,\\n    kw_only: bool | None = _Unset,\\n    pattern: str | typing.Pattern[str] | None = _Unset,\\n    strict: bool | None = _Unset,\\n    coerce_numbers_to_str: bool | None = _Unset,\\n    gt: annotated_types.SupportsGt | None = _Unset,\\n    ge: annotated_types.SupportsGe | None = _Unset,\\n    lt: annotated_types.SupportsLt | None = _Unset,\\n    le: annotated_types.SupportsLe | None = _Unset,\\n    multiple_of: float | None = _Unset,\\n    allow_inf_nan: bool | None = _Unset,\\n    max_digits: int | None = _Unset,\\n    decimal_places: int | None = _Unset,\\n    min_length: int | None = _Unset,\\n    max_length: int | None = _Unset,\\n    union_mode: Literal[\\'smart\\', \\'left_to_right\\'] = _Unset,\\n    fail_fast: bool | None = _Unset,\\n    **extra: Unpack[_EmptyKwargs],\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Fields](../concepts/fields.md)\\n\\n    Create a field for objects that can be configured.\\n\\n    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\\n    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\\n\\n    Note:\\n        - Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\\n\\n    Args:\\n        default: Default value if the field is not set.\\n        default_factory: A callable to generate the default value. The callable can either take 0 arguments\\n            (in which case it is called as is) or a single argument containing the already validated data.\\n        alias: The name to use for the attribute when validating or serializing by alias.\\n            This is often used for things like converting between snake and camel case.\\n        alias_priority: Priority of the alias. This affects whether an alias generator is used.\\n        validation_alias: Like `alias`, but only affects validation, not serialization.\\n        serialization_alias: Like `alias`, but only affects serialization, not validation.\\n        title: Human-readable title.\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Human-readable description.\\n        examples: Example values for this field.\\n        exclude: Whether to exclude the field from the model serialization.\\n        discriminator: Field name or Discriminator for discriminating the type in a tagged union.\\n        deprecated: A deprecation message, an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport,\\n            or a boolean. If `True`, a default deprecation message will be emitted when accessing the field.\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        frozen: Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.\\n        validate_default: If `True`, apply validation to the default value every time you create an instance.\\n            Otherwise, for performance reasons, the default value of the field is trusted and not validated.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        init: Whether the field should be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        init_var: Whether the field should _only_ be included in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n            (Only applies to dataclasses.)\\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\\n        strict: If `True`, strict validation is applied to the field.\\n            See [Strict Mode](../concepts/strict_mode.md) for details.\\n        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\\n        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\\n        lt: Less than. If set, value must be less than this. Only applicable to numbers.\\n        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\\n        multiple_of: Value must be a multiple of this. Only applicable to numbers.\\n        min_length: Minimum length for iterables.\\n        max_length: Maximum length for iterables.\\n        pattern: Pattern for strings (a regular expression).\\n        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to float and [`Decimal`][decimal.Decimal] numbers.\\n        max_digits: Maximum number of allow digits for strings.\\n        decimal_places: Maximum number of decimal places allowed for numbers.\\n        union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.\\n            See [Union Mode](../concepts/unions.md#union-modes) for details.\\n        fail_fast: If `True`, validation will stop on the first error. If `False`, all validation errors will be collected.\\n            This option can be applied only to iterable types (list, tuple, set, and frozenset).\\n        extra: (Deprecated) Extra fields that will be included in the JSON schema.\\n\\n            !!! warning Deprecated\\n                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\\n\\n    Returns:\\n        A new [`FieldInfo`][pydantic.fields.FieldInfo]. The return annotation is `Any` so `Field` can be used on\\n            type-annotated fields without causing a type error.\\n    \"\"\"\\n    # Check deprecated and removed params from V1. This logic should eventually be removed.\\n    const = extra.pop(\\'const\\', None)  # type: ignore\\n    if const is not None:\\n        raise PydanticUserError(\\'`const` is removed, use `Literal` instead\\', code=\\'removed-kwargs\\')\\n\\n    min_items = extra.pop(\\'min_items\\', None)  # type: ignore\\n    if min_items is not None:\\n        warn(\\'`min_items` is deprecated and will be removed, use `min_length` instead\\', DeprecationWarning)\\n        if min_length in (None, _Unset):\\n            min_length = min_items  # type: ignore\\n\\n    max_items = extra.pop(\\'max_items\\', None)  # type: ignore\\n    if max_items is not None:\\n        warn(\\'`max_items` is deprecated and will be removed, use `max_length` instead\\', DeprecationWarning)\\n        if max_length in (None, _Unset):\\n            max_length = max_items  # type: ignore\\n\\n    unique_items = extra.pop(\\'unique_items\\', None)  # type: ignore\\n    if unique_items is not None:\\n        raise PydanticUserError(\\n            (\\n                \\'`unique_items` is removed, use `Set` instead\\'\\n                \\'(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)\\'\\n            ),\\n            code=\\'removed-kwargs\\',\\n        )\\n\\n    allow_mutation = extra.pop(\\'allow_mutation\\', None)  # type: ignore\\n    if allow_mutation is not None:\\n        warn(\\'`allow_mutation` is deprecated and will be removed. use `frozen` instead\\', DeprecationWarning)\\n        if allow_mutation is False:\\n            frozen = True\\n\\n    regex = extra.pop(\\'regex\\', None)  # type: ignore\\n    if regex is not None:\\n        raise PydanticUserError(\\'`regex` is removed. use `pattern` instead\\', code=\\'removed-kwargs\\')\\n\\n    if extra:\\n        warn(\\n            \\'Using extra keyword arguments on `Field` is deprecated and will be removed.\\'\\n            \\' Use `json_schema_extra` instead.\\'\\n            f\\' (Extra keys: {\", \".join(k.__repr__() for k in extra.keys())})\\',\\n            DeprecationWarning,\\n        )\\n        if not json_schema_extra or json_schema_extra is _Unset:\\n            json_schema_extra = extra  # type: ignore\\n\\n    if (\\n        validation_alias\\n        and validation_alias is not _Unset\\n        and not isinstance(validation_alias, (str, AliasChoices, AliasPath))\\n    ):\\n        raise TypeError(\\'Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`\\')\\n\\n    if serialization_alias in (_Unset, None) and isinstance(alias, str):\\n        serialization_alias = alias\\n\\n    if validation_alias in (_Unset, None):\\n        validation_alias = alias\\n\\n    include = extra.pop(\\'include\\', None)  # type: ignore\\n    if include is not None:\\n        warn(\\'`include` is deprecated and does nothing. It will be removed, use `exclude` instead\\', DeprecationWarning)\\n\\n    return FieldInfo.from_field(\\n        default,\\n        default_factory=default_factory,\\n        alias=alias,\\n        alias_priority=alias_priority,\\n        validation_alias=validation_alias,\\n        serialization_alias=serialization_alias,\\n        title=title,\\n        field_title_generator=field_title_generator,\\n        description=description,\\n        examples=examples,\\n        exclude=exclude,\\n        discriminator=discriminator,\\n        deprecated=deprecated,\\n        json_schema_extra=json_schema_extra,\\n        frozen=frozen,\\n        pattern=pattern,\\n        validate_default=validate_default,\\n        repr=repr,\\n        init=init,\\n        init_var=init_var,\\n        kw_only=kw_only,\\n        coerce_numbers_to_str=coerce_numbers_to_str,\\n        strict=strict,\\n        gt=gt,\\n        ge=ge,\\n        lt=lt,\\n        le=le,\\n        multiple_of=multiple_of,\\n        min_length=min_length,\\n        max_length=max_length,\\n        allow_inf_nan=allow_inf_nan,\\n        max_digits=max_digits,\\n        decimal_places=decimal_places,\\n        union_mode=union_mode,\\n        fail_fast=fail_fast,\\n    )\\n\\n```\\n\\n## FieldInfo\\n\\n```python\\nFieldInfo(**kwargs: Unpack[_FieldInfoInputs])\\n\\n```\\n\\nBases: `Representation`\\n\\nThis class holds information about a field.\\n\\n`FieldInfo` is used for any field definition regardless of whether the Field() function is explicitly used.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `FieldInfo` directly, you\\'ll only need to use it when accessing BaseModel `.model_fields` internals.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `annotation` | `type[Any] | None` | The type annotation of the field. | | `default` | `Any` | The default value of the field. | | `default_factory` | `Callable[[], Any] | Callable[[dict[str, Any]], Any] | None` | A callable to generate the default value. The callable can either take 0 arguments (in which case it is called as is) or a single argument containing the already validated data. | | `alias` | `str | None` | The alias name of the field. | | `alias_priority` | `int | None` | The priority of the field\\'s alias. | | `validation_alias` | `str | AliasPath | AliasChoices | None` | The validation alias of the field. | | `serialization_alias` | `str | None` | The serialization alias of the field. | | `title` | `str | None` | The title of the field. | | `field_title_generator` | `Callable[[str, FieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | The description of the field. | | `examples` | `list[Any] | None` | List of examples of the field. | | `exclude` | `bool | None` | Whether to exclude the field from the model serialization. | | `discriminator` | `str | Discriminator | None` | Field name or Discriminator for discriminating the type in a tagged union. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `frozen` | `bool | None` | Whether the field is frozen. | | `validate_default` | `bool | None` | Whether to validate the default value of the field. | | `repr` | `bool` | Whether to include the field in representation of the model. | | `init` | `bool | None` | Whether the field should be included in the constructor of the dataclass. | | `init_var` | `bool | None` | Whether the field should only be included in the constructor of the dataclass, and not stored. | | `kw_only` | `bool | None` | Whether the field should be a keyword-only argument in the constructor of the dataclass. | | `metadata` | `list[Any]` | List of metadata constraints. |\\n\\nSee the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -> None:\\n    \"\"\"This class should generally not be initialized directly; instead, use the `pydantic.fields.Field` function\\n    or one of the constructor classmethods.\\n\\n    See the signature of `pydantic.fields.Field` for more details about the expected arguments.\\n    \"\"\"\\n    self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset}\\n    kwargs = {k: _DefaultValues.get(k) if v is _Unset else v for k, v in kwargs.items()}  # type: ignore\\n    self.annotation = kwargs.get(\\'annotation\\')\\n\\n    default = kwargs.pop(\\'default\\', PydanticUndefined)\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n        self._attributes_set.pop(\\'default\\', None)\\n    else:\\n        self.default = default\\n\\n    self.default_factory = kwargs.pop(\\'default_factory\\', None)\\n\\n    if self.default is not PydanticUndefined and self.default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    self.alias = kwargs.pop(\\'alias\\', None)\\n    self.validation_alias = kwargs.pop(\\'validation_alias\\', None)\\n    self.serialization_alias = kwargs.pop(\\'serialization_alias\\', None)\\n    alias_is_set = any(alias is not None for alias in (self.alias, self.validation_alias, self.serialization_alias))\\n    self.alias_priority = kwargs.pop(\\'alias_priority\\', None) or 2 if alias_is_set else None\\n    self.title = kwargs.pop(\\'title\\', None)\\n    self.field_title_generator = kwargs.pop(\\'field_title_generator\\', None)\\n    self.description = kwargs.pop(\\'description\\', None)\\n    self.examples = kwargs.pop(\\'examples\\', None)\\n    self.exclude = kwargs.pop(\\'exclude\\', None)\\n    self.discriminator = kwargs.pop(\\'discriminator\\', None)\\n    # For compatibility with FastAPI<=0.110.0, we preserve the existing value if it is not overridden\\n    self.deprecated = kwargs.pop(\\'deprecated\\', getattr(self, \\'deprecated\\', None))\\n    self.repr = kwargs.pop(\\'repr\\', True)\\n    self.json_schema_extra = kwargs.pop(\\'json_schema_extra\\', None)\\n    self.validate_default = kwargs.pop(\\'validate_default\\', None)\\n    self.frozen = kwargs.pop(\\'frozen\\', None)\\n    # currently only used on dataclasses\\n    self.init = kwargs.pop(\\'init\\', None)\\n    self.init_var = kwargs.pop(\\'init_var\\', None)\\n    self.kw_only = kwargs.pop(\\'kw_only\\', None)\\n\\n    self.metadata = self._collect_metadata(kwargs)  # type: ignore\\n\\n    # Private attributes:\\n    self._qualifiers: set[Qualifier] = set()\\n    # Used to rebuild FieldInfo instances:\\n    self._complete = True\\n    self._original_annotation: Any = PydanticUndefined\\n    self._original_assignment: Any = PydanticUndefined\\n\\n```\\n\\n### from_field\\n\\n```python\\nfrom_field(\\n    default: Any = PydanticUndefined,\\n    **kwargs: Unpack[_FromFieldInfoInputs]\\n) -> FieldInfo\\n\\n```\\n\\nCreate a new `FieldInfo` object with the `Field` function.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The default value for the field. Defaults to Undefined. | `PydanticUndefined` | | `**kwargs` | `Unpack[_FromFieldInfoInputs]` | Additional arguments dictionary. | `{}` |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `TypeError` | If \\'annotation\\' is passed as a keyword argument. |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A new FieldInfo object with the given parameters. |\\n\\nExample\\n\\nThis is how you can create a field with default value like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = pydantic.Field(4)\\n\\n```\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_field(default: Any = PydanticUndefined, **kwargs: Unpack[_FromFieldInfoInputs]) -> FieldInfo:\\n    \"\"\"Create a new `FieldInfo` object with the `Field` function.\\n\\n    Args:\\n        default: The default value for the field. Defaults to Undefined.\\n        **kwargs: Additional arguments dictionary.\\n\\n    Raises:\\n        TypeError: If \\'annotation\\' is passed as a keyword argument.\\n\\n    Returns:\\n        A new FieldInfo object with the given parameters.\\n\\n    Example:\\n        This is how you can create a field with default value like this:\\n\\n        ```python\\n        import pydantic\\n\\n        class MyModel(pydantic.BaseModel):\\n            foo: int = pydantic.Field(4)\\n        ```\\n    \"\"\"\\n    if \\'annotation\\' in kwargs:\\n        raise TypeError(\\'\"annotation\" is not permitted as a Field keyword argument\\')\\n    return FieldInfo(default=default, **kwargs)\\n\\n````\\n\\n### from_annotation\\n\\n```python\\nfrom_annotation(\\n    annotation: type[Any],\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreates a `FieldInfo` instance from a bare annotation.\\n\\nThis function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n```python\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int  # <-- like this\\n\\n```\\n\\nWe also account for the case where the annotation can be an instance of `Annotated` and where one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: Annotated[int, annotated_types.Gt(42)]\\n    bar: Annotated[int, pydantic.Field(gt=42)]\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | An annotation object. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | An instance of the field metadata. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotation(annotation: type[Any], *, _source: AnnotationSource = AnnotationSource.ANY) -> FieldInfo:\\n    \"\"\"Creates a `FieldInfo` instance from a bare annotation.\\n\\n    This function is used internally to create a `FieldInfo` from a bare annotation like this:\\n\\n    ```python\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int  # <-- like this\\n    ```\\n\\n    We also account for the case where the annotation can be an instance of `Annotated` and where\\n    one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: Annotated[int, annotated_types.Gt(42)]\\n        bar: Annotated[int, pydantic.Field(gt=42)]\\n    ```\\n\\n    Args:\\n        annotation: An annotation object.\\n\\n    Returns:\\n        An instance of the field metadata.\\n    \"\"\"\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # No assigned value, this happens when using a bare `Final` qualifier (also for other\\n    # qualifiers, but they shouldn\\'t appear here). In this case we infer the type as `Any`\\n    # because we don\\'t have any assigned value.\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int`, or `field: Final[str]`:\\n        field_info = FieldInfo(annotation=type_expr, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)]`:\\n    field_info_annotations = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_info_annotations, annotation=type_expr)\\n\\n    new_field_info = field_info._copy()\\n    new_field_info.annotation = type_expr\\n    new_field_info.frozen = final or field_info.frozen\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            new_field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n        new_field_info.metadata = field_metadata\\n    new_field_info._qualifiers = inspected_ann.qualifiers\\n    return new_field_info\\n\\n````\\n\\n### from_annotated_attribute\\n\\n```python\\nfrom_annotated_attribute(\\n    annotation: type[Any],\\n    default: Any,\\n    *,\\n    _source: AnnotationSource = ANY\\n) -> FieldInfo\\n\\n```\\n\\nCreate `FieldInfo` from an annotation with a default value.\\n\\nThis is used in cases like the following:\\n\\n```python\\nfrom typing import Annotated\\n\\nimport annotated_types\\n\\nimport pydantic\\n\\nclass MyModel(pydantic.BaseModel):\\n    foo: int = 4  # <-- like this\\n    bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n    spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `annotation` | `type[Any]` | The type annotation of the field. | *required* | | `default` | `Any` | The default value of the field. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `FieldInfo` | A field object with the passed values. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\n@staticmethod\\ndef from_annotated_attribute(\\n    annotation: type[Any], default: Any, *, _source: AnnotationSource = AnnotationSource.ANY\\n) -> FieldInfo:\\n    \"\"\"Create `FieldInfo` from an annotation with a default value.\\n\\n    This is used in cases like the following:\\n\\n    ```python\\n    from typing import Annotated\\n\\n    import annotated_types\\n\\n    import pydantic\\n\\n    class MyModel(pydantic.BaseModel):\\n        foo: int = 4  # <-- like this\\n        bar: Annotated[int, annotated_types.Gt(4)] = 4  # <-- or this\\n        spam: Annotated[int, pydantic.Field(gt=4)] = 4  # <-- or this\\n    ```\\n\\n    Args:\\n        annotation: The type annotation of the field.\\n        default: The default value of the field.\\n\\n    Returns:\\n        A field object with the passed values.\\n    \"\"\"\\n    if annotation is default:\\n        raise PydanticUserError(\\n            \\'Error when building FieldInfo from annotated attribute. \\'\\n            \"Make sure you don\\'t have any field name clashing with a type annotation.\",\\n            code=\\'unevaluable-type-annotation\\',\\n        )\\n\\n    try:\\n        inspected_ann = inspect_annotation(\\n            annotation,\\n            annotation_source=_source,\\n            unpack_type_aliases=\\'skip\\',\\n        )\\n    except ForbiddenQualifier as e:\\n        raise PydanticForbiddenQualifier(e.qualifier, annotation)\\n\\n    # TODO check for classvar and error?\\n\\n    # TODO infer from the default, this can be done in v3 once we treat final fields with\\n    # a default as proper fields and not class variables:\\n    type_expr: Any = Any if inspected_ann.type is UNKNOWN else inspected_ann.type\\n    final = \\'final\\' in inspected_ann.qualifiers\\n    metadata = inspected_ann.metadata\\n\\n    if isinstance(default, FieldInfo):\\n        # e.g. `field: int = Field(...)`\\n        default_metadata = default.metadata.copy()\\n        default = copy(default)\\n        default.metadata = default_metadata\\n\\n        default.annotation = type_expr\\n        default.metadata += metadata\\n        merged_default = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            default,\\n            annotation=default.annotation,\\n        )\\n        merged_default.frozen = final or merged_default.frozen\\n        merged_default._qualifiers = inspected_ann.qualifiers\\n        return merged_default\\n\\n    if isinstance(default, dataclasses.Field):\\n        # `collect_dataclass_fields()` passes the dataclass Field as a default.\\n        pydantic_field = FieldInfo._from_dataclass_field(default)\\n        pydantic_field.annotation = type_expr\\n        pydantic_field.metadata += metadata\\n        pydantic_field = FieldInfo.merge_field_infos(\\n            *[x for x in metadata if isinstance(x, FieldInfo)],\\n            pydantic_field,\\n            annotation=pydantic_field.annotation,\\n        )\\n        pydantic_field.frozen = final or pydantic_field.frozen\\n        pydantic_field.init_var = \\'init_var\\' in inspected_ann.qualifiers\\n        pydantic_field.init = getattr(default, \\'init\\', None)\\n        pydantic_field.kw_only = getattr(default, \\'kw_only\\', None)\\n        pydantic_field._qualifiers = inspected_ann.qualifiers\\n        return pydantic_field\\n\\n    if not metadata:\\n        # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\\n        field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\\n        field_info._qualifiers = inspected_ann.qualifiers\\n        return field_info\\n\\n    # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\\n    field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\\n    field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\\n    field_metadata: list[Any] = []\\n    for a in metadata:\\n        if typing_objects.is_deprecated(a):\\n            field_info.deprecated = a.message\\n        elif not isinstance(a, FieldInfo):\\n            field_metadata.append(a)\\n        else:\\n            field_metadata.extend(a.metadata)\\n    field_info.metadata = field_metadata\\n    field_info._qualifiers = inspected_ann.qualifiers\\n    return field_info\\n\\n````\\n\\n### merge_field_infos\\n\\n```python\\nmerge_field_infos(\\n    *field_infos: FieldInfo, **overrides: Any\\n) -> FieldInfo\\n\\n```\\n\\nMerge `FieldInfo` instances keeping only explicitly set attributes.\\n\\nLater `FieldInfo` instances override earlier ones.\\n\\nReturns:\\n\\n| Name | Type | Description | | --- | --- | --- | | `FieldInfo` | `FieldInfo` | A merged FieldInfo instance. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\n@staticmethod\\ndef merge_field_infos(*field_infos: FieldInfo, **overrides: Any) -> FieldInfo:\\n    \"\"\"Merge `FieldInfo` instances keeping only explicitly set attributes.\\n\\n    Later `FieldInfo` instances override earlier ones.\\n\\n    Returns:\\n        FieldInfo: A merged FieldInfo instance.\\n    \"\"\"\\n    if len(field_infos) == 1:\\n        # No merging necessary, but we still need to make a copy and apply the overrides\\n        field_info = field_infos[0]._copy()\\n        field_info._attributes_set.update(overrides)\\n\\n        default_override = overrides.pop(\\'default\\', PydanticUndefined)\\n        if default_override is Ellipsis:\\n            default_override = PydanticUndefined\\n        if default_override is not PydanticUndefined:\\n            field_info.default = default_override\\n\\n        for k, v in overrides.items():\\n            setattr(field_info, k, v)\\n        return field_info  # type: ignore\\n\\n    merged_field_info_kwargs: dict[str, Any] = {}\\n    metadata = {}\\n    for field_info in field_infos:\\n        attributes_set = field_info._attributes_set.copy()\\n\\n        try:\\n            json_schema_extra = attributes_set.pop(\\'json_schema_extra\\')\\n            existing_json_schema_extra = merged_field_info_kwargs.get(\\'json_schema_extra\\')\\n\\n            if existing_json_schema_extra is None:\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n            if isinstance(existing_json_schema_extra, dict):\\n                if isinstance(json_schema_extra, dict):\\n                    merged_field_info_kwargs[\\'json_schema_extra\\'] = {\\n                        **existing_json_schema_extra,\\n                        **json_schema_extra,\\n                    }\\n                if callable(json_schema_extra):\\n                    warn(\\n                        \\'Composing `dict` and `callable` type `json_schema_extra` is not supported.\\'\\n                        \\'The `callable` type is being ignored.\\'\\n                        \"If you\\'d like support for this behavior, please open an issue on pydantic.\",\\n                        PydanticJsonSchemaWarning,\\n                    )\\n            elif callable(json_schema_extra):\\n                # if ever there\\'s a case of a callable, we\\'ll just keep the last json schema extra spec\\n                merged_field_info_kwargs[\\'json_schema_extra\\'] = json_schema_extra\\n        except KeyError:\\n            pass\\n\\n        # later FieldInfo instances override everything except json_schema_extra from earlier FieldInfo instances\\n        merged_field_info_kwargs.update(attributes_set)\\n\\n        for x in field_info.metadata:\\n            if not isinstance(x, FieldInfo):\\n                metadata[type(x)] = x\\n\\n    merged_field_info_kwargs.update(overrides)\\n    field_info = FieldInfo(**merged_field_info_kwargs)\\n    field_info.metadata = list(metadata.values())\\n    return field_info\\n\\n```\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n\\n### default_factory_takes_validated_data\\n\\n```python\\ndefault_factory_takes_validated_data: bool | None\\n\\n```\\n\\nWhether the provided default factory callable has a validated data parameter.\\n\\nReturns `None` if no default factory is set.\\n\\n### get_default\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: Literal[True],\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *, call_default_factory: Literal[False] = ...\\n) -> Any\\n\\n```\\n\\n```python\\nget_default(\\n    *,\\n    call_default_factory: bool = False,\\n    validated_data: dict[str, Any] | None = None\\n) -> Any\\n\\n```\\n\\nGet the default value.\\n\\nWe expose an option for whether to call the default_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via `model_construct`).\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `call_default_factory` | `bool` | Whether to call the default factory or not. | `False` | | `validated_data` | `dict[str, Any] | None` | The already validated data to be passed to the default factory. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value, calling the default factory if requested or None if not set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self, *, call_default_factory: bool = False, validated_data: dict[str, Any] | None = None) -> Any:\\n    \"\"\"Get the default value.\\n\\n    We expose an option for whether to call the default_factory (if present), as calling it may\\n    result in side effects that we want to avoid. However, there are times when it really should\\n    be called (namely, when instantiating a model via `model_construct`).\\n\\n    Args:\\n        call_default_factory: Whether to call the default factory or not.\\n        validated_data: The already validated data to be passed to the default factory.\\n\\n    Returns:\\n        The default value, calling the default factory if requested or `None` if not set.\\n    \"\"\"\\n    if self.default_factory is None:\\n        return _utils.smart_deepcopy(self.default)\\n    elif call_default_factory:\\n        if self.default_factory_takes_validated_data:\\n            fac = cast(\\'Callable[[dict[str, Any]], Any]\\', self.default_factory)\\n            if validated_data is None:\\n                raise ValueError(\\n                    \"The default factory requires the \\'validated_data\\' argument, which was not provided when calling \\'get_default\\'.\"\\n                )\\n            return fac(validated_data)\\n        else:\\n            fac = cast(\\'Callable[[], Any]\\', self.default_factory)\\n            return fac()\\n    else:\\n        return None\\n\\n```\\n\\n### is_required\\n\\n```python\\nis_required() -> bool\\n\\n```\\n\\nCheck if the field is required (i.e., does not have a default value or factory).\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool` | True if the field is required, False otherwise. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef is_required(self) -> bool:\\n    \"\"\"Check if the field is required (i.e., does not have a default value or factory).\\n\\n    Returns:\\n        `True` if the field is required, `False` otherwise.\\n    \"\"\"\\n    return self.default is PydanticUndefined and self.default_factory is None\\n\\n```\\n\\n### rebuild_annotation\\n\\n```python\\nrebuild_annotation() -> Any\\n\\n```\\n\\nAttempts to rebuild the original annotation for use in function signatures.\\n\\nIf metadata is present, it adds it to the original annotation using `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\nNote that because the metadata has been flattened, the original annotation may not be reconstructed exactly as originally provided, e.g. if the original type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The rebuilt annotation. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef rebuild_annotation(self) -> Any:\\n    \"\"\"Attempts to rebuild the original annotation for use in function signatures.\\n\\n    If metadata is present, it adds it to the original annotation using\\n    `Annotated`. Otherwise, it returns the original annotation as-is.\\n\\n    Note that because the metadata has been flattened, the original annotation\\n    may not be reconstructed exactly as originally provided, e.g. if the original\\n    type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\\n\\n    Returns:\\n        The rebuilt annotation.\\n    \"\"\"\\n    if not self.metadata:\\n        return self.annotation\\n    else:\\n        # Annotated arguments must be a tuple\\n        return Annotated[(self.annotation, *self.metadata)]  # type: ignore\\n\\n```\\n\\n### apply_typevars_map\\n\\n```python\\napply_typevars_map(\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None\\n\\n```\\n\\nApply a `typevars_map` to the annotation.\\n\\nThis method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\nThis method applies the `typevars_map` to the annotation in place.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `typevars_map` | `Mapping[TypeVar, Any] | None` | A dictionary mapping type variables to their concrete types. | *required* | | `globalns` | `GlobalsNamespace | None` | The globals namespace to use during type annotation evaluation. | `None` | | `localns` | `MappingNamespace | None` | The locals namespace to use during type annotation evaluation. | `None` |\\n\\nSee Also\\n\\npydantic.\\\\_internal.\\\\_generics.replace_types is used for replacing the typevars with their concrete types.\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef apply_typevars_map(\\n    self,\\n    typevars_map: Mapping[TypeVar, Any] | None,\\n    globalns: GlobalsNamespace | None = None,\\n    localns: MappingNamespace | None = None,\\n) -> None:\\n    \"\"\"Apply a `typevars_map` to the annotation.\\n\\n    This method is used when analyzing parametrized generic types to replace typevars with their concrete types.\\n\\n    This method applies the `typevars_map` to the annotation in place.\\n\\n    Args:\\n        typevars_map: A dictionary mapping type variables to their concrete types.\\n        globalns: The globals namespace to use during type annotation evaluation.\\n        localns: The locals namespace to use during type annotation evaluation.\\n\\n    See Also:\\n        pydantic._internal._generics.replace_types is used for replacing the typevars with\\n            their concrete types.\\n    \"\"\"\\n    annotation = _generics.replace_types(self.annotation, typevars_map)\\n    annotation, evaluated = _typing_extra.try_eval_type(annotation, globalns, localns)\\n    self.annotation = annotation\\n    if not evaluated:\\n        self._complete = False\\n        self._original_annotation = self.annotation\\n\\n```\\n\\n## PrivateAttr\\n\\n```python\\nPrivateAttr(\\n    default: _T, *, init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    *,\\n    default_factory: Callable[[], _T],\\n    init: Literal[False] = False\\n) -> _T\\n\\n```\\n\\n```python\\nPrivateAttr(*, init: Literal[False] = False) -> Any\\n\\n```\\n\\n```python\\nPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False\\n) -> Any\\n\\n```\\n\\nUsage Documentation\\n\\n[Private Model Attributes](../../concepts/models/#private-model-attributes)\\n\\nIndicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\nPrivate attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\nPrivate attributes are stored in `__private_attributes__` on the model.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `default` | `Any` | The attribute\\'s default value. Defaults to Undefined. | `PydanticUndefined` | | `default_factory` | `Callable[[], Any] | None` | Callable that will be called when a default value is needed for this attribute. If both default and default_factory are set, an error will be raised. | `None` | | `init` | `Literal[False]` | Whether the attribute should be included in the constructor of the dataclass. Always False. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | An instance of ModelPrivateAttr class. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `ValueError` | If both default and default_factory are set. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef PrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None,\\n    init: Literal[False] = False,\\n) -> Any:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [Private Model Attributes](../concepts/models.md#private-model-attributes)\\n\\n    Indicates that an attribute is intended for private use and not handled during normal validation/serialization.\\n\\n    Private attributes are not validated by Pydantic, so it\\'s up to you to ensure they are used in a type-safe manner.\\n\\n    Private attributes are stored in `__private_attributes__` on the model.\\n\\n    Args:\\n        default: The attribute\\'s default value. Defaults to Undefined.\\n        default_factory: Callable that will be\\n            called when a default value is needed for this attribute.\\n            If both `default` and `default_factory` are set, an error will be raised.\\n        init: Whether the attribute should be included in the constructor of the dataclass. Always `False`.\\n\\n    Returns:\\n        An instance of [`ModelPrivateAttr`][pydantic.fields.ModelPrivateAttr] class.\\n\\n    Raises:\\n        ValueError: If both `default` and `default_factory` are set.\\n    \"\"\"\\n    if default is not PydanticUndefined and default_factory is not None:\\n        raise TypeError(\\'cannot specify both default and default_factory\\')\\n\\n    return ModelPrivateAttr(\\n        default,\\n        default_factory=default_factory,\\n    )\\n\\n```\\n\\n## ModelPrivateAttr\\n\\n```python\\nModelPrivateAttr(\\n    default: Any = PydanticUndefined,\\n    *,\\n    default_factory: Callable[[], Any] | None = None\\n)\\n\\n```\\n\\nBases: `Representation`\\n\\nA descriptor for private attributes in class models.\\n\\nWarning\\n\\nYou generally shouldn\\'t be creating `ModelPrivateAttr` instances directly, instead use `pydantic.fields.PrivateAttr`. (This is similar to `FieldInfo` vs. `Field`.)\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `default` | | The default value of the attribute if not provided. | | `default_factory` | | A callable function that generates the default value of the attribute if not provided. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef __init__(\\n    self, default: Any = PydanticUndefined, *, default_factory: typing.Callable[[], Any] | None = None\\n) -> None:\\n    if default is Ellipsis:\\n        self.default = PydanticUndefined\\n    else:\\n        self.default = default\\n    self.default_factory = default_factory\\n\\n```\\n\\n### get_default\\n\\n```python\\nget_default() -> Any\\n\\n```\\n\\nRetrieve the default value of the object.\\n\\nIf `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\nIf `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Any` | The default value of the object. |\\n\\nSource code in `pydantic/fields.py`\\n\\n```python\\ndef get_default(self) -> Any:\\n    \"\"\"Retrieve the default value of the object.\\n\\n    If `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\\n\\n    If `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\\n\\n    Returns:\\n        The default value of the object.\\n    \"\"\"\\n    return _utils.smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\\n\\n```\\n\\n## computed_field\\n\\n```python\\ncomputed_field(func: PropertyT) -> PropertyT\\n\\n```\\n\\n```python\\ncomputed_field(\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool = True,\\n    return_type: Any = PydanticUndefined\\n) -> Callable[[PropertyT], PropertyT]\\n\\n```\\n\\n```python\\ncomputed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ) = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ) = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | Callable[[PropertyT], PropertyT]\\n\\n```\\n\\nUsage Documentation\\n\\n[The `computed_field` decorator](../../concepts/fields/#the-computed_field-decorator)\\n\\nDecorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\nThis is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Rectangle(BaseModel):\\n    width: int\\n    length: int\\n\\n    @computed_field\\n    @property\\n    def area(self) -> int:\\n        return self.width * self.length\\n\\nprint(Rectangle(width=3, length=2).model_dump())\\n#> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n\\n```\\n\\nIf applied to functions not yet decorated with `@property` or `@cached_property`, the function is automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\nMypy Warning\\n\\nEven with the `@property` or `@cached_property` applied to your function before `@computed_field`, mypy may throw a `Decorated property not supported` error. See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information. To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n[pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n```python\\nimport random\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Square(BaseModel):\\n    width: float\\n\\n    @computed_field\\n    def area(self) -> float:  # converted to a `property` by `computed_field`\\n        return round(self.width**2, 2)\\n\\n    @area.setter\\n    def area(self, new_area: float) -> None:\\n        self.width = new_area**0.5\\n\\n    @computed_field(alias=\\'the magic number\\', repr=False)\\n    def random_number(self) -> int:\\n        return random.randint(0, 1_000)\\n\\nsquare = Square(width=1.3)\\n\\n# `random_number` does not appear in representation\\nprint(repr(square))\\n#> Square(width=1.3, area=1.69)\\n\\nprint(square.random_number)\\n#> 3\\n\\nsquare.area = 4\\n\\nprint(square.model_dump_json(by_alias=True))\\n#> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n\\n```\\n\\nOverriding with `computed_field`\\n\\nYou can\\'t override a field from a parent class with a `computed_field` in the child class. `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either. See the example below:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Parent(BaseModel):\\n    a: str\\n\\ntry:\\n\\n    class Child(Parent):\\n        @computed_field\\n        @property\\n        def a(self) -> str:\\n            return \\'new a\\'\\n\\nexcept TypeError as e:\\n    print(e)\\n    \\'\\'\\'\\n    Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n    \\'\\'\\'\\n\\n```\\n\\nPrivate properties decorated with `@computed_field` have `repr=False` by default.\\n\\n```python\\nfrom functools import cached_property\\n\\nfrom pydantic import BaseModel, computed_field\\n\\nclass Model(BaseModel):\\n    foo: int\\n\\n    @computed_field\\n    @cached_property\\n    def _private_cached_property(self) -> int:\\n        return -self.foo\\n\\n    @computed_field\\n    @property\\n    def _private_property(self) -> int:\\n        return -self.foo\\n\\nm = Model(foo=1)\\nprint(repr(m))\\n#> Model(foo=1)\\n\\n```\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `func` | `PropertyT | None` | the function to wrap. | `None` | | `alias` | `str | None` | alias to use when serializing this computed field, only used when by_alias=True | `None` | | `alias_priority` | `int | None` | priority of the alias. This affects whether an alias generator is used | `None` | | `title` | `str | None` | Title to use when including this computed field in JSON Schema | `None` | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | `None` | | `description` | `str | None` | Description to use when including this computed field in JSON Schema, defaults to the function\\'s docstring | `None` | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message (or an instance of warnings.deprecated or the typing_extensions.deprecated backport). to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the deprecated decorator. | `None` | | `examples` | `list[Any] | None` | Example values to use when including this computed field in JSON Schema | `None` | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | `None` | | `repr` | `bool | None` | whether to include this computed field in model repr. Default is False for private properties and True for public properties. | `None` | | `return_type` | `Any` | optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a TypeError is raised. If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary objects. | `PydanticUndefined` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `PropertyT | Callable[[PropertyT], PropertyT]` | A proxy wrapper for the property. |\\n\\nSource code in `pydantic/fields.py`\\n\\n````python\\ndef computed_field(\\n    func: PropertyT | None = None,\\n    /,\\n    *,\\n    alias: str | None = None,\\n    alias_priority: int | None = None,\\n    title: str | None = None,\\n    field_title_generator: typing.Callable[[str, ComputedFieldInfo], str] | None = None,\\n    description: str | None = None,\\n    deprecated: Deprecated | str | bool | None = None,\\n    examples: list[Any] | None = None,\\n    json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None,\\n    repr: bool | None = None,\\n    return_type: Any = PydanticUndefined,\\n) -> PropertyT | typing.Callable[[PropertyT], PropertyT]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [The `computed_field` decorator](../concepts/fields.md#the-computed_field-decorator)\\n\\n    Decorator to include `property` and `cached_property` when serializing models or dataclasses.\\n\\n    This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Rectangle(BaseModel):\\n        width: int\\n        length: int\\n\\n        @computed_field\\n        @property\\n        def area(self) -> int:\\n            return self.width * self.length\\n\\n    print(Rectangle(width=3, length=2).model_dump())\\n    #> {\\'width\\': 3, \\'length\\': 2, \\'area\\': 6}\\n    ```\\n\\n    If applied to functions not yet decorated with `@property` or `@cached_property`, the function is\\n    automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE,\\n    and confuse static type checkers, thus explicit use of `@property` is recommended.\\n\\n    !!! warning \"Mypy Warning\"\\n        Even with the `@property` or `@cached_property` applied to your function before `@computed_field`,\\n        mypy may throw a `Decorated property not supported` error.\\n        See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information.\\n        To avoid this error message, add `# type: ignore[prop-decorator]` to the `@computed_field` line.\\n\\n        [pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\\n\\n    ```python\\n    import random\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Square(BaseModel):\\n        width: float\\n\\n        @computed_field\\n        def area(self) -> float:  # converted to a `property` by `computed_field`\\n            return round(self.width**2, 2)\\n\\n        @area.setter\\n        def area(self, new_area: float) -> None:\\n            self.width = new_area**0.5\\n\\n        @computed_field(alias=\\'the magic number\\', repr=False)\\n        def random_number(self) -> int:\\n            return random.randint(0, 1_000)\\n\\n    square = Square(width=1.3)\\n\\n    # `random_number` does not appear in representation\\n    print(repr(square))\\n    #> Square(width=1.3, area=1.69)\\n\\n    print(square.random_number)\\n    #> 3\\n\\n    square.area = 4\\n\\n    print(square.model_dump_json(by_alias=True))\\n    #> {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\\n    ```\\n\\n    !!! warning \"Overriding with `computed_field`\"\\n        You can\\'t override a field from a parent class with a `computed_field` in the child class.\\n        `mypy` complains about this behavior if allowed, and `dataclasses` doesn\\'t allow this pattern either.\\n        See the example below:\\n\\n    ```python\\n    from pydantic import BaseModel, computed_field\\n\\n    class Parent(BaseModel):\\n        a: str\\n\\n    try:\\n\\n        class Child(Parent):\\n            @computed_field\\n            @property\\n            def a(self) -> str:\\n                return \\'new a\\'\\n\\n    except TypeError as e:\\n        print(e)\\n        \\'\\'\\'\\n        Field \\'a\\' of class \\'Child\\' overrides symbol of same name in a parent class. This override with a computed_field is incompatible.\\n        \\'\\'\\'\\n    ```\\n\\n    Private properties decorated with `@computed_field` have `repr=False` by default.\\n\\n    ```python\\n    from functools import cached_property\\n\\n    from pydantic import BaseModel, computed_field\\n\\n    class Model(BaseModel):\\n        foo: int\\n\\n        @computed_field\\n        @cached_property\\n        def _private_cached_property(self) -> int:\\n            return -self.foo\\n\\n        @computed_field\\n        @property\\n        def _private_property(self) -> int:\\n            return -self.foo\\n\\n    m = Model(foo=1)\\n    print(repr(m))\\n    #> Model(foo=1)\\n    ```\\n\\n    Args:\\n        func: the function to wrap.\\n        alias: alias to use when serializing this computed field, only used when `by_alias=True`\\n        alias_priority: priority of the alias. This affects whether an alias generator is used\\n        title: Title to use when including this computed field in JSON Schema\\n        field_title_generator: A callable that takes a field name and returns title for it.\\n        description: Description to use when including this computed field in JSON Schema, defaults to the function\\'s\\n            docstring\\n        deprecated: A deprecation message (or an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport).\\n            to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the\\n            `deprecated` decorator.\\n        examples: Example values to use when including this computed field in JSON Schema\\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\\n        repr: whether to include this computed field in model repr.\\n            Default is `False` for private properties and `True` for public properties.\\n        return_type: optional return for serialization logic to expect when serializing to JSON, if included\\n            this must be correct, otherwise a `TypeError` is raised.\\n            If you don\\'t include a return type Any is used, which does runtime introspection to handle arbitrary\\n            objects.\\n\\n    Returns:\\n        A proxy wrapper for the property.\\n    \"\"\"\\n\\n    def dec(f: Any) -> Any:\\n        nonlocal description, deprecated, return_type, alias_priority\\n        unwrapped = _decorators.unwrap_wrapped_function(f)\\n\\n        if description is None and unwrapped.__doc__:\\n            description = inspect.cleandoc(unwrapped.__doc__)\\n\\n        if deprecated is None and hasattr(unwrapped, \\'__deprecated__\\'):\\n            deprecated = unwrapped.__deprecated__\\n\\n        # if the function isn\\'t already decorated with `@property` (or another descriptor), then we wrap it now\\n        f = _decorators.ensure_property(f)\\n        alias_priority = (alias_priority or 2) if alias is not None else None\\n\\n        if repr is None:\\n            repr_: bool = not _wrapped_property_is_private(property_=f)\\n        else:\\n            repr_ = repr\\n\\n        dec_info = ComputedFieldInfo(\\n            f,\\n            return_type,\\n            alias,\\n            alias_priority,\\n            title,\\n            field_title_generator,\\n            description,\\n            deprecated,\\n            examples,\\n            json_schema_extra,\\n            repr_,\\n        )\\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\\n\\n    if func is None:\\n        return dec\\n    else:\\n        return dec(func)\\n\\n````\\n\\n## ComputedFieldInfo\\n\\n```python\\nComputedFieldInfo(\\n    wrapped_property: property,\\n    return_type: Any,\\n    alias: str | None,\\n    alias_priority: int | None,\\n    title: str | None,\\n    field_title_generator: (\\n        Callable[[str, ComputedFieldInfo], str] | None\\n    ),\\n    description: str | None,\\n    deprecated: Deprecated | str | bool | None,\\n    examples: list[Any] | None,\\n    json_schema_extra: (\\n        JsonDict | Callable[[JsonDict], None] | None\\n    ),\\n    repr: bool,\\n)\\n\\n```\\n\\nA container for data from `@computed_field` so that we can access it while building the pydantic-core schema.\\n\\nAttributes:\\n\\n| Name | Type | Description | | --- | --- | --- | | `decorator_repr` | `str` | A class variable representing the decorator string, \\'@computed_field\\'. | | `wrapped_property` | `property` | The wrapped computed field property. | | `return_type` | `Any` | The type of the computed field property\\'s return value. | | `alias` | `str | None` | The alias of the property to be used during serialization. | | `alias_priority` | `int | None` | The priority of the alias. This affects whether an alias generator is used. | | `title` | `str | None` | Title of the computed field to include in the serialization JSON schema. | | `field_title_generator` | `Callable[[str, ComputedFieldInfo], str] | None` | A callable that takes a field name and returns title for it. | | `description` | `str | None` | Description of the computed field to include in the serialization JSON schema. | | `deprecated` | `Deprecated | str | bool | None` | A deprecation message, an instance of warnings.deprecated or the typing_extensions.deprecated backport, or a boolean. If True, a default deprecation message will be emitted when accessing the field. | | `examples` | `list[Any] | None` | Example values of the computed field to include in the serialization JSON schema. | | `json_schema_extra` | `JsonDict | Callable[[JsonDict], None] | None` | A dict or callable to provide extra JSON schema properties. | | `repr` | `bool` | A boolean indicating whether to include the field in the repr output. |\\n\\n### deprecation_message\\n\\n```python\\ndeprecation_message: str | None\\n\\n```\\n\\nThe deprecation message to be emitted, or `None` if not set.\\n',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md'},\n",
       " {'context': 'API Documentation\\n\\npydantic.fields.Field\\n\\nIn this section, we will go through the available mechanisms to customize Pydantic model fields: default values, JSON Schema metadata, constraints, etc.\\n\\nTo do so, the Field() function is used a lot, and behaves the same way as the standard library field() function for dataclasses:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    name: str = Field(frozen=True)\\n\\n```\\n\\nNote\\n\\nEven though `name` is assigned a value, it is still required and has no default value. If you want to emphasize on the fact that a value must be provided, you can use the ellipsis:\\n\\n```python\\nclass Model(BaseModel):\\n    name: str = Field(..., frozen=True)\\n\\n```\\n\\nHowever, its usage is discouraged as it doesn\\'t play well with static type checkers.\\n\\n## The annotated pattern\\n\\nTo apply constraints or attach Field() functions to a model field, Pydantic supports the Annotated typing construct to attach metadata to an annotation:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field, WithJsonSchema\\n\\n\\nclass Model(BaseModel):\\n    name: Annotated[str, Field(strict=True), WithJsonSchema({\\'extra\\': \\'data\\'})]\\n\\n```\\n\\nAs far as static type checkers are concerned, `name` is still typed as `str`, but Pydantic leverages the available metadata to add validation logic, type constraints, etc.\\n\\nUsing this pattern has some advantages:\\n\\n- Using the `f: \\n = Field(...)` form can be confusing and might trick users into thinking `f` has a default value, while in reality it is still required.\\n- You can provide an arbitrary amount of metadata elements for a field. As shown in the example above, the Field() function only supports a limited set of constraints/metadata, and you may have to use different Pydantic utilities such as WithJsonSchema in some cases.\\n- Types can be made reusable (see the documentation on [custom types](../types/#using-the-annotated-pattern) using this pattern).\\n\\nHowever, note that certain arguments to the Field() function (namely, `default`, `default_factory`, and `alias`) are taken into account by static type checkers to synthesize a correct `__init__` method. The annotated pattern is *not* understood by them, so you should use the normal assignment form instead.\\n\\nTip\\n\\nThe annotated pattern can also be used to add metadata to specific parts of the type. For instance, [validation constraints](#field-constraints) can be added this way:\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    int_list: list[Annotated[int, Field(gt=0)]]\\n    # Valid: [1, 3]\\n    # Invalid: [-1, 2]\\n\\n```\\n\\nBe careful not mixing *field* and *type* metadata:\\n\\n```python\\nclass Model(BaseModel):\\n    field_bad: Annotated[int, Field(deprecated=True)] | None = None  # (1)!\\n    field_ok: Annotated[int | None, Field(deprecated=True)] = None  # (2)!\\n\\n```\\n\\n1. The Field() function is applied to `int` type, hence the `deprecated` flag won\\'t have any effect. While this may be confusing given that the name of the Field() function would imply it should apply to the field, the API was designed when this function was the only way to provide metadata. You can alternatively make use of the [`annotated_types`](https://github.com/annotated-types/annotated-types) library which is now supported by Pydantic.\\n1. The Field() function is applied to the \"top-level\" union type, hence the `deprecated` flag will be applied to the field.\\n\\n## Default values\\n\\nDefault values for fields can be provided using the normal assignment syntax or by providing a value to the `default` argument:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    # Both fields aren\\'t required:\\n    name: str = \\'John Doe\\'\\n    age: int = Field(default=20)\\n\\n```\\n\\nWarning\\n\\n[In Pydantic V1](../../migration/#required-optional-and-nullable-fields), a type annotated as Any or wrapped by Optional would be given an implicit default of `None` even if no default was explicitly specified. This is no longer the case in Pydantic V2.\\n\\nYou can also pass a callable to the `default_factory` argument that will be called to generate a default value:\\n\\n```python\\nfrom uuid import uuid4\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    id: str = Field(default_factory=lambda: uuid4().hex)\\n\\n```\\n\\nThe default factory can also take a single required argument, in which case the already validated data will be passed as a dictionary.\\n\\n```python\\nfrom pydantic import BaseModel, EmailStr, Field\\n\\n\\nclass User(BaseModel):\\n    email: EmailStr\\n    username: str = Field(default_factory=lambda data: data[\\'email\\'])\\n\\n\\nuser = User(email=\\'user@example.com\\')\\nprint(user.username)\\n#> user@example.com\\n\\n```\\n\\nThe `data` argument will *only* contain the already validated data, based on the [order of model fields](../models/#field-ordering) (the above example would fail if `username` were to be defined before `email`).\\n\\n## Validate default values\\n\\nBy default, Pydantic will *not* validate default values. The `validate_default` field parameter (or the validate_default configuration value) can be used to enable this behavior:\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    age: int = Field(default=\\'twelve\\', validate_default=True)\\n\\n\\ntry:\\n    user = User()\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    age\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'twelve\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Mutable default values\\n\\nA common source of bugs in Python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call.\\n\\nThe dataclasses module actually raises an error in this case, indicating that you should use a [default factory](https://docs.python.org/3/library/dataclasses.html#default-factory-functions) instead.\\n\\nWhile the same thing can be done in Pydantic, it is not required. In the event that the default value is not hashable, Pydantic will create a deep copy of the default value when creating each instance of the model:\\n\\n```python\\nfrom pydantic import BaseModel\\n\\n\\nclass Model(BaseModel):\\n    item_counts: list[dict[str, int]] = [{}]\\n\\n\\nm1 = Model()\\nm1.item_counts[0][\\'a\\'] = 1\\nprint(m1.item_counts)\\n#> [{\\'a\\': 1}]\\n\\nm2 = Model()\\nprint(m2.item_counts)\\n#> [{}]\\n\\n```\\n\\n## Field aliases\\n\\nTip\\n\\nRead more about aliases in the [dedicated section](../alias/).\\n\\nFor validation and serialization, you can define an alias for a field.\\n\\nThere are three ways to define an alias:\\n\\n- `Field(alias=\\'foo\\')`\\n- `Field(validation_alias=\\'foo\\')`\\n- `Field(serialization_alias=\\'foo\\')`\\n\\nThe `alias` parameter is used for both validation *and* serialization. If you want to use *different* aliases for validation and serialization respectively, you can use the `validation_alias` and `serialization_alias` parameters, which will apply only in their respective use cases.\\n\\nHere is an example of using the `alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The alias `\\'username\\'` is used for instance creation and validation.\\n\\n1. We are using model_dump() to convert the model into a serializable format.\\n\\n   Note that the `by_alias` keyword argument defaults to `False`, and must be specified explicitly to dump models using the field (serialization) aliases.\\n\\n   You can also use ConfigDict.serialize_by_alias to configure this behavior at the model level.\\n\\n   When `by_alias=True`, the alias `\\'username\\'` used during serialization.\\n\\nIf you want to use an alias *only* for validation, you can use the `validation_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(validation_alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'name\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The validation alias `\\'username\\'` is used during validation.\\n1. The field name `\\'name\\'` is used during serialization.\\n\\nIf you only want to define an alias for *serialization*, you can use the `serialization_alias` parameter:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(serialization_alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nprint(user)\\n#> name=\\'johndoe\\'\\nprint(user.model_dump(by_alias=True))  # (2)!\\n#> {\\'username\\': \\'johndoe\\'}\\n\\n```\\n\\n1. The field name `\\'name\\'` is used for validation.\\n1. The serialization alias `\\'username\\'` is used for serialization.\\n\\nAlias precedence and priority\\n\\nIn case you use `alias` together with `validation_alias` or `serialization_alias` at the same time, the `validation_alias` will have priority over `alias` for validation, and `serialization_alias` will have priority over `alias` for serialization.\\n\\nIf you provide a value for the alias_generator model setting, you can control the order of precedence for field alias and generated aliases via the `alias_priority` field parameter. You can read more about alias precedence [here](../alias/#alias-precedence).\\n\\nStatic type checking/IDE support\\n\\nIf you provide a value for the `alias` field parameter, static type checkers will use this alias instead of the actual field name to synthesize the `__init__` method:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(username=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n\\nThis means that when using the validate_by_name model setting (which allows both the field name and alias to be used during model validation), type checkers will error when the actual field name is used:\\n\\n```python\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True)\\n\\n    name: str = Field(alias=\\'username\\')\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\n\\n```\\n\\n1. *Not* accepted by type checkers.\\n\\nIf you still want type checkers to use the field name and not the alias, the [annotated pattern](#the-annotated-pattern) can be used (which is only understood by Pydantic):\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, ConfigDict, Field\\n\\n\\nclass User(BaseModel):\\n    model_config = ConfigDict(validate_by_name=True, validate_by_alias=True)\\n\\n    name: Annotated[str, Field(alias=\\'username\\')]\\n\\n\\nuser = User(name=\\'johndoe\\')  # (1)!\\nuser = User(username=\\'johndoe\\')  # (2)!\\n\\n```\\n\\n1. Accepted by type checkers.\\n1. *Not* accepted by type checkers.\\n\\n### Validation Alias\\n\\nEven though Pydantic treats `alias` and `validation_alias` the same when creating model instances, type checkers only understand the `alias` field parameter. As a workaround, you can instead specify both an `alias` and serialization_alias`(identical to the field name), as the`serialization_alias`will override the`alias\\\\` during serialization:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(validation_alias=\\'myValidationAlias\\')\\n\\n```\\n\\nwith:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass MyModel(BaseModel):\\n    my_field: int = Field(\\n        alias=\\'myValidationAlias\\',\\n        serialization_alias=\\'my_field\\',\\n    )\\n\\n\\nm = MyModel(myValidationAlias=1)\\nprint(m.model_dump(by_alias=True))\\n#> {\\'my_field\\': 1}\\n\\n```\\n\\n## Numeric Constraints\\n\\nThere are some keyword arguments that can be used to constrain numeric values:\\n\\n- `gt` - greater than\\n- `lt` - less than\\n- `ge` - greater than or equal to\\n- `le` - less than or equal to\\n- `multiple_of` - a multiple of the given number\\n- `allow_inf_nan` - allow `\\'inf\\'`, `\\'-inf\\'`, `\\'nan\\'` values\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: int = Field(gt=0)\\n    non_negative: int = Field(ge=0)\\n    negative: int = Field(lt=0)\\n    non_positive: int = Field(le=0)\\n    even: int = Field(multiple_of=2)\\n    love_for_pydantic: float = Field(allow_inf_nan=True)\\n\\n\\nfoo = Foo(\\n    positive=1,\\n    non_negative=0,\\n    negative=-1,\\n    non_positive=0,\\n    even=2,\\n    love_for_pydantic=float(\\'inf\\'),\\n)\\nprint(foo)\\n\"\"\"\\npositive=1 non_negative=0 negative=-1 non_positive=0 even=2 love_for_pydantic=inf\\n\"\"\"\\n\\n```\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `gt` and `lt` constraints will be translated to `exclusiveMinimum` and `exclusiveMaximum`.\\n- `ge` and `le` constraints will be translated to `minimum` and `maximum`.\\n- `multiple_of` constraint will be translated to `multipleOf`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"positive\": {\\n      \"title\": \"Positive\",\\n      \"type\": \"integer\",\\n      \"exclusiveMinimum\": 0\\n    },\\n    \"non_negative\": {\\n      \"title\": \"Non Negative\",\\n      \"type\": \"integer\",\\n      \"minimum\": 0\\n    },\\n    \"negative\": {\\n      \"title\": \"Negative\",\\n      \"type\": \"integer\",\\n      \"exclusiveMaximum\": 0\\n    },\\n    \"non_positive\": {\\n      \"title\": \"Non Positive\",\\n      \"type\": \"integer\",\\n      \"maximum\": 0\\n    },\\n    \"even\": {\\n      \"title\": \"Even\",\\n      \"type\": \"integer\",\\n      \"multipleOf\": 2\\n    },\\n    \"love_for_pydantic\": {\\n      \"title\": \"Love For Pydantic\",\\n      \"type\": \"number\"\\n    }\\n  },\\n  \"required\": [\\n    \"positive\",\\n    \"non_negative\",\\n    \"negative\",\\n    \"non_positive\",\\n    \"even\",\\n    \"love_for_pydantic\"\\n  ]\\n}\\n\\n```\\n\\nSee the [JSON Schema Draft 2020-12](https://json-schema.org/understanding-json-schema/reference/numeric.html#numeric-types) for more details.\\n\\nConstraints on compound types\\n\\nIn case you use field constraints with compound types, an error can happen in some cases. To avoid potential issues, you can use `Annotated`:\\n\\n```python\\nfrom typing import Annotated, Optional\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    positive: Optional[Annotated[int, Field(gt=0)]]\\n    # Can error in some cases, not recommended:\\n    non_negative: Optional[int] = Field(ge=0)\\n\\n```\\n\\n## String Constraints\\n\\nAPI Documentation\\n\\npydantic.types.StringConstraints\\n\\nThere are fields that can be used to constrain strings:\\n\\n- `min_length`: Minimum length of the string.\\n- `max_length`: Maximum length of the string.\\n- `pattern`: A regular expression that the string must match.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    short: str = Field(min_length=3)\\n    long: str = Field(max_length=10)\\n    regex: str = Field(pattern=r\\'^\\\\d*$\\')  # (1)!\\n\\n\\nfoo = Foo(short=\\'foo\\', long=\\'foobarbaz\\', regex=\\'123\\')\\nprint(foo)\\n#> short=\\'foo\\' long=\\'foobarbaz\\' regex=\\'123\\'\\n\\n```\\n\\n1. Only digits are allowed.\\n\\nJSON Schema\\n\\nIn the generated JSON schema:\\n\\n- `min_length` constraint will be translated to `minLength`.\\n- `max_length` constraint will be translated to `maxLength`.\\n- `pattern` constraint will be translated to `pattern`.\\n\\nThe above snippet will generate the following JSON Schema:\\n\\n```json\\n{\\n  \"title\": \"Foo\",\\n  \"type\": \"object\",\\n  \"properties\": {\\n    \"short\": {\\n      \"title\": \"Short\",\\n      \"type\": \"string\",\\n      \"minLength\": 3\\n    },\\n    \"long\": {\\n      \"title\": \"Long\",\\n      \"type\": \"string\",\\n      \"maxLength\": 10\\n    },\\n    \"regex\": {\\n      \"title\": \"Regex\",\\n      \"type\": \"string\",\\n      \"pattern\": \"^\\\\\\\\d*$\"\\n    }\\n  },\\n  \"required\": [\\n    \"short\",\\n    \"long\",\\n    \"regex\"\\n  ]\\n}\\n\\n```\\n\\n## Decimal Constraints\\n\\nThere are fields that can be used to constrain decimals:\\n\\n- `max_digits`: Maximum number of digits within the `Decimal`. It does not include a zero before the decimal point or trailing decimal zeroes.\\n- `decimal_places`: Maximum number of decimal places allowed. It does not include trailing decimal zeroes.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom decimal import Decimal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Foo(BaseModel):\\n    precise: Decimal = Field(max_digits=5, decimal_places=2)\\n\\n\\nfoo = Foo(precise=Decimal(\\'123.45\\'))\\nprint(foo)\\n#> precise=Decimal(\\'123.45\\')\\n\\n```\\n\\n## Dataclass Constraints\\n\\nThere are fields that can be used to constrain dataclasses:\\n\\n- `init`: Whether the field should be included in the `__init__` of the dataclass.\\n- `init_var`: Whether the field should be seen as an [init-only field](https://docs.python.org/3/library/dataclasses.html#init-only-variables) in the dataclass.\\n- `kw_only`: Whether the field should be a keyword-only argument in the constructor of the dataclass.\\n\\nHere\\'s an example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Foo:\\n    bar: str\\n    baz: str = Field(init_var=True)\\n    qux: str = Field(kw_only=True)\\n\\n\\nclass Model(BaseModel):\\n    foo: Foo\\n\\n\\nmodel = Model(foo=Foo(\\'bar\\', baz=\\'baz\\', qux=\\'qux\\'))\\nprint(model.model_dump())  # (1)!\\n#> {\\'foo\\': {\\'bar\\': \\'bar\\', \\'qux\\': \\'qux\\'}}\\n\\n```\\n\\n1. The `baz` field is not included in the `model_dump()` output, since it is an init-only field.\\n\\n## Field Representation\\n\\nThe parameter `repr` can be used to control whether the field should be included in the string representation of the model.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(repr=True)  # (1)!\\n    age: int = Field(repr=False)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user)\\n#> name=\\'John\\'\\n\\n```\\n\\n1. This is the default value.\\n\\n## Discriminator\\n\\nThe parameter `discriminator` can be used to control the field that will be used to discriminate between different models in a union. It takes either the name of a field or a `Discriminator` instance. The `Discriminator` approach can be useful when the discriminator fields aren\\'t the same for all the models in the `Union`.\\n\\nThe following example shows how to use `discriminator` with a field name:\\n\\n```python\\nfrom typing import Literal, Union\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Cat, Dog] = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\n```python\\nfrom typing import Literal\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_type: Literal[\\'dog\\']\\n    age: int\\n\\n\\nclass Model(BaseModel):\\n    pet: Cat | Dog = Field(discriminator=\\'pet_type\\')\\n\\n\\nprint(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}}))  # (1)!\\n#> pet=Cat(pet_type=\\'cat\\', age=12)\\n\\n```\\n\\n1. See more about [Validating data](../models/#validating-data) in the [Models](../models/) page.\\n\\nThe following example shows how to use the `discriminator` keyword argument with a `Discriminator` instance:\\n\\n```python\\nfrom typing import Annotated, Literal, Union\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Union[Annotated[Cat, Tag(\\'cat\\')], Annotated[Dog, Tag(\\'dog\\')]] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\n```python\\nfrom typing import Annotated, Literal\\n\\nfrom pydantic import BaseModel, Discriminator, Field, Tag\\n\\n\\nclass Cat(BaseModel):\\n    pet_type: Literal[\\'cat\\']\\n    age: int\\n\\n\\nclass Dog(BaseModel):\\n    pet_kind: Literal[\\'dog\\']\\n    age: int\\n\\n\\ndef pet_discriminator(v):\\n    if isinstance(v, dict):\\n        return v.get(\\'pet_type\\', v.get(\\'pet_kind\\'))\\n    return getattr(v, \\'pet_type\\', getattr(v, \\'pet_kind\\', None))\\n\\n\\nclass Model(BaseModel):\\n    pet: Annotated[Cat, Tag(\\'cat\\')] | Annotated[Dog, Tag(\\'dog\\')] = Field(\\n        discriminator=Discriminator(pet_discriminator)\\n    )\\n\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_type\\': \\'cat\\', \\'age\\': 12}})))\\n#> Model(pet=Cat(pet_type=\\'cat\\', age=12))\\n\\nprint(repr(Model.model_validate({\\'pet\\': {\\'pet_kind\\': \\'dog\\', \\'age\\': 12}})))\\n#> Model(pet=Dog(pet_kind=\\'dog\\', age=12))\\n\\n```\\n\\nYou can also take advantage of `Annotated` to define your discriminated unions. See the [Discriminated Unions](../unions/#discriminated-unions) docs for more details.\\n\\n## Strict Mode\\n\\nThe `strict` parameter on a Field specifies whether the field should be validated in \"strict mode\". In strict mode, Pydantic throws an error during validation instead of coercing data on the field where `strict=True`.\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(strict=True)\\n    age: int = Field(strict=False)  # (1)!\\n\\n\\nuser = User(name=\\'John\\', age=\\'42\\')  # (2)!\\nprint(user)\\n#> name=\\'John\\' age=42\\n\\n```\\n\\n1. This is the default value.\\n1. The `age` field is not validated in the strict mode. Therefore, it can be assigned a string.\\n\\nSee [Strict Mode](../strict_mode/) for more details.\\n\\nSee [Conversion Table](../conversion_table/) for more details on how Pydantic converts data in both strict and lax modes.\\n\\n## Immutability\\n\\nThe parameter `frozen` is used to emulate the frozen dataclass behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability).\\n\\nSee the [frozen dataclass documentation](https://docs.python.org/3/library/dataclasses.html#frozen-instances) for more details.\\n\\n```python\\nfrom pydantic import BaseModel, Field, ValidationError\\n\\n\\nclass User(BaseModel):\\n    name: str = Field(frozen=True)\\n    age: int\\n\\n\\nuser = User(name=\\'John\\', age=42)\\n\\ntry:\\n    user.name = \\'Jane\\'  # (1)!\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for User\\n    name\\n      Field is frozen [type=frozen_field, input_value=\\'Jane\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n1. Since `name` field is frozen, the assignment is not allowed.\\n\\n## Exclude\\n\\nThe `exclude` parameter can be used to control which fields should be excluded from the model when exporting the model.\\n\\nSee the following example:\\n\\n```python\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass User(BaseModel):\\n    name: str\\n    age: int = Field(exclude=True)\\n\\n\\nuser = User(name=\\'John\\', age=42)\\nprint(user.model_dump())  # (1)!\\n#> {\\'name\\': \\'John\\'}\\n\\n```\\n\\n1. The `age` field is not included in the `model_dump()` output, since it is excluded.\\n\\nSee the [Serialization](../serialization/#model-and-field-level-include-and-exclude) section for more details.\\n\\n## Deprecated fields\\n\\nThe `deprecated` parameter can be used to mark a field as being deprecated. Doing so will result in:\\n\\n- a runtime deprecation warning emitted when accessing the field.\\n- `\"deprecated\": true` being set in the generated JSON schema.\\n\\nYou can set the `deprecated` parameter as one of:\\n\\n- A string, which will be used as the deprecation message.\\n- An instance of the `warnings.deprecated` decorator (or the `typing_extensions` backport).\\n- A boolean, which will be used to mark the field as deprecated with a default `\\'deprecated\\'` deprecation message.\\n\\n### `deprecated` as a string\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=\\'This is deprecated\\')]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\n### `deprecated` via the `warnings.deprecated` decorator\\n\\nNote\\n\\nYou can only use the `deprecated` decorator in this way if you have `typing_extensions` >= 4.9.0 installed.\\n\\n```python\\nimport importlib.metadata\\nfrom typing import Annotated, deprecated\\n\\nfrom packaging.version import Version\\n\\nfrom pydantic import BaseModel, Field\\n\\nif Version(importlib.metadata.version(\\'typing_extensions\\')) >= Version(\\'4.9\\'):\\n\\n    class Model(BaseModel):\\n        deprecated_field: Annotated[int, deprecated(\\'This is deprecated\\')]\\n\\n        # Or explicitly using `Field`:\\n        alt_form: Annotated[\\n            int, Field(deprecated=deprecated(\\'This is deprecated\\'))\\n        ]\\n\\n```\\n\\n### `deprecated` as a boolean\\n\\n```python\\nfrom typing import Annotated\\n\\nfrom pydantic import BaseModel, Field\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: Annotated[int, Field(deprecated=True)]\\n\\n\\nprint(Model.model_json_schema()[\\'properties\\'][\\'deprecated_field\\'])\\n#> {\\'deprecated\\': True, \\'title\\': \\'Deprecated Field\\', \\'type\\': \\'integer\\'}\\n\\n```\\n\\nSupport for `category` and `stacklevel`\\n\\nThe current implementation of this feature does not take into account the `category` and `stacklevel` arguments to the `deprecated` decorator. This might land in a future version of Pydantic.\\n\\nAccessing a deprecated field in validators\\n\\nWhen accessing a deprecated field inside a validator, the deprecation warning will be emitted. You can use catch_warnings to explicitly ignore it:\\n\\n```python\\nimport warnings\\n\\nfrom typing_extensions import Self\\n\\nfrom pydantic import BaseModel, Field, model_validator\\n\\n\\nclass Model(BaseModel):\\n    deprecated_field: int = Field(deprecated=\\'This is deprecated\\')\\n\\n    @model_validator(mode=\\'after\\')\\n    def validate_model(self) -> Self:\\n        with warnings.catch_warnings():\\n            warnings.simplefilter(\\'ignore\\', DeprecationWarning)\\n            self.deprecated_field = self.deprecated_field * 2\\n\\n```\\n\\n## Customizing JSON Schema\\n\\nSome field parameters are used exclusively to customize the generated JSON schema. The parameters in question are:\\n\\n- `title`\\n- `description`\\n- `examples`\\n- `json_schema_extra`\\n\\nRead more about JSON schema customization / modification with fields in the [Customizing JSON Schema](../json_schema/#field-level-customization) section of the JSON schema docs.\\n\\n## The `computed_field` decorator\\n\\nAPI Documentation\\n\\ncomputed_field\\n\\nThe computed_field decorator can be used to include property or cached_property attributes when serializing a model or dataclass. The property will also be taken into account in the JSON Schema (in serialization mode).\\n\\nNote\\n\\nProperties can be useful for fields that are computed from other fields, or for fields that are expensive to be computed (and thus, are cached if using cached_property).\\n\\nHowever, note that Pydantic will *not* perform any additional logic on the wrapped property (validation, cache invalidation, etc.).\\n\\nHere\\'s an example of the JSON schema (in serialization mode) generated for a model with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property  # (1)!\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nprint(Box.model_json_schema(mode=\\'serialization\\'))\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'width\\': {\\'title\\': \\'Width\\', \\'type\\': \\'number\\'},\\n        \\'height\\': {\\'title\\': \\'Height\\', \\'type\\': \\'number\\'},\\n        \\'depth\\': {\\'title\\': \\'Depth\\', \\'type\\': \\'number\\'},\\n        \\'volume\\': {\\'readOnly\\': True, \\'title\\': \\'Volume\\', \\'type\\': \\'number\\'},\\n    },\\n    \\'required\\': [\\'width\\', \\'height\\', \\'depth\\', \\'volume\\'],\\n    \\'title\\': \\'Box\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n1. If not specified, computed_field will implicitly convert the method to a property. However, it is preferable to explicitly use the @property decorator for type checking purposes.\\n\\nHere\\'s an example using the `model_dump` method with a computed field:\\n\\n```python\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n\\nb = Box(width=1, height=2, depth=3)\\nprint(b.model_dump())\\n#> {\\'width\\': 1.0, \\'height\\': 2.0, \\'depth\\': 3.0, \\'volume\\': 6.0}\\n\\n```\\n\\nAs with regular fields, computed fields can be marked as being deprecated:\\n\\n```python\\nfrom typing_extensions import deprecated\\n\\nfrom pydantic import BaseModel, computed_field\\n\\n\\nclass Box(BaseModel):\\n    width: float\\n    height: float\\n    depth: float\\n\\n    @computed_field\\n    @property\\n    @deprecated(\"\\'volume\\' is deprecated\")\\n    def volume(self) -> float:\\n        return self.width * self.height * self.depth\\n\\n```\\n',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md'},\n",
       " {'context': 'API Documentation\\n\\npydantic.dataclasses.dataclass\\n\\nIf you don\\'t want to use Pydantic\\'s BaseModel you can instead get the same data validation on standard dataclasses.\\n\\n```python\\nfrom datetime import datetime\\nfrom typing import Optional\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: Optional[datetime] = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\n```python\\nfrom datetime import datetime\\n\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    signup_ts: datetime | None = None\\n\\n\\nuser = User(id=\\'42\\', signup_ts=\\'2032-06-21T12:00\\')\\nprint(user)\\n\"\"\"\\nUser(id=42, name=\\'John Doe\\', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\\n\"\"\"\\n\\n```\\n\\nNote\\n\\nKeep in mind that Pydantic dataclasses are **not** a replacement for [Pydantic models](../models/). They provide a similar functionality to stdlib dataclasses with the addition of Pydantic validation.\\n\\nThere are cases where subclassing using Pydantic models is the better choice.\\n\\nFor more information and discussion see [pydantic/pydantic#710](https://github.com/pydantic/pydantic/issues/710).\\n\\nSimilarities between Pydantic dataclasses and models include support for:\\n\\n- [Configuration](#dataclass-config) support\\n- [Nested](../models/#nested-models) classes\\n- [Generics](../models/#generic-models)\\n\\nSome differences between Pydantic dataclasses and models include:\\n\\n- [validators](#validators-and-initialization-hooks)\\n- The behavior with the extra configuration value\\n\\nSimilarly to Pydantic models, arguments used to instantiate the dataclass are [copied](../models/#attribute-copies).\\n\\nTo make use of the [various methods](../models/#model-methods-and-properties) to validate, dump and generate a JSON Schema, you can wrap the dataclass with a TypeAdapter and make use of its methods.\\n\\nYou can use both the Pydantic\\'s Field() and the stdlib\\'s field() functions:\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: Optional[int] = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: Optional[int] = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import Field, TypeAdapter\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass User:\\n    id: int\\n    name: str = \\'John Doe\\'\\n    friends: list[int] = dataclasses.field(default_factory=lambda: [0])\\n    age: int | None = dataclasses.field(\\n        default=None,\\n        metadata={\\'title\\': \\'The age of the user\\', \\'description\\': \\'do not lie!\\'},\\n    )\\n    height: int | None = Field(None, title=\\'The height in cm\\', ge=50, le=300)\\n\\n\\nuser = User(id=\\'42\\')\\nprint(TypeAdapter(User).json_schema())\\n\"\"\"\\n{\\n    \\'properties\\': {\\n        \\'id\\': {\\'title\\': \\'Id\\', \\'type\\': \\'integer\\'},\\n        \\'name\\': {\\'default\\': \\'John Doe\\', \\'title\\': \\'Name\\', \\'type\\': \\'string\\'},\\n        \\'friends\\': {\\n            \\'items\\': {\\'type\\': \\'integer\\'},\\n            \\'title\\': \\'Friends\\',\\n            \\'type\\': \\'array\\',\\n        },\\n        \\'age\\': {\\n            \\'anyOf\\': [{\\'type\\': \\'integer\\'}, {\\'type\\': \\'null\\'}],\\n            \\'default\\': None,\\n            \\'description\\': \\'do not lie!\\',\\n            \\'title\\': \\'The age of the user\\',\\n        },\\n        \\'height\\': {\\n            \\'anyOf\\': [\\n                {\\'maximum\\': 300, \\'minimum\\': 50, \\'type\\': \\'integer\\'},\\n                {\\'type\\': \\'null\\'},\\n            ],\\n            \\'default\\': None,\\n            \\'title\\': \\'The height in cm\\',\\n        },\\n    },\\n    \\'required\\': [\\'id\\'],\\n    \\'title\\': \\'User\\',\\n    \\'type\\': \\'object\\',\\n}\\n\"\"\"\\n\\n```\\n\\nThe Pydantic `@dataclass` decorator accepts the same arguments as the standard decorator, with the addition of a `config` parameter.\\n\\n## Dataclass config\\n\\nIf you want to modify the configuration like you would with a BaseModel, you have two options:\\n\\n- Use the `config` argument of the decorator.\\n- Define the configuration with the `__pydantic_config__` attribute.\\n\\n```python\\nfrom pydantic import ConfigDict\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n# Option 1 -- using the decorator argument:\\n@dataclass(config=ConfigDict(validate_assignment=True))  # (1)!\\nclass MyDataclass1:\\n    a: int\\n\\n\\n# Option 2 -- using an attribute:\\n@dataclass\\nclass MyDataclass2:\\n    a: int\\n\\n    __pydantic_config__ = ConfigDict(validate_assignment=True)\\n\\n```\\n\\n1. You can read more about `validate_assignment` in the API reference.\\n\\nNote\\n\\nWhile Pydantic dataclasses support the extra configuration value, some default behavior of stdlib dataclasses may prevail. For example, any extra fields present on a Pydantic dataclass with extra set to `\\'allow\\'` are omitted in the dataclass\\' string representation. There is also no way to provide validation [using the `__pydantic_extra__` attribute](../models/#extra-data).\\n\\n## Rebuilding dataclass schema\\n\\nThe rebuild_dataclass() can be used to rebuild the core schema of the dataclass. See the [rebuilding model schema](../models/#rebuilding-model-schema) section for more details.\\n\\n## Stdlib dataclasses and Pydantic dataclasses\\n\\n### Inherit from stdlib dataclasses\\n\\nStdlib dataclasses (nested or not) can also be inherited and Pydantic will automatically validate all the inherited fields.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass Z:\\n    z: int\\n\\n\\n@dataclasses.dataclass\\nclass Y(Z):\\n    y: int = 0\\n\\n\\n@pydantic.dataclasses.dataclass\\nclass X(Y):\\n    x: int = 0\\n\\n\\nfoo = X(x=b\\'1\\', y=\\'2\\', z=\\'3\\')\\nprint(foo)\\n#> X(z=3, y=2, x=1)\\n\\ntry:\\n    X(z=\\'pika\\')\\nexcept pydantic.ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for X\\n    z\\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value=\\'pika\\', input_type=str]\\n    \"\"\"\\n\\n```\\n\\n### Usage of stdlib dataclasses with `BaseModel`\\n\\nWhen a standard library dataclass is used within a Pydantic model, a Pydantic dataclass or a TypeAdapter, validation will be applied (and the [configuration](#dataclass-config) stays the same). This means that using a stdlib or a Pydantic dataclass as a field annotation is functionally equivalent.\\n\\n```python\\nimport dataclasses\\nfrom typing import Optional\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: Optional[User] = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict, ValidationError\\n\\n\\n@dataclasses.dataclass(frozen=True)\\nclass User:\\n    name: str\\n\\n\\nclass Foo(BaseModel):\\n    # Required so that pydantic revalidates the model attributes:\\n    model_config = ConfigDict(revalidate_instances=\\'always\\')\\n\\n    user: User | None = None\\n\\n\\n# nothing is validated as expected:\\nuser = User(name=[\\'not\\', \\'a\\', \\'string\\'])\\nprint(user)\\n#> User(name=[\\'not\\', \\'a\\', \\'string\\'])\\n\\n\\ntry:\\n    Foo(user=user)\\nexcept ValidationError as e:\\n    print(e)\\n    \"\"\"\\n    1 validation error for Foo\\n    user.name\\n      Input should be a valid string [type=string_type, input_value=[\\'not\\', \\'a\\', \\'string\\'], input_type=list]\\n    \"\"\"\\n\\nfoo = Foo(user=User(name=\\'pika\\'))\\ntry:\\n    foo.user.name = \\'bulbi\\'\\nexcept dataclasses.FrozenInstanceError as e:\\n    print(e)\\n    #> cannot assign to field \\'name\\'\\n\\n```\\n\\n### Using custom types\\n\\nAs said above, validation is applied on standard library dataclasses. If you make use of custom types, you will get an error when trying to refer to the dataclass. To circumvent the issue, you can set the arbitrary_types_allowed configuration value on the dataclass:\\n\\n```python\\nimport dataclasses\\n\\nfrom pydantic import BaseModel, ConfigDict\\nfrom pydantic.errors import PydanticSchemaGenerationError\\n\\n\\nclass ArbitraryType:\\n    def __init__(self, value):\\n        self.value = value\\n\\n    def __repr__(self):\\n        return f\\'ArbitraryType(value={self.value!r})\\'\\n\\n\\n@dataclasses.dataclass\\nclass DC:\\n    a: ArbitraryType\\n    b: str\\n\\n\\n# valid as it is a stdlib dataclass without validation:\\nmy_dc = DC(a=ArbitraryType(value=3), b=\\'qwe\\')\\n\\ntry:\\n\\n    class Model(BaseModel):\\n        dc: DC\\n        other: str\\n\\n    # invalid as dc is now validated with pydantic, and ArbitraryType is not a known type\\n    Model(dc=my_dc, other=\\'other\\')\\n\\nexcept PydanticSchemaGenerationError as e:\\n    print(e.message)\\n    \"\"\"\\n    Unable to generate pydantic-core schema for \\n. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\\n\\n    If you got this error by calling handler(\\n) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(\\n)` since we do not call `__get_pydantic_core_schema__` on `\\n` otherwise to avoid infinite recursion.\\n    \"\"\"\\n\\n\\n# valid as we set arbitrary_types_allowed=True, and that config pushes down to the nested vanilla dataclass\\nclass Model(BaseModel):\\n    model_config = ConfigDict(arbitrary_types_allowed=True)\\n\\n    dc: DC\\n    other: str\\n\\n\\nm = Model(dc=my_dc, other=\\'other\\')\\nprint(repr(m))\\n#> Model(dc=DC(a=ArbitraryType(value=3), b=\\'qwe\\'), other=\\'other\\')\\n\\n```\\n\\n### Checking if a dataclass is a Pydantic dataclass\\n\\nPydantic dataclasses are still considered dataclasses, so using dataclasses.is_dataclass will return `True`. To check if a type is specifically a pydantic dataclass you can use the is_pydantic_dataclass function.\\n\\n```python\\nimport dataclasses\\n\\nimport pydantic\\n\\n\\n@dataclasses.dataclass\\nclass StdLibDataclass:\\n    id: int\\n\\n\\nPydanticDataclass = pydantic.dataclasses.dataclass(StdLibDataclass)\\n\\nprint(dataclasses.is_dataclass(StdLibDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(StdLibDataclass))\\n#> False\\n\\nprint(dataclasses.is_dataclass(PydanticDataclass))\\n#> True\\nprint(pydantic.dataclasses.is_pydantic_dataclass(PydanticDataclass))\\n#> True\\n\\n```\\n\\n## Validators and initialization hooks\\n\\nValidators also work with Pydantic dataclasses:\\n\\n```python\\nfrom pydantic import field_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass DemoDataclass:\\n    product_id: str  # should be a five-digit string, may have leading zeros\\n\\n    @field_validator(\\'product_id\\', mode=\\'before\\')\\n    @classmethod\\n    def convert_int_serial(cls, v):\\n        if isinstance(v, int):\\n            v = str(v).zfill(5)\\n        return v\\n\\n\\nprint(DemoDataclass(product_id=\\'01234\\'))\\n#> DemoDataclass(product_id=\\'01234\\')\\nprint(DemoDataclass(product_id=2468))\\n#> DemoDataclass(product_id=\\'02468\\')\\n\\n```\\n\\nThe dataclass __post_init__() method is also supported, and will be called between the calls to *before* and *after* model validators.\\n\\nExample\\n\\n```python\\nfrom pydantic_core import ArgsKwargs\\nfrom typing_extensions import Self\\n\\nfrom pydantic import model_validator\\nfrom pydantic.dataclasses import dataclass\\n\\n\\n@dataclass\\nclass Birth:\\n    year: int\\n    month: int\\n    day: int\\n\\n\\n@dataclass\\nclass User:\\n    birth: Birth\\n\\n    @model_validator(mode=\\'before\\')\\n    @classmethod\\n    def before(cls, values: ArgsKwargs) -> ArgsKwargs:\\n        print(f\\'First: {values}\\')  # (1)!\\n        \"\"\"\\n        First: ArgsKwargs((), {\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n        \"\"\"\\n        return values\\n\\n    @model_validator(mode=\\'after\\')\\n    def after(self) -> Self:\\n        print(f\\'Third: {self}\\')\\n        #> Third: User(birth=Birth(year=1995, month=3, day=2))\\n        return self\\n\\n    def __post_init__(self):\\n        print(f\\'Second: {self.birth}\\')\\n        #> Second: Birth(year=1995, month=3, day=2)\\n\\n\\nuser = User(**{\\'birth\\': {\\'year\\': 1995, \\'month\\': 3, \\'day\\': 2}})\\n\\n```\\n\\n1. Unlike Pydantic models, the `values` parameter is of type ArgsKwargs\\n',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md'},\n",
       " {'context': 'Provide an enhanced dataclass that performs validation.\\n\\n## dataclass\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool = False,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = ...,\\n    slots: bool = ...\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> Callable[[type[_T]], type[PydanticDataclass]]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T],\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None\\n) -> type[PydanticDataclass]\\n\\n```\\n\\n```python\\ndataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False\\n) -> (\\n    Callable[[type[_T]], type[PydanticDataclass]]\\n    | type[PydanticDataclass]\\n)\\n\\n```\\n\\nUsage Documentation\\n\\n[`dataclasses`](../../concepts/dataclasses/)\\n\\nA decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`, but with added validation.\\n\\nThis function should be used similarly to `dataclasses.dataclass`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `_cls` | `type[_T] | None` | The target dataclass. | `None` | | `init` | `Literal[False]` | Included for signature compatibility with dataclasses.dataclass, and is passed through to dataclasses.dataclass when appropriate. If specified, must be set to False, as pydantic inserts its own __init__ function. | `False` | | `repr` | `bool` | A boolean indicating whether to include the field in the __repr__ output. | `True` | | `eq` | `bool` | Determines if a __eq__ method should be generated for the class. | `True` | | `order` | `bool` | Determines if comparison magic methods should be generated, such as __lt__, but not __eq__. | `False` | | `unsafe_hash` | `bool` | Determines if a __hash__ method should be included in the class, as in dataclasses.dataclass. | `False` | | `frozen` | `bool | None` | Determines if the generated class should be a \\'frozen\\' dataclass, which does not allow its attributes to be modified after it has been initialized. If not set, the value from the provided config argument will be used (and will default to False otherwise). | `None` | | `config` | `ConfigDict | type[object] | None` | The Pydantic config to use for the dataclass. | `None` | | `validate_on_init` | `bool | None` | A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses are validated on init. | `None` | | `kw_only` | `bool` | Determines if __init__ method parameters must be specified by keyword only. Defaults to False. | `False` | | `slots` | `bool` | Determines if the generated class should be a \\'slots\\' dataclass, which does not allow the addition of new attributes after instantiation. | `False` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]` | A decorator that accepts a class as its argument and returns a Pydantic dataclass. |\\n\\nRaises:\\n\\n| Type | Description | | --- | --- | | `AssertionError` | Raised if init is not False or validate_on_init is False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\n@dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))\\ndef dataclass(\\n    _cls: type[_T] | None = None,\\n    *,\\n    init: Literal[False] = False,\\n    repr: bool = True,\\n    eq: bool = True,\\n    order: bool = False,\\n    unsafe_hash: bool = False,\\n    frozen: bool | None = None,\\n    config: ConfigDict | type[object] | None = None,\\n    validate_on_init: bool | None = None,\\n    kw_only: bool = False,\\n    slots: bool = False,\\n) -> Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:\\n    \"\"\"!!! abstract \"Usage Documentation\"\\n        [`dataclasses`](../concepts/dataclasses.md)\\n\\n    A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,\\n    but with added validation.\\n\\n    This function should be used similarly to `dataclasses.dataclass`.\\n\\n    Args:\\n        _cls: The target `dataclass`.\\n        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to\\n            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its\\n            own  `__init__` function.\\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\\n        eq: Determines if a `__eq__` method should be generated for the class.\\n        order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.\\n        unsafe_hash: Determines if a `__hash__` method should be included in the class, as in `dataclasses.dataclass`.\\n        frozen: Determines if the generated class should be a \\'frozen\\' `dataclass`, which does not allow its\\n            attributes to be modified after it has been initialized. If not set, the value from the provided `config` argument will be used (and will default to `False` otherwise).\\n        config: The Pydantic config to use for the `dataclass`.\\n        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses\\n            are validated on init.\\n        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.\\n        slots: Determines if the generated class should be a \\'slots\\' `dataclass`, which does not allow the addition of\\n            new attributes after instantiation.\\n\\n    Returns:\\n        A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.\\n\\n    Raises:\\n        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.\\n    \"\"\"\\n    assert init is False, \\'pydantic.dataclasses.dataclass only supports init=False\\'\\n    assert validate_on_init is not False, \\'validate_on_init=False is no longer supported\\'\\n\\n    if sys.version_info >= (3, 10):\\n        kwargs = {\\'kw_only\\': kw_only, \\'slots\\': slots}\\n    else:\\n        kwargs = {}\\n\\n    def make_pydantic_fields_compatible(cls: type[Any]) -> None:\\n        \"\"\"Make sure that stdlib `dataclasses` understands `Field` kwargs like `kw_only`\\n        To do that, we simply change\\n          `x: int = pydantic.Field(..., kw_only=True)`\\n        into\\n          `x: int = dataclasses.field(default=pydantic.Field(..., kw_only=True), kw_only=True)`\\n        \"\"\"\\n        for annotation_cls in cls.__mro__:\\n            annotations: dict[str, Any] = getattr(annotation_cls, \\'__annotations__\\', {})\\n            for field_name in annotations:\\n                field_value = getattr(cls, field_name, None)\\n                # Process only if this is an instance of `FieldInfo`.\\n                if not isinstance(field_value, FieldInfo):\\n                    continue\\n\\n                # Initialize arguments for the standard `dataclasses.field`.\\n                field_args: dict = {\\'default\\': field_value}\\n\\n                # Handle `kw_only` for Python 3.10+\\n                if sys.version_info >= (3, 10) and field_value.kw_only:\\n                    field_args[\\'kw_only\\'] = True\\n\\n                # Set `repr` attribute if it\\'s explicitly specified to be not `True`.\\n                if field_value.repr is not True:\\n                    field_args[\\'repr\\'] = field_value.repr\\n\\n                setattr(cls, field_name, dataclasses.field(**field_args))\\n                # In Python 3.9, when subclassing, information is pulled from cls.__dict__[\\'__annotations__\\']\\n                # for annotations, so we must make sure it\\'s initialized before we add to it.\\n                if cls.__dict__.get(\\'__annotations__\\') is None:\\n                    cls.__annotations__ = {}\\n                cls.__annotations__[field_name] = annotations[field_name]\\n\\n    def create_dataclass(cls: type[Any]) -> type[PydanticDataclass]:\\n        \"\"\"Create a Pydantic dataclass from a regular dataclass.\\n\\n        Args:\\n            cls: The class to create the Pydantic dataclass from.\\n\\n        Returns:\\n            A Pydantic dataclass.\\n        \"\"\"\\n        from ._internal._utils import is_model_class\\n\\n        if is_model_class(cls):\\n            raise PydanticUserError(\\n                f\\'Cannot create a Pydantic dataclass from {cls.__name__} as it is already a Pydantic model\\',\\n                code=\\'dataclass-on-model\\',\\n            )\\n\\n        original_cls = cls\\n\\n        # we warn on conflicting config specifications, but only if the class doesn\\'t have a dataclass base\\n        # because a dataclass base might provide a __pydantic_config__ attribute that we don\\'t want to warn about\\n        has_dataclass_base = any(dataclasses.is_dataclass(base) for base in cls.__bases__)\\n        if not has_dataclass_base and config is not None and hasattr(cls, \\'__pydantic_config__\\'):\\n            warn(\\n                f\\'`config` is set via both the `dataclass` decorator and `__pydantic_config__` for dataclass {cls.__name__}. \\'\\n                f\\'The `config` specification from `dataclass` decorator will take priority.\\',\\n                category=UserWarning,\\n                stacklevel=2,\\n            )\\n\\n        # if config is not explicitly provided, try to read it from the type\\n        config_dict = config if config is not None else getattr(cls, \\'__pydantic_config__\\', None)\\n        config_wrapper = _config.ConfigWrapper(config_dict)\\n        decorators = _decorators.DecoratorInfos.build(cls)\\n\\n        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator\\n        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,\\n        # since dataclasses.dataclass will set this as the __doc__\\n        original_doc = cls.__doc__\\n\\n        if _pydantic_dataclasses.is_builtin_dataclass(cls):\\n            # Don\\'t preserve the docstring for vanilla dataclasses, as it may include the signature\\n            # This matches v1 behavior, and there was an explicit test for it\\n            original_doc = None\\n\\n            # We don\\'t want to add validation to the existing std lib dataclass, so we will subclass it\\n            #   If the class is generic, we need to make sure the subclass also inherits from Generic\\n            #   with all the same parameters.\\n            bases = (cls,)\\n            if issubclass(cls, Generic):\\n                generic_base = Generic[cls.__parameters__]  # type: ignore\\n                bases = bases + (generic_base,)\\n            cls = types.new_class(cls.__name__, bases)\\n\\n        make_pydantic_fields_compatible(cls)\\n\\n        # Respect frozen setting from dataclass constructor and fallback to config setting if not provided\\n        if frozen is not None:\\n            frozen_ = frozen\\n            if config_wrapper.frozen:\\n                # It\\'s not recommended to define both, as the setting from the dataclass decorator will take priority.\\n                warn(\\n                    f\\'`frozen` is set via both the `dataclass` decorator and `config` for dataclass {cls.__name__!r}.\\'\\n                    \\'This is not recommended. The `frozen` specification on `dataclass` will take priority.\\',\\n                    category=UserWarning,\\n                    stacklevel=2,\\n                )\\n        else:\\n            frozen_ = config_wrapper.frozen or False\\n\\n        cls = dataclasses.dataclass(  # type: ignore[call-overload]\\n            cls,\\n            # the value of init here doesn\\'t affect anything except that it makes it easier to generate a signature\\n            init=True,\\n            repr=repr,\\n            eq=eq,\\n            order=order,\\n            unsafe_hash=unsafe_hash,\\n            frozen=frozen_,\\n            **kwargs,\\n        )\\n\\n        # This is an undocumented attribute to distinguish stdlib/Pydantic dataclasses.\\n        # It should be set as early as possible:\\n        cls.__is_pydantic_dataclass__ = True\\n\\n        cls.__pydantic_decorators__ = decorators  # type: ignore\\n        cls.__doc__ = original_doc\\n        cls.__module__ = original_cls.__module__\\n        cls.__qualname__ = original_cls.__qualname__\\n        cls.__pydantic_fields_complete__ = classmethod(_pydantic_fields_complete)\\n        cls.__pydantic_complete__ = False  # `complete_dataclass` will set it to `True` if successful.\\n        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:\\n        # fetch the parent ns using `parent_frame_namespace` (if the dataclass was defined in a function),\\n        # and possibly cache it (see the `__pydantic_parent_namespace__` logic for models).\\n        _pydantic_dataclasses.complete_dataclass(cls, config_wrapper, raise_errors=False)\\n        return cls\\n\\n    return create_dataclass if _cls is None else create_dataclass(_cls)\\n\\n```\\n\\n## rebuild_dataclass\\n\\n```python\\nrebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None\\n) -> bool | None\\n\\n```\\n\\nTry to rebuild the pydantic-core schema for the dataclass.\\n\\nThis may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.\\n\\nThis is analogous to `BaseModel.model_rebuild`.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `cls` | `type[PydanticDataclass]` | The class to rebuild the pydantic-core schema for. | *required* | | `force` | `bool` | Whether to force the rebuilding of the schema, defaults to False. | `False` | | `raise_errors` | `bool` | Whether to raise errors, defaults to True. | `True` | | `_parent_namespace_depth` | `int` | The depth level of the parent namespace, defaults to 2. | `2` | | `_types_namespace` | `MappingNamespace | None` | The types namespace, defaults to None. | `None` |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `bool | None` | Returns None if the schema is already \"complete\" and rebuilding was not required. | | `bool | None` | If rebuilding was required, returns True if rebuilding was successful, otherwise False. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef rebuild_dataclass(\\n    cls: type[PydanticDataclass],\\n    *,\\n    force: bool = False,\\n    raise_errors: bool = True,\\n    _parent_namespace_depth: int = 2,\\n    _types_namespace: MappingNamespace | None = None,\\n) -> bool | None:\\n    \"\"\"Try to rebuild the pydantic-core schema for the dataclass.\\n\\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\\n    the initial attempt to build the schema, and automatic rebuilding fails.\\n\\n    This is analogous to `BaseModel.model_rebuild`.\\n\\n    Args:\\n        cls: The class to rebuild the pydantic-core schema for.\\n        force: Whether to force the rebuilding of the schema, defaults to `False`.\\n        raise_errors: Whether to raise errors, defaults to `True`.\\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\\n        _types_namespace: The types namespace, defaults to `None`.\\n\\n    Returns:\\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\\n    \"\"\"\\n    if not force and cls.__pydantic_complete__:\\n        return None\\n\\n    for attr in (\\'__pydantic_core_schema__\\', \\'__pydantic_validator__\\', \\'__pydantic_serializer__\\'):\\n        if attr in cls.__dict__:\\n            # Deleting the validator/serializer is necessary as otherwise they can get reused in\\n            # pydantic-core. Same applies for the core schema that can be reused in schema generation.\\n            delattr(cls, attr)\\n\\n    cls.__pydantic_complete__ = False\\n\\n    if _types_namespace is not None:\\n        rebuild_ns = _types_namespace\\n    elif _parent_namespace_depth > 0:\\n        rebuild_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}\\n    else:\\n        rebuild_ns = {}\\n\\n    ns_resolver = _namespace_utils.NsResolver(\\n        parent_namespace=rebuild_ns,\\n    )\\n\\n    return _pydantic_dataclasses.complete_dataclass(\\n        cls,\\n        _config.ConfigWrapper(cls.__pydantic_config__, check=False),\\n        raise_errors=raise_errors,\\n        ns_resolver=ns_resolver,\\n        # We could provide a different config instead (with `\\'defer_build\\'` set to `True`)\\n        # of this explicit `_force_build` argument, but because config can come from the\\n        # decorator parameter or the `__pydantic_config__` attribute, `complete_dataclass`\\n        # will overwrite `__pydantic_config__` with the provided config above:\\n        _force_build=True,\\n    )\\n\\n```\\n\\n## is_pydantic_dataclass\\n\\n```python\\nis_pydantic_dataclass(\\n    class_: type[Any],\\n) -> TypeGuard[type[PydanticDataclass]]\\n\\n```\\n\\nWhether a class is a pydantic dataclass.\\n\\nParameters:\\n\\n| Name | Type | Description | Default | | --- | --- | --- | --- | | `class_` | `type[Any]` | The class. | *required* |\\n\\nReturns:\\n\\n| Type | Description | | --- | --- | | `TypeGuard[type[PydanticDataclass]]` | True if the class is a pydantic dataclass, False otherwise. |\\n\\nSource code in `pydantic/dataclasses.py`\\n\\n```python\\ndef is_pydantic_dataclass(class_: type[Any], /) -> TypeGuard[type[PydanticDataclass]]:\\n    \"\"\"Whether a class is a pydantic dataclass.\\n\\n    Args:\\n        class_: The class.\\n\\n    Returns:\\n        `True` if the class is a pydantic dataclass, `False` otherwise.\\n    \"\"\"\\n    try:\\n        return \\'__is_pydantic_dataclass__\\' in class_.__dict__ and dataclasses.is_dataclass(class_)\\n    except AttributeError:\\n        return False\\n\\n```\\n',\n",
       "  'url': 'https://docs.pydantic.dev/latest/api/dataclasses/index.md'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_context = \"\\n\\n\".join([c[\"context\"] for c in filtered_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are an AI assistant for question-answering tasks.\n",
    "\n",
    "Use the retrieved context provided below to answer the user's question.\n",
    "Your response **must** include any relevant URLs mentioned in the context.\n",
    "Please exclude \"/index.md\" at the end of URLs\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in **ENGLISH**.\n",
    "Please follow the format below:\n",
    "# FORMAT\n",
    "\n",
    "Answer\n",
    "\n",
    "[Related Links]\n",
    "- URL1\n",
    "- URL2\n",
    "...\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set llm\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Build the chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `Field` class in Pydantic is used to define fields on models, providing extra information about a field for the model schema or complex validation. It allows you to specify various parameters such as default values, aliases, validation constraints, and more.\n",
      "\n",
      "Here is an example code snippet using the `Field` class:\n",
      "\n",
      "```python\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "class User(BaseModel):\n",
      "    name: str = Field(default='John Doe', title='Name', description='The name of the user')\n",
      "    age: int = Field(default=20, ge=0, title='Age', description='The age of the user, must be non-negative')\n",
      "\n",
      "user = User()\n",
      "print(user)\n",
      "```\n",
      "\n",
      "In this example, the `Field` class is used to define the `name` and `age` fields with default values, titles, descriptions, and a validation constraint for the `age` field to ensure it is non-negative.\n",
      "\n",
      "[Related Links]\n",
      "- https://docs.pydantic.dev/latest/api/fields\n",
      "- https://docs.pydantic.dev/latest/concepts/fields\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the Fields class and give the example code?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
